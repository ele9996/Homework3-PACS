{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Homework3_code.ipynb","provenance":[{"file_id":"1PhNPpklp9FbxJEtsZ8Jp9qXQa4aZDK5Y","timestamp":1589382498471}],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"780f56039c8d4e24b5b453253c760679":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_7e16ecbf3a4045cc9a4e424e477610d1","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_e8ce81c2b5ef40298a798bc3369b9390","IPY_MODEL_4cfdf69ca88f479894810878c852d381"]}},"7e16ecbf3a4045cc9a4e424e477610d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e8ce81c2b5ef40298a798bc3369b9390":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_931d2d67c13748b59a1c753715f2005f","_dom_classes":[],"description":"100%","_model_name":"FloatProgressModel","bar_style":"success","max":244418560,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":244418560,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8a9fd7a66f474cd1aa471400d4bec44d"}},"4cfdf69ca88f479894810878c852d381":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c0ae073c6374429f9d61ff88aa7fcc51","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 233M/233M [00:02&lt;00:00, 96.6MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_17a07c8ec3a1467ba7eebf8e8d1ad479"}},"931d2d67c13748b59a1c753715f2005f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8a9fd7a66f474cd1aa471400d4bec44d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c0ae073c6374429f9d61ff88aa7fcc51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"17a07c8ec3a1467ba7eebf8e8d1ad479":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"c9QcGnGPdX2C","colab_type":"text"},"source":["\n","**Install requirements**"]},{"cell_type":"code","metadata":{"id":"k9O3aM3Tb28q","colab_type":"code","outputId":"6a9a12f3-5172-426b-828b-b06b1d2a3d9f","executionInfo":{"status":"ok","timestamp":1591798910517,"user_tz":-120,"elapsed":282502,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":760}},"source":["!pip3 install 'torch==1.3.0'\n","!pip3 install 'torchvision==0.5.0'\n","!pip3 install 'Pillow-SIMD'\n","!pip3 install 'tqdm'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Collecting torch==1.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/50a05de5337f7a924bb8bd70c6936230642233e424d6a9747ef1cfbde353/torch-1.3.0-cp36-cp36m-manylinux1_x86_64.whl (773.1MB)\n","\u001b[K     |████████████████████████████████| 773.1MB 23kB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.3.0) (1.18.5)\n","\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 1.3.0 which is incompatible.\u001b[0m\n","Installing collected packages: torch\n","  Found existing installation: torch 1.5.0+cu101\n","    Uninstalling torch-1.5.0+cu101:\n","      Successfully uninstalled torch-1.5.0+cu101\n","Successfully installed torch-1.3.0\n","Collecting torchvision==0.5.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/90/6141bf41f5655c78e24f40f710fdd4f8a8aff6c8b7c6f0328240f649bdbe/torchvision-0.5.0-cp36-cp36m-manylinux1_x86_64.whl (4.0MB)\n","\u001b[K     |████████████████████████████████| 4.0MB 2.8MB/s \n","\u001b[?25hCollecting torch==1.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n","\u001b[K     |████████████████████████████████| 753.4MB 19kB/s \n","\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (7.0.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.12.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.5.0) (1.18.5)\n","Installing collected packages: torch, torchvision\n","  Found existing installation: torch 1.3.0\n","    Uninstalling torch-1.3.0:\n","      Successfully uninstalled torch-1.3.0\n","  Found existing installation: torchvision 0.6.0+cu101\n","    Uninstalling torchvision-0.6.0+cu101:\n","      Successfully uninstalled torchvision-0.6.0+cu101\n","Successfully installed torch-1.4.0 torchvision-0.5.0\n","Collecting Pillow-SIMD\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/6a/30d21c886293cca3755b8e55de34137a5068b77eba1c0644d3632080516b/Pillow-SIMD-7.0.0.post3.tar.gz (630kB)\n","\u001b[K     |████████████████████████████████| 634kB 2.8MB/s \n","\u001b[?25hBuilding wheels for collected packages: Pillow-SIMD\n","  Building wheel for Pillow-SIMD (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for Pillow-SIMD: filename=Pillow_SIMD-7.0.0.post3-cp36-cp36m-linux_x86_64.whl size=1110246 sha256=8160f6f3236f427ec3e2ff95573b3b288346ecd1c7f7628b08c27bb1965cc63a\n","  Stored in directory: /root/.cache/pip/wheels/d3/ac/4f/4cdf8febba528e5f1b09fc58d5181e1c12ed1e8655dcd583b8\n","Successfully built Pillow-SIMD\n","Installing collected packages: Pillow-SIMD\n","Successfully installed Pillow-SIMD-7.0.0.post3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["PIL"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.41.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fo942LMOdlh4","colab_type":"text"},"source":["**Import libraries**"]},{"cell_type":"code","metadata":{"id":"DokFOdD1dJEl","colab_type":"code","colab":{}},"source":["import os\n","import logging\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Subset, DataLoader\n","from torch.backends import cudnn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torchvision\n","from torchvision import transforms\n","from torchvision.models import alexnet\n","from torch.autograd import Function \n","try:\n","    from torch.hub import load_state_dict_from_url\n","except ImportError:\n","    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n","\n","from PIL import Image\n","from tqdm import tqdm\n","from sklearn.model_selection import GridSearchCV"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OIDLJuIXK_vh","colab_type":"text"},"source":["#**Set Arguments**"]},{"cell_type":"code","metadata":{"id":"d5PkYfqfK_SA","colab_type":"code","colab":{}},"source":["DEVICE = 'cuda' # 'cuda' or 'cpu'\n","\n","NUM_CLASSES = 7\n","\n","BATCH_SIZE = 256     # Higher batch sizes allows for larger learning rates. An empirical heuristic suggests that, when changing\n","                     # the batch size, learning rate should change by the same factor to have comparable results\n","\n","LR = 1e-3            # The initial Learning Rate\n","MOMENTUM = 0.9       # Hyperparameter for SGD, keep this at 0.9 when using SGD\n","WEIGHT_DECAY = 5e-5  # Regularization, you can keep this at the default\n","\n","NUM_EPOCHS = 30      # Total number of training epochs (iterations over dataset)\n","STEP_SIZE = 20       # How many epochs before decreasing learning rate (if using a step-down policy)\n","GAMMA = 0.1          # Multiplicative factor for learning rate step-down\n","\n","#vectors for grid search\n","Learning_rates = [1e-5, 1e-4,1e-2]\n","\n","\n","num_epochs = [10, 20, 30]\n","\n","LOG_FREQUENCY = 10"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9gwii0TBHvzh","colab_type":"text"},"source":["# **Define Data Preprocessing**"]},{"cell_type":"code","metadata":{"id":"QUDdw4j2H0Mc","colab_type":"code","colab":{}},"source":["# Define transforms for training phase\n","train_transform = transforms.Compose([transforms.Resize(256),      # Resizes short size of the PIL image to 256\n","                                      transforms.CenterCrop(224),  # Crops a central square patch of the image\n","                                                                   # 224 because torchvision's AlexNet needs a 224x224 input!\n","                                                                   # Remember this when applying different transformations, otherwise you get an error\n","                                     \n","                                      transforms.ToTensor(), # Turn PIL Image to torch.Tensor\n","                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Normalizes tensor with mean and standard deviation\n","])\n","# Define transforms for the evaluation phase\n","eval_transform = transforms.Compose([transforms.Resize(256),\n","                                      transforms.CenterCrop(224),\n","                                      transforms.ToTensor(),\n","                                      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))                                    \n","])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2qYIHPzYLY7i","colab_type":"text"},"source":["#**Prepare Dataset**"]},{"cell_type":"code","metadata":{"id":"QfVq_uDHLbsR","colab_type":"code","outputId":"b163a78f-a395-4658-f34a-a36e2af9397c","executionInfo":{"status":"ok","timestamp":1591798934270,"user_tz":-120,"elapsed":306207,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":151}},"source":["# Clone github repository with data\n","if not os.path.isdir('./Homework3-PACS'):\n","  !git clone https://github.com/ele9996/Homework3-PACS.git\n","\n","DATA_DIR = 'Homework3-PACS/PACS'\n","\n","# Prepare Pytorch train/test Datasets\n","train_dataset = torchvision.datasets.ImageFolder(DATA_DIR + \"/photo\", transform=train_transform)\n","test_dataset = torchvision.datasets.ImageFolder(DATA_DIR + \"/art_painting\", transform=eval_transform)\n","\n","#from old template\n","#train_indexes = [idx for idx in range(len(train_dataset)) if idx % 5]\n","#test_indexes = [idx for idx in range(len(test_dataset)) if not idx % 5]\n","\n","#train_dataset = Subset(train_dataset, train_indexes)\n","#test_dataset = Subset(test_dataset, test_indexes)\n","\n","# Check dataset sizes\n","print('Train Dataset: {}'.format(len(train_dataset)))\n","print('Test Dataset: {}'.format(len(test_dataset)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'Homework3-PACS'...\n","remote: Enumerating objects: 10032, done.\u001b[K\n","remote: Total 10032 (delta 0), reused 0 (delta 0), pack-reused 10032\u001b[K\n","Receiving objects: 100% (10032/10032), 174.13 MiB | 11.47 MiB/s, done.\n","Resolving deltas: 100% (1/1), done.\n","Checking out files: 100% (9993/9993), done.\n","Train Dataset: 1670\n","Test Dataset: 2048\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FYEDQ7Z21ldN","colab_type":"text"},"source":["#**Prepare Dataloaders**"]},{"cell_type":"code","metadata":{"id":"VriRw8SI1nle","colab_type":"code","colab":{}},"source":["# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n","#photos\n","train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True) #num_workers=4\n","#art painting\n","test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gbZ1t5Qs2z4j","colab_type":"text"},"source":["#**Prepare DACNN and main function definition**"]},{"cell_type":"code","metadata":{"id":"exHUjtXa22DN","colab_type":"code","outputId":"b82f988e-69f9-4f42-ebaa-339417e2cc29","executionInfo":{"status":"ok","timestamp":1591798938201,"user_tz":-120,"elapsed":310114,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":654,"referenced_widgets":["780f56039c8d4e24b5b453253c760679","7e16ecbf3a4045cc9a4e424e477610d1","e8ce81c2b5ef40298a798bc3369b9390","4cfdf69ca88f479894810878c852d381","931d2d67c13748b59a1c753715f2005f","8a9fd7a66f474cd1aa471400d4bec44d","c0ae073c6374429f9d61ff88aa7fcc51","17a07c8ec3a1467ba7eebf8e8d1ad479"]}},"source":["model_urls = {\n","    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n","}\n","\n","\n","\n","class GradientReversalFn(Function):\n","    @staticmethod\n","    def forward(ctx, x, alpha):\n","        # Store context for backprop\n","        ctx.alpha = alpha\n","        \n","        # Forward pass is a no-op\n","        return x.view_as(x)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        # Backward pass is just to -alpha the gradient\n","        output = grad_output.neg() * ctx.alpha\n","        return output, None\n","\n","\n","\n","\n","class DACNN(nn.Module):\n","  def __init__(self, num_classes, **kwargs):\n","        super(DACNN, self).__init__()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2)),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n","            nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2)),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n","            nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.ReLU(inplace=True),\n","            nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n","            nn.ReLU(inplace=True),\n","            nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n","           \n","          )\n","        self.avgpool= nn.AdaptiveAvgPool2d(output_size=(6, 6))\n","        \n","        self.classifier = nn.Sequential(\n","            \n","            nn.Dropout(),\n","            nn.Linear(in_features=9216, out_features=4096, bias=True),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout(),\n","            nn.Linear(in_features=4096, out_features=4096, bias=True),\n","            nn.ReLU(inplace=True),\n","            nn.Linear(in_features=4096, out_features=1000, bias=True),\n","            \n","          )\n","        \n","        self.domain_classifier = nn.Sequential(\n","            nn.Linear(256 * 6 * 6, 4096), \n","            nn.BatchNorm1d(4096),\n","            nn.ReLU(True),\n","            nn.Linear(4096, 1000),\n","            nn.LogSoftmax(dim=1),\n","          )\n","          \n","  def forward(self, x, alpha=None):     \n","        # Handle single-channel input by expanding (repeating) the singleton dimention\n","        features=self.features(x)\n","        features = features.view(features.size(0), -1)\n","\n","        if alpha is not None:\n","            # gradient reversal layer (backward gradients will be reversed)\n","            reverse_feature = GradientReversalFn.apply(features, alpha)\n","            domain_pred = self.domain_classifier(features)\n","            return domain_pred\n","        # If we don't pass alpha, we assume we are training with supervision\n","        else:\n","            \n","            class_pred = self.classifier(features)\n","            return class_pred\n","        \n","        \n","       \n","\n","def DANNAlexnet(pretrained=True,  num_classes=7, **kwargs):\n","    net = DACNN(num_classes = 7, **kwargs)\n","    if pretrained:\n","        state_dict = load_state_dict_from_url(model_urls['alexnet'])\n","        net.load_state_dict(state_dict, strict=False)\n","        for x in [(0,1) , (3,6)]:\n","            \n","            net.domain_classifier[x[0]].weight.data = net.classifier[x[1]].weight.data\n","            net.domain_classifier[x[0]].bias.data = net.classifier[x[1]].bias.data\n","        net.classifier[6] = nn.Linear(4096, num_classes)\n","        net.domain_classifier[3] = nn.Linear(4096, 2)\n","    return net\n","\n","net=DANNAlexnet(num_classes=7)\n","net"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to /root/.cache/torch/checkpoints/alexnet-owt-4df8aa71.pth\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"780f56039c8d4e24b5b453253c760679","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=244418560.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["DACNN(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n","    (1): ReLU(inplace=True)\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU(inplace=True)\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU(inplace=True)\n","    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU(inplace=True)\n","    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n","  (classifier): Sequential(\n","    (0): Dropout(p=0.5, inplace=False)\n","    (1): Linear(in_features=9216, out_features=4096, bias=True)\n","    (2): ReLU(inplace=True)\n","    (3): Dropout(p=0.5, inplace=False)\n","    (4): Linear(in_features=4096, out_features=4096, bias=True)\n","    (5): ReLU(inplace=True)\n","    (6): Linear(in_features=4096, out_features=7, bias=True)\n","  )\n","  (domain_classifier): Sequential(\n","    (0): Linear(in_features=9216, out_features=4096, bias=True)\n","    (1): BatchNorm1d(4096, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Linear(in_features=4096, out_features=2, bias=True)\n","    (4): LogSoftmax()\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"KEyL3H_R4qCf","colab_type":"text"},"source":["#**Prepare Training**"]},{"cell_type":"code","metadata":{"id":"9sjq00G94tSc","colab_type":"code","colab":{}},"source":["# Define loss function\n","criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n","\n","# Choose parameters to optimize\n","# To access a different set of parameters, you have to access submodules of AlexNet\n","# (nn.Module objects, like AlexNet, implement the Composite Pattern)\n","# e.g.: parameters of the fully connected layers: net.classifier.parameters()\n","# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n","parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n","\n","# Define optimizer\n","# An optimizer updates the weights based on loss\n","# We use SGD with momentum\n","optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","\n","# Define scheduler\n","# A scheduler dynamically changes learning rate\n","# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vDSXXL6_C-dC","colab_type":"text"},"source":["#Training without adaptation"]},{"cell_type":"code","metadata":{"id":"BngAs2UnhnZv","colab_type":"code","outputId":"2a68d586-e8a2-42ea-ed34-27db7d894677","executionInfo":{"status":"ok","timestamp":1591798940612,"user_tz":-120,"elapsed":312497,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["net=net.to(DEVICE)\n","cudnn.benchmark"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"JzxXD_pKjkI3","colab_type":"code","outputId":"e6ff6628-8892-4b3e-ef4a-6f178e5bb7ec","executionInfo":{"status":"ok","timestamp":1591799166966,"user_tz":-120,"elapsed":538835,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","\n","actual_step=0;\n","num_corrects=0\n","\n","for epoch in range(NUM_EPOCHS):\n","  scheduler.step() \n","  \n","  for images, labels in  tqdm(train_dataloader):\n","\n","    \n","    images = images.to(DEVICE)\n","    labels = labels.to(DEVICE)\n","\n","    net.train() \n","\n","    # PyTorch, by default, accumulates gradients after each backward pass\n","    # We need to manually set the gradients to zero before starting a new iteration\n","    optimizer.zero_grad() # Zero-ing the gradients\n","\n","  \n","    outputs = net(images)\n","\n","    loss = criterion(outputs, labels)\n","\n","    # Log loss\n","    if actual_step % LOG_FREQUENCY == 0:\n","      print('Step {}, Loss {}'.format(actual_step, loss.item()))\n","\n","  \n","\n","    loss.backward() \n","\n","    optimizer.step() \n","\n","    actual_step += 1\n","    # Get predictions\n","    _, preds = torch.max(outputs.data, 1)\n","\n","    # Update Corrects\n","    num_corrects += torch.sum(preds == labels.data).data.item()\n","\n","  # Calculate Accuracy\n","  accuracy = num_corrects / float(len(train_dataset))\n","  print(\"Accuracy on training set = \"  + str(accuracy))\n","  num_corrects = 0"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","\r  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Step 0, Loss 2.4324557781219482\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.3502994011976048\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.41122186183929443\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.7502994011976047\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.8311377245508982\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.22147369384765625\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.8568862275449102\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.8670658682634731\n","Step 30, Loss 0.1223674863576889\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.8820359281437126\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.11551046371459961\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.8850299401197604\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.895808383233533\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:12,  3.21s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.10226358473300934\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.8904191616766467\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9\n","Step 60, Loss 0.06610885262489319\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9005988023952096\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 0.08327994495630264\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.907185628742515\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9041916167664671\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 0.042918264865875244\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.907185628742515\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9059880239520958\n","Step 90, Loss 0.06281545013189316\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9089820359281438\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.90s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 0.049250319600105286\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.911377245508982\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9089820359281438\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:13,  3.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 0.02567090466618538\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.907185628742515\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n","Step 120, Loss 0.05746140703558922\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9107784431137724\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.77s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 130, Loss 0.026426654309034348\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.19s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 140, Loss 0.03874946013092995\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9095808383233533\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n","Step 150, Loss 0.032164279371500015\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9119760479041916\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.89s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 160, Loss 0.02211327664554119\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9167664670658683\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 170, Loss 0.02422325685620308\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9083832335329342\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"UsHFI-GAJd69","colab_type":"text"},"source":["#**Test**"]},{"cell_type":"code","metadata":{"id":"EO3HV5pqJg1o","colab_type":"code","outputId":"0bf16728-9c98-42e5-ddd4-5b16c2a1e2ed","executionInfo":{"status":"ok","timestamp":1591799175784,"user_tz":-120,"elapsed":547635,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","net.train(False) # Set Network to evaluation mode\n","\n","running_corrects = 0\n","for images, labels in tqdm(test_dataloader):\n","  images = images.to(DEVICE)\n","  labels = labels.to(DEVICE)\n","\n","  # Forward Pass\n","  outputs = net(images)\n","\n","  # Get predictions\n","  _, preds = torch.max(outputs.data, 1)\n","\n","  # Update Corrects\n","  running_corrects += torch.sum(preds == labels.data).data.item()\n","\n","# Calculate Accuracy\n","accuracy = running_corrects / float(len(test_dataset))\n","\n","print('Test Accuracy: {}'.format(accuracy))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 8/8 [00:08<00:00,  1.11s/it]"],"name":"stderr"},{"output_type":"stream","text":["Test Accuracy: 0.47021484375\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"n9EyBU_Pkjzx","colab_type":"text"},"source":["#Train With Domain Adaptation"]},{"cell_type":"code","metadata":{"id":"Z5uWdqOWkpJ6","colab_type":"code","colab":{}},"source":["alpha=1\n","\n","net = DANNAlexnet(num_classes = 7)\n","net = net.to(DEVICE)\n","\n","class_loss = nn.CrossEntropyLoss() \n","domain_loss = nn.CrossEntropyLoss()\n","\n","parameters_to_optimize = net.parameters() \n","\n","optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"75dqws0il_AK","colab_type":"code","outputId":"67c2a228-288c-4869-9c63-de055c3ebe99","executionInfo":{"status":"ok","timestamp":1591799918145,"user_tz":-120,"elapsed":1289972,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["max_batches = max(len(train_dataloader), len(test_dataloader))\n","min_batches = min(len(train_dataloader), len(test_dataloader))#\n","net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","\n","cudnn.benchmark #function to optimize runtime by finding the best configuration for your hw, useful when input size \n","running_corrects = 0\n","current_step = 0\n","for epoch in range(NUM_EPOCHS):\n","  print(f'\\nEpoch {epoch+1:04d} / {NUM_EPOCHS:04d}', end='\\n=================\\n')\n","  scheduler.step() \n","  train_iterable = iter(train_dataloader)\n","  test_iterable = iter(test_dataloader)\n","  for batch in range(max_batches):\n","    net.train() # Sets module in training mode\n","    optimizer.zero_grad() # Zero-ing the gradients \n","    if( batch == min_batches):#\n","      train_iterable = iter(train_dataloader)#\n","\n","    images_source, labels_source = next(train_iterable)\n","    labels_domain = torch.zeros(len(images_source), dtype=torch.long)    \n","    \n","    images_source = images_source.to(DEVICE)\n","    labels_source = labels_source.to(DEVICE)\n","    labels_domain = labels_domain.to(DEVICE)\n","    \n","    class_output = net(images_source)\n","    domain_output = net(images_source, alpha)\n","    \n","\n","\n","    loss_s_label = class_loss(class_output, labels_source)\n","    loss_s_domain = domain_loss(domain_output, labels_domain)\n","    \n","\n","  \n","    targets, _ = next(test_iterable)\n","    target_domain = torch.ones(len(targets), dtype=torch.long)\n","\n"," \n","    targets = targets.to(DEVICE)\n","    target_domain = target_domain.to(DEVICE)\n","\n","    target_output = net(targets, alpha)\n","\n","\n","    loss_t_domain = domain_loss(target_output,target_domain)\n","\n","\n","    loss = loss_s_label + loss_s_domain + loss_t_domain\n","    loss.backward() \n","\n","    optimizer.step() \n","\n","    current_step += 1\n","\n","    print(f'[{batch+1}/{max_batches}] '\n","          f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '\n","          f't_domain_loss: {loss_t_domain.item():.4f} '\n","          )  \n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Epoch 0001 / 0030\n","=================\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[1/8] class_loss: 1.9753 s_domain_loss: 0.7616 t_domain_loss: 0.6761 \n","[2/8] class_loss: 1.7905 s_domain_loss: 0.7219 t_domain_loss: 0.7006 \n","[3/8] class_loss: 1.5045 s_domain_loss: 0.6889 t_domain_loss: 0.7369 \n","[4/8] class_loss: 1.2210 s_domain_loss: 0.6622 t_domain_loss: 0.7565 \n","[5/8] class_loss: 1.0798 s_domain_loss: 0.6637 t_domain_loss: 0.7511 \n","[6/8] class_loss: 1.0463 s_domain_loss: 0.6879 t_domain_loss: 0.7150 \n","[7/8] class_loss: 0.7232 s_domain_loss: 0.7178 t_domain_loss: 0.6848 \n","[8/8] class_loss: 0.6229 s_domain_loss: 0.7310 t_domain_loss: 0.6680 \n","\n","Epoch 0002 / 0030\n","=================\n","[1/8] class_loss: 0.5683 s_domain_loss: 0.7125 t_domain_loss: 0.6796 \n","[2/8] class_loss: 0.5145 s_domain_loss: 0.6891 t_domain_loss: 0.7012 \n","[3/8] class_loss: 0.3797 s_domain_loss: 0.6582 t_domain_loss: 0.7198 \n","[4/8] class_loss: 0.3414 s_domain_loss: 0.6552 t_domain_loss: 0.7267 \n","[5/8] class_loss: 0.3154 s_domain_loss: 0.6593 t_domain_loss: 0.7171 \n","[6/8] class_loss: 0.3035 s_domain_loss: 0.6844 t_domain_loss: 0.6954 \n","[7/8] class_loss: 0.3129 s_domain_loss: 0.6881 t_domain_loss: 0.6791 \n","[8/8] class_loss: 0.2072 s_domain_loss: 0.6942 t_domain_loss: 0.6708 \n","\n","Epoch 0003 / 0030\n","=================\n","[1/8] class_loss: 0.2372 s_domain_loss: 0.6812 t_domain_loss: 0.6865 \n","[2/8] class_loss: 0.2336 s_domain_loss: 0.6604 t_domain_loss: 0.7028 \n","[3/8] class_loss: 0.2133 s_domain_loss: 0.6386 t_domain_loss: 0.7116 \n","[4/8] class_loss: 0.1943 s_domain_loss: 0.6542 t_domain_loss: 0.7068 \n","[5/8] class_loss: 0.2097 s_domain_loss: 0.6631 t_domain_loss: 0.6910 \n","[6/8] class_loss: 0.2134 s_domain_loss: 0.6668 t_domain_loss: 0.6732 \n","[7/8] class_loss: 0.2609 s_domain_loss: 0.6828 t_domain_loss: 0.6648 \n","[8/8] class_loss: 0.1687 s_domain_loss: 0.6782 t_domain_loss: 0.6567 \n","\n","Epoch 0004 / 0030\n","=================\n","[1/8] class_loss: 0.1280 s_domain_loss: 0.6633 t_domain_loss: 0.6714 \n","[2/8] class_loss: 0.1825 s_domain_loss: 0.6495 t_domain_loss: 0.6834 \n","[3/8] class_loss: 0.1905 s_domain_loss: 0.6509 t_domain_loss: 0.6899 \n","[4/8] class_loss: 0.1541 s_domain_loss: 0.6363 t_domain_loss: 0.6909 \n","[5/8] class_loss: 0.1682 s_domain_loss: 0.6424 t_domain_loss: 0.6790 \n","[6/8] class_loss: 0.1727 s_domain_loss: 0.6543 t_domain_loss: 0.6598 \n","[7/8] class_loss: 0.1401 s_domain_loss: 0.6686 t_domain_loss: 0.6554 \n","[8/8] class_loss: 0.1417 s_domain_loss: 0.6528 t_domain_loss: 0.6411 \n","\n","Epoch 0005 / 0030\n","=================\n","[1/8] class_loss: 0.1765 s_domain_loss: 0.6594 t_domain_loss: 0.6520 \n","[2/8] class_loss: 0.1341 s_domain_loss: 0.6444 t_domain_loss: 0.6634 \n","[3/8] class_loss: 0.1269 s_domain_loss: 0.6220 t_domain_loss: 0.6744 \n","[4/8] class_loss: 0.1102 s_domain_loss: 0.6221 t_domain_loss: 0.6737 \n","[5/8] class_loss: 0.1398 s_domain_loss: 0.6231 t_domain_loss: 0.6615 \n","[6/8] class_loss: 0.1315 s_domain_loss: 0.6531 t_domain_loss: 0.6388 \n","[7/8] class_loss: 0.1408 s_domain_loss: 0.6465 t_domain_loss: 0.6466 \n","[8/8] class_loss: 0.1511 s_domain_loss: 0.6703 t_domain_loss: 0.6249 \n","\n","Epoch 0006 / 0030\n","=================\n","[1/8] class_loss: 0.0857 s_domain_loss: 0.6404 t_domain_loss: 0.6394 \n","[2/8] class_loss: 0.0848 s_domain_loss: 0.6305 t_domain_loss: 0.6542 \n","[3/8] class_loss: 0.0731 s_domain_loss: 0.5847 t_domain_loss: 0.6682 \n","[4/8] class_loss: 0.1377 s_domain_loss: 0.6069 t_domain_loss: 0.6577 \n","[5/8] class_loss: 0.1262 s_domain_loss: 0.6299 t_domain_loss: 0.6380 \n","[6/8] class_loss: 0.1164 s_domain_loss: 0.6689 t_domain_loss: 0.6185 \n","[7/8] class_loss: 0.1074 s_domain_loss: 0.6401 t_domain_loss: 0.6406 \n","[8/8] class_loss: 0.0950 s_domain_loss: 0.6196 t_domain_loss: 0.6283 \n","\n","Epoch 0007 / 0030\n","=================\n","[1/8] class_loss: 0.0750 s_domain_loss: 0.6030 t_domain_loss: 0.6386 \n","[2/8] class_loss: 0.1009 s_domain_loss: 0.6290 t_domain_loss: 0.6324 \n","[3/8] class_loss: 0.1445 s_domain_loss: 0.6189 t_domain_loss: 0.6347 \n","[4/8] class_loss: 0.0883 s_domain_loss: 0.6226 t_domain_loss: 0.6337 \n","[5/8] class_loss: 0.0894 s_domain_loss: 0.5965 t_domain_loss: 0.6380 \n","[6/8] class_loss: 0.0783 s_domain_loss: 0.6055 t_domain_loss: 0.6270 \n","[7/8] class_loss: 0.0898 s_domain_loss: 0.6451 t_domain_loss: 0.6361 \n","[8/8] class_loss: 0.0882 s_domain_loss: 0.6162 t_domain_loss: 0.6097 \n","\n","Epoch 0008 / 0030\n","=================\n","[1/8] class_loss: 0.0752 s_domain_loss: 0.6376 t_domain_loss: 0.6147 \n","[2/8] class_loss: 0.0774 s_domain_loss: 0.5897 t_domain_loss: 0.6234 \n","[3/8] class_loss: 0.0567 s_domain_loss: 0.5879 t_domain_loss: 0.6280 \n","[4/8] class_loss: 0.0637 s_domain_loss: 0.5904 t_domain_loss: 0.6220 \n","[5/8] class_loss: 0.0761 s_domain_loss: 0.5851 t_domain_loss: 0.6159 \n","[6/8] class_loss: 0.0759 s_domain_loss: 0.5964 t_domain_loss: 0.6009 \n","[7/8] class_loss: 0.0927 s_domain_loss: 0.5918 t_domain_loss: 0.6110 \n","[8/8] class_loss: 0.0663 s_domain_loss: 0.6341 t_domain_loss: 0.5783 \n","\n","Epoch 0009 / 0030\n","=================\n","[1/8] class_loss: 0.0707 s_domain_loss: 0.5928 t_domain_loss: 0.5908 \n","[2/8] class_loss: 0.0518 s_domain_loss: 0.6072 t_domain_loss: 0.6031 \n","[3/8] class_loss: 0.1019 s_domain_loss: 0.5628 t_domain_loss: 0.6252 \n","[4/8] class_loss: 0.0812 s_domain_loss: 0.5536 t_domain_loss: 0.6244 \n","[5/8] class_loss: 0.0785 s_domain_loss: 0.5815 t_domain_loss: 0.6088 \n","[6/8] class_loss: 0.0544 s_domain_loss: 0.6120 t_domain_loss: 0.5830 \n","[7/8] class_loss: 0.0561 s_domain_loss: 0.5848 t_domain_loss: 0.5949 \n","[8/8] class_loss: 0.0807 s_domain_loss: 0.6133 t_domain_loss: 0.5599 \n","\n","Epoch 0010 / 0030\n","=================\n","[1/8] class_loss: 0.0596 s_domain_loss: 0.6039 t_domain_loss: 0.5691 \n","[2/8] class_loss: 0.0894 s_domain_loss: 0.5819 t_domain_loss: 0.5884 \n","[3/8] class_loss: 0.0697 s_domain_loss: 0.5366 t_domain_loss: 0.6125 \n","[4/8] class_loss: 0.0858 s_domain_loss: 0.5748 t_domain_loss: 0.6072 \n","[5/8] class_loss: 0.0503 s_domain_loss: 0.5426 t_domain_loss: 0.5981 \n","[6/8] class_loss: 0.0793 s_domain_loss: 0.5808 t_domain_loss: 0.5720 \n","[7/8] class_loss: 0.0699 s_domain_loss: 0.6108 t_domain_loss: 0.5757 \n","[8/8] class_loss: 0.0386 s_domain_loss: 0.5923 t_domain_loss: 0.5454 \n","\n","Epoch 0011 / 0030\n","=================\n","[1/8] class_loss: 0.0896 s_domain_loss: 0.5893 t_domain_loss: 0.5577 \n","[2/8] class_loss: 0.0407 s_domain_loss: 0.5810 t_domain_loss: 0.5773 \n","[3/8] class_loss: 0.0542 s_domain_loss: 0.5194 t_domain_loss: 0.6049 \n","[4/8] class_loss: 0.0666 s_domain_loss: 0.4945 t_domain_loss: 0.6022 \n","[5/8] class_loss: 0.0492 s_domain_loss: 0.5424 t_domain_loss: 0.5713 \n","[6/8] class_loss: 0.0823 s_domain_loss: 0.5943 t_domain_loss: 0.5350 \n","[7/8] class_loss: 0.0618 s_domain_loss: 0.6076 t_domain_loss: 0.5475 \n","[8/8] class_loss: 0.0680 s_domain_loss: 0.5761 t_domain_loss: 0.5313 \n","\n","Epoch 0012 / 0030\n","=================\n","[1/8] class_loss: 0.0774 s_domain_loss: 0.5467 t_domain_loss: 0.5495 \n","[2/8] class_loss: 0.0531 s_domain_loss: 0.5379 t_domain_loss: 0.5640 \n","[3/8] class_loss: 0.0426 s_domain_loss: 0.5042 t_domain_loss: 0.5772 \n","[4/8] class_loss: 0.0686 s_domain_loss: 0.5347 t_domain_loss: 0.5572 \n","[5/8] class_loss: 0.0569 s_domain_loss: 0.5281 t_domain_loss: 0.5417 \n","[6/8] class_loss: 0.0499 s_domain_loss: 0.6068 t_domain_loss: 0.5239 \n","[7/8] class_loss: 0.0687 s_domain_loss: 0.5629 t_domain_loss: 0.5573 \n","[8/8] class_loss: 0.0570 s_domain_loss: 0.5475 t_domain_loss: 0.5402 \n","\n","Epoch 0013 / 0030\n","=================\n","[1/8] class_loss: 0.0532 s_domain_loss: 0.5168 t_domain_loss: 0.5559 \n","[2/8] class_loss: 0.0704 s_domain_loss: 0.5176 t_domain_loss: 0.5530 \n","[3/8] class_loss: 0.0680 s_domain_loss: 0.4930 t_domain_loss: 0.5443 \n","[4/8] class_loss: 0.0466 s_domain_loss: 0.5865 t_domain_loss: 0.5119 \n","[5/8] class_loss: 0.0615 s_domain_loss: 0.5395 t_domain_loss: 0.5139 \n","[6/8] class_loss: 0.0475 s_domain_loss: 0.5605 t_domain_loss: 0.5233 \n","[7/8] class_loss: 0.0442 s_domain_loss: 0.5279 t_domain_loss: 0.5701 \n","[8/8] class_loss: 0.0639 s_domain_loss: 0.4807 t_domain_loss: 0.5470 \n","\n","Epoch 0014 / 0030\n","=================\n","[1/8] class_loss: 0.0749 s_domain_loss: 0.4877 t_domain_loss: 0.5347 \n","[2/8] class_loss: 0.0404 s_domain_loss: 0.5600 t_domain_loss: 0.4998 \n","[3/8] class_loss: 0.0464 s_domain_loss: 0.5420 t_domain_loss: 0.4918 \n","[4/8] class_loss: 0.0704 s_domain_loss: 0.5835 t_domain_loss: 0.4978 \n","[5/8] class_loss: 0.0521 s_domain_loss: 0.4917 t_domain_loss: 0.5340 \n","[6/8] class_loss: 0.0712 s_domain_loss: 0.4758 t_domain_loss: 0.5505 \n","[7/8] class_loss: 0.0478 s_domain_loss: 0.4779 t_domain_loss: 0.5761 \n","[8/8] class_loss: 0.0681 s_domain_loss: 0.4942 t_domain_loss: 0.5087 \n","\n","Epoch 0015 / 0030\n","=================\n","[1/8] class_loss: 0.0429 s_domain_loss: 0.5619 t_domain_loss: 0.4747 \n","[2/8] class_loss: 0.0324 s_domain_loss: 0.5061 t_domain_loss: 0.4707 \n","[3/8] class_loss: 0.0706 s_domain_loss: 0.4958 t_domain_loss: 0.4842 \n","[4/8] class_loss: 0.0404 s_domain_loss: 0.5501 t_domain_loss: 0.4901 \n","[5/8] class_loss: 0.0468 s_domain_loss: 0.4466 t_domain_loss: 0.5202 \n","[6/8] class_loss: 0.0336 s_domain_loss: 0.4537 t_domain_loss: 0.5194 \n","[7/8] class_loss: 0.0412 s_domain_loss: 0.5829 t_domain_loss: 0.5285 \n","[8/8] class_loss: 0.0375 s_domain_loss: 0.4687 t_domain_loss: 0.4909 \n","\n","Epoch 0016 / 0030\n","=================\n","[1/8] class_loss: 0.0437 s_domain_loss: 0.5240 t_domain_loss: 0.4774 \n","[2/8] class_loss: 0.0310 s_domain_loss: 0.4856 t_domain_loss: 0.4728 \n","[3/8] class_loss: 0.0399 s_domain_loss: 0.4302 t_domain_loss: 0.4811 \n","[4/8] class_loss: 0.0335 s_domain_loss: 0.5087 t_domain_loss: 0.4616 \n","[5/8] class_loss: 0.0773 s_domain_loss: 0.4743 t_domain_loss: 0.4669 \n","[6/8] class_loss: 0.0543 s_domain_loss: 0.5329 t_domain_loss: 0.4709 \n","[7/8] class_loss: 0.0605 s_domain_loss: 0.4237 t_domain_loss: 0.5190 \n","[8/8] class_loss: 0.0526 s_domain_loss: 0.4753 t_domain_loss: 0.4765 \n","\n","Epoch 0017 / 0030\n","=================\n","[1/8] class_loss: 0.0590 s_domain_loss: 0.4127 t_domain_loss: 0.4709 \n","[2/8] class_loss: 0.0388 s_domain_loss: 0.4568 t_domain_loss: 0.4415 \n","[3/8] class_loss: 0.0611 s_domain_loss: 0.5689 t_domain_loss: 0.4230 \n","[4/8] class_loss: 0.0497 s_domain_loss: 0.4832 t_domain_loss: 0.4413 \n","[5/8] class_loss: 0.0393 s_domain_loss: 0.4233 t_domain_loss: 0.4802 \n","[6/8] class_loss: 0.0338 s_domain_loss: 0.4337 t_domain_loss: 0.4919 \n","[7/8] class_loss: 0.0525 s_domain_loss: 0.4017 t_domain_loss: 0.5212 \n","[8/8] class_loss: 0.0203 s_domain_loss: 0.4392 t_domain_loss: 0.4393 \n","\n","Epoch 0018 / 0030\n","=================\n","[1/8] class_loss: 0.0416 s_domain_loss: 0.4722 t_domain_loss: 0.4051 \n","[2/8] class_loss: 0.0361 s_domain_loss: 0.4993 t_domain_loss: 0.3826 \n","[3/8] class_loss: 0.0492 s_domain_loss: 0.5018 t_domain_loss: 0.3994 \n","[4/8] class_loss: 0.0465 s_domain_loss: 0.4043 t_domain_loss: 0.4374 \n","[5/8] class_loss: 0.0391 s_domain_loss: 0.4219 t_domain_loss: 0.4718 \n","[6/8] class_loss: 0.0341 s_domain_loss: 0.4091 t_domain_loss: 0.4823 \n","[7/8] class_loss: 0.0355 s_domain_loss: 0.4167 t_domain_loss: 0.5037 \n","[8/8] class_loss: 0.0529 s_domain_loss: 0.4049 t_domain_loss: 0.4322 \n","\n","Epoch 0019 / 0030\n","=================\n","[1/8] class_loss: 0.0462 s_domain_loss: 0.4472 t_domain_loss: 0.4048 \n","[2/8] class_loss: 0.0323 s_domain_loss: 0.4456 t_domain_loss: 0.3766 \n","[3/8] class_loss: 0.0394 s_domain_loss: 0.5097 t_domain_loss: 0.3796 \n","[4/8] class_loss: 0.0514 s_domain_loss: 0.4333 t_domain_loss: 0.4070 \n","[5/8] class_loss: 0.0290 s_domain_loss: 0.3529 t_domain_loss: 0.4475 \n","[6/8] class_loss: 0.0310 s_domain_loss: 0.3726 t_domain_loss: 0.4448 \n","[7/8] class_loss: 0.0364 s_domain_loss: 0.4005 t_domain_loss: 0.4578 \n","[8/8] class_loss: 0.0354 s_domain_loss: 0.4480 t_domain_loss: 0.3888 \n","\n","Epoch 0020 / 0030\n","=================\n","[1/8] class_loss: 0.0422 s_domain_loss: 0.4268 t_domain_loss: 0.3911 \n","[2/8] class_loss: 0.0448 s_domain_loss: 0.4213 t_domain_loss: 0.3834 \n","[3/8] class_loss: 0.0543 s_domain_loss: 0.3922 t_domain_loss: 0.3905 \n","[4/8] class_loss: 0.0376 s_domain_loss: 0.4383 t_domain_loss: 0.3864 \n","[5/8] class_loss: 0.0299 s_domain_loss: 0.5119 t_domain_loss: 0.3915 \n","[6/8] class_loss: 0.0334 s_domain_loss: 0.3780 t_domain_loss: 0.3870 \n","[7/8] class_loss: 0.0318 s_domain_loss: 0.4084 t_domain_loss: 0.4216 \n","[8/8] class_loss: 0.0318 s_domain_loss: 0.4116 t_domain_loss: 0.3894 \n","\n","Epoch 0021 / 0030\n","=================\n","[1/8] class_loss: 0.0370 s_domain_loss: 0.3704 t_domain_loss: 0.4059 \n","[2/8] class_loss: 0.0262 s_domain_loss: 0.4136 t_domain_loss: 0.3972 \n","[3/8] class_loss: 0.0256 s_domain_loss: 0.3530 t_domain_loss: 0.4029 \n","[4/8] class_loss: 0.0539 s_domain_loss: 0.4097 t_domain_loss: 0.3971 \n","[5/8] class_loss: 0.0424 s_domain_loss: 0.4185 t_domain_loss: 0.4008 \n","[6/8] class_loss: 0.0556 s_domain_loss: 0.4318 t_domain_loss: 0.3934 \n","[7/8] class_loss: 0.0333 s_domain_loss: 0.4109 t_domain_loss: 0.4293 \n","[8/8] class_loss: 0.0320 s_domain_loss: 0.4744 t_domain_loss: 0.3947 \n","\n","Epoch 0022 / 0030\n","=================\n","[1/8] class_loss: 0.0483 s_domain_loss: 0.3772 t_domain_loss: 0.4096 \n","[2/8] class_loss: 0.0416 s_domain_loss: 0.4818 t_domain_loss: 0.4021 \n","[3/8] class_loss: 0.0358 s_domain_loss: 0.3512 t_domain_loss: 0.4106 \n","[4/8] class_loss: 0.0275 s_domain_loss: 0.3996 t_domain_loss: 0.4071 \n","[5/8] class_loss: 0.0368 s_domain_loss: 0.3536 t_domain_loss: 0.4133 \n","[6/8] class_loss: 0.0548 s_domain_loss: 0.3369 t_domain_loss: 0.4042 \n","[7/8] class_loss: 0.0394 s_domain_loss: 0.4309 t_domain_loss: 0.4380 \n","[8/8] class_loss: 0.0319 s_domain_loss: 0.3736 t_domain_loss: 0.3978 \n","\n","Epoch 0023 / 0030\n","=================\n","[1/8] class_loss: 0.0302 s_domain_loss: 0.3367 t_domain_loss: 0.4063 \n","[2/8] class_loss: 0.0254 s_domain_loss: 0.3607 t_domain_loss: 0.3926 \n","[3/8] class_loss: 0.0613 s_domain_loss: 0.4123 t_domain_loss: 0.3918 \n","[4/8] class_loss: 0.0395 s_domain_loss: 0.3659 t_domain_loss: 0.3831 \n","[5/8] class_loss: 0.0477 s_domain_loss: 0.5000 t_domain_loss: 0.3834 \n","[6/8] class_loss: 0.0290 s_domain_loss: 0.3756 t_domain_loss: 0.3741 \n","[7/8] class_loss: 0.0347 s_domain_loss: 0.3972 t_domain_loss: 0.4083 \n","[8/8] class_loss: 0.0296 s_domain_loss: 0.3946 t_domain_loss: 0.3717 \n","\n","Epoch 0024 / 0030\n","=================\n","[1/8] class_loss: 0.0439 s_domain_loss: 0.4311 t_domain_loss: 0.3824 \n","[2/8] class_loss: 0.0308 s_domain_loss: 0.3584 t_domain_loss: 0.3744 \n","[3/8] class_loss: 0.0480 s_domain_loss: 0.4071 t_domain_loss: 0.3783 \n","[4/8] class_loss: 0.0255 s_domain_loss: 0.3844 t_domain_loss: 0.3749 \n","[5/8] class_loss: 0.0287 s_domain_loss: 0.4063 t_domain_loss: 0.3798 \n","[6/8] class_loss: 0.0368 s_domain_loss: 0.4013 t_domain_loss: 0.3725 \n","[7/8] class_loss: 0.0380 s_domain_loss: 0.3743 t_domain_loss: 0.4092 \n","[8/8] class_loss: 0.0285 s_domain_loss: 0.4756 t_domain_loss: 0.3744 \n","\n","Epoch 0025 / 0030\n","=================\n","[1/8] class_loss: 0.0515 s_domain_loss: 0.3992 t_domain_loss: 0.3896 \n","[2/8] class_loss: 0.0341 s_domain_loss: 0.4230 t_domain_loss: 0.3840 \n","[3/8] class_loss: 0.0395 s_domain_loss: 0.4093 t_domain_loss: 0.3921 \n","[4/8] class_loss: 0.0415 s_domain_loss: 0.3470 t_domain_loss: 0.3916 \n","[5/8] class_loss: 0.0265 s_domain_loss: 0.3768 t_domain_loss: 0.3986 \n","[6/8] class_loss: 0.0252 s_domain_loss: 0.3721 t_domain_loss: 0.3917 \n","[7/8] class_loss: 0.0535 s_domain_loss: 0.3600 t_domain_loss: 0.4284 \n","[8/8] class_loss: 0.0284 s_domain_loss: 0.3632 t_domain_loss: 0.3895 \n","\n","Epoch 0026 / 0030\n","=================\n","[1/8] class_loss: 0.0184 s_domain_loss: 0.3277 t_domain_loss: 0.4004 \n","[2/8] class_loss: 0.0378 s_domain_loss: 0.4199 t_domain_loss: 0.3877 \n","[3/8] class_loss: 0.0338 s_domain_loss: 0.3913 t_domain_loss: 0.3891 \n","[4/8] class_loss: 0.0453 s_domain_loss: 0.4096 t_domain_loss: 0.3824 \n","[5/8] class_loss: 0.0272 s_domain_loss: 0.3596 t_domain_loss: 0.3858 \n","[6/8] class_loss: 0.0359 s_domain_loss: 0.3625 t_domain_loss: 0.3755 \n","[7/8] class_loss: 0.0466 s_domain_loss: 0.3497 t_domain_loss: 0.4081 \n","[8/8] class_loss: 0.0486 s_domain_loss: 0.4625 t_domain_loss: 0.3683 \n","\n","Epoch 0027 / 0030\n","=================\n","[1/8] class_loss: 0.0410 s_domain_loss: 0.4000 t_domain_loss: 0.3799 \n","[2/8] class_loss: 0.0546 s_domain_loss: 0.3874 t_domain_loss: 0.3708 \n","[3/8] class_loss: 0.0327 s_domain_loss: 0.3548 t_domain_loss: 0.3746 \n","[4/8] class_loss: 0.0507 s_domain_loss: 0.3992 t_domain_loss: 0.3693 \n","[5/8] class_loss: 0.0465 s_domain_loss: 0.4246 t_domain_loss: 0.3739 \n","[6/8] class_loss: 0.0402 s_domain_loss: 0.3871 t_domain_loss: 0.3669 \n","[7/8] class_loss: 0.0413 s_domain_loss: 0.3940 t_domain_loss: 0.4036 \n","[8/8] class_loss: 0.0371 s_domain_loss: 0.3480 t_domain_loss: 0.3690 \n","\n","Epoch 0028 / 0030\n","=================\n","[1/8] class_loss: 0.0320 s_domain_loss: 0.3559 t_domain_loss: 0.3833 \n","[2/8] class_loss: 0.0524 s_domain_loss: 0.3714 t_domain_loss: 0.3737 \n","[3/8] class_loss: 0.0338 s_domain_loss: 0.3830 t_domain_loss: 0.3774 \n","[4/8] class_loss: 0.0500 s_domain_loss: 0.3938 t_domain_loss: 0.3729 \n","[5/8] class_loss: 0.0509 s_domain_loss: 0.4898 t_domain_loss: 0.3782 \n","[6/8] class_loss: 0.0323 s_domain_loss: 0.3427 t_domain_loss: 0.3726 \n","[7/8] class_loss: 0.0309 s_domain_loss: 0.3534 t_domain_loss: 0.4096 \n","[8/8] class_loss: 0.0342 s_domain_loss: 0.3815 t_domain_loss: 0.3718 \n","\n","Epoch 0029 / 0030\n","=================\n","[1/8] class_loss: 0.0273 s_domain_loss: 0.3613 t_domain_loss: 0.3853 \n","[2/8] class_loss: 0.0268 s_domain_loss: 0.3998 t_domain_loss: 0.3752 \n","[3/8] class_loss: 0.0313 s_domain_loss: 0.4542 t_domain_loss: 0.3794 \n","[4/8] class_loss: 0.0192 s_domain_loss: 0.3326 t_domain_loss: 0.3764 \n","[5/8] class_loss: 0.0564 s_domain_loss: 0.3652 t_domain_loss: 0.3816 \n","[6/8] class_loss: 0.0302 s_domain_loss: 0.3610 t_domain_loss: 0.3726 \n","[7/8] class_loss: 0.0304 s_domain_loss: 0.3542 t_domain_loss: 0.4082 \n","[8/8] class_loss: 0.0395 s_domain_loss: 0.3468 t_domain_loss: 0.3683 \n","\n","Epoch 0030 / 0030\n","=================\n","[1/8] class_loss: 0.0319 s_domain_loss: 0.3679 t_domain_loss: 0.3793 \n","[2/8] class_loss: 0.0244 s_domain_loss: 0.3439 t_domain_loss: 0.3667 \n","[3/8] class_loss: 0.0466 s_domain_loss: 0.4868 t_domain_loss: 0.3674 \n","[4/8] class_loss: 0.0333 s_domain_loss: 0.3770 t_domain_loss: 0.3628 \n","[5/8] class_loss: 0.0354 s_domain_loss: 0.3675 t_domain_loss: 0.3681 \n","[6/8] class_loss: 0.0321 s_domain_loss: 0.3452 t_domain_loss: 0.3594 \n","[7/8] class_loss: 0.0373 s_domain_loss: 0.4300 t_domain_loss: 0.3944 \n","[8/8] class_loss: 0.0554 s_domain_loss: 0.4067 t_domain_loss: 0.3582 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ohGaT5xNp3Ol","colab_type":"text"},"source":["#Test"]},{"cell_type":"code","metadata":{"id":"RF3htREKp25D","colab_type":"code","outputId":"1260bf86-2713-49d4-d738-b081edfeb6da","executionInfo":{"status":"ok","timestamp":1591799927372,"user_tz":-120,"elapsed":1299184,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["\n","net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","net.train(False) # Set Network to evaluation mode\n","\n","running_corrects = 0\n","for images, labels in tqdm(test_dataloader):\n","  images = images.to(DEVICE)\n","  labels = labels.to(DEVICE)\n","\n","  # Forward Pass\n","  outputs = net(images)\n","\n","  loss = criterion(outputs, labels)\n","\n","  # Get predictions\n","  _, preds = torch.max(outputs.data, 1)\n","\n","  # Update Corrects\n","  running_corrects += torch.sum(preds == labels.data).data.item()\n","\n","# Calculate Accuracy\n","accuracy = running_corrects / float(len(test_dataset))\n","\n","print('Test Accuracy: {}'.format(accuracy))\n","print('Loss is: ' + str(loss.item()))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 8/8 [00:09<00:00,  1.17s/it]"],"name":"stderr"},{"output_type":"stream","text":["Test Accuracy: 0.4580078125\n","Loss is: 8.91762638092041\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"SGkANpUW2ope","colab_type":"text"},"source":["#(EXTRA) Cross Domain Validation"]},{"cell_type":"markdown","metadata":{"id":"YWrY7jHVREbE","colab_type":"text"},"source":["##Preparing new dataset"]},{"cell_type":"code","metadata":{"id":"1Zlu63WK2t-H","colab_type":"code","outputId":"2c1ebc9f-6d83-416c-b151-d4d55a63e6ef","executionInfo":{"status":"ok","timestamp":1591799927379,"user_tz":-120,"elapsed":1299177,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["\n","# first validation set --> Cartoon\n","cartoon_dataset = torchvision.datasets.ImageFolder(DATA_DIR + \"/cartoon\", transform=eval_transform)\n","\n","# second validation set --> Sketch\n","sketch_dataset = torchvision.datasets.ImageFolder(DATA_DIR + \"/sketch\", transform=eval_transform)\n","\n","\n","print('Cartoon Dataset: {}'.format(len(cartoon_dataset)))\n","print('Sketch Dataset: {}'.format(len(sketch_dataset)))\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cartoon Dataset: 2344\n","Sketch Dataset: 3929\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hq0NkN6ATjVk","colab_type":"text"},"source":["##Prepare Dataloader"]},{"cell_type":"code","metadata":{"id":"m6uS3KHdTizw","colab_type":"code","colab":{}},"source":["# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n","#photos\n","cartoon_dataloader = DataLoader(cartoon_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4) \n","# sketch\n","sketch_dataloader = DataLoader(sketch_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yDayPo3-UB-e","colab_type":"text"},"source":["##Grid search on on photo to cartoon and sketch without domain adaptation"]},{"cell_type":"markdown","metadata":{"id":"lbSMkmN-8qbf","colab_type":"text"},"source":["###Validation on cartoon"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"lDOiB3m28ov5","colab":{}},"source":["def valOnCartoon():\n","    #net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","    net.train(False) # Set Network to evaluation mode\n","\n","    running_corrects = 0\n","    for images, labels in tqdm(cartoon_dataloader):\n","      images = images.to(DEVICE)\n","      labels = labels.to(DEVICE)\n","\n","      # Forward Pass\n","      outputs = net(images)\n","\n","      # Get predictions\n","      _, preds = torch.max(outputs.data, 1)\n","\n","      # Update Corrects\n","      running_corrects += torch.sum(preds == labels.data).data.item()\n","\n","    # Calculate Accuracy\n","    accuracy = running_corrects / float(len(test_dataset))\n","    #Calculate Loss\n","    loss = criterion(outputs, labels)\n","\n","    print('Validation Accuracy on Cartoon: {}'.format(accuracy))\n","    return (accuracy, loss.item())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"a0e6d72d-9d4a-4b44-b44b-ae37c8e807ed","executionInfo":{"status":"ok","timestamp":1591801390144,"user_tz":-120,"elapsed":2761918,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"id":"Wcg3WGeUFMFP","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["max_val_accuracy=0\n","min_val_loss=100\n","best_LR=0\n","best_epoch_num=0\n","for lrate in Learning_rates:\n","  \n","  for epochs in num_epochs:\n","      print(\"hyperparameters are: LR={} and NUM_EPOCHS = {}\".format(lrate,epochs))\n","      \n","      # Define loss function\n","      criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n","\n","      # Choose parameters to optimize\n","      # To access a different set of parameters, you have to access submodules of AlexNet\n","      # (nn.Module objects, like AlexNet, implement the Composite Pattern)\n","      # e.g.: parameters of the fully connected layers: net.classifier.parameters()\n","      # e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n","      parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n","\n","      # Define optimizer\n","      # An optimizer updates the weights based on loss\n","      # We use SGD with momentum\n","      optimizer = optim.SGD(parameters_to_optimize, lr=lrate, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","\n","      # Define scheduler\n","      # A scheduler dynamically changes learning rate\n","      # The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n","      scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n","      net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","      cudnn.benchmark\n","      \n","      actual_step=0;\n","      num_corrects=0\n","\n","\n","\n","      for epoch in range(epochs):\n","        scheduler.step() \n","        \n","        for images, labels in  tqdm(train_dataloader):\n","\n","          \n","          images = images.to(DEVICE)\n","          labels = labels.to(DEVICE)\n","\n","          net.train() \n","\n","          # PyTorch, by default, accumulates gradients after each backward pass\n","          # We need to manually set the gradients to zero before starting a new iteration\n","          optimizer.zero_grad() # Zero-ing the gradients\n","\n","        \n","          outputs = net(images)\n","\n","          loss = criterion(outputs, labels)\n","\n","          # Log loss\n","          if actual_step % LOG_FREQUENCY == 0:\n","            print('Step {}, Loss {}'.format(actual_step, loss.item()))\n","\n","        \n","\n","          loss.backward() \n","\n","          optimizer.step() \n","\n","          actual_step += 1\n","          # Get predictions\n","          _, preds = torch.max(outputs.data, 1)\n","\n","          # Update Corrects\n","          num_corrects += torch.sum(preds == labels.data).data.item()\n","\n","        # Calculate Accuracy\n","        accuracy = num_corrects / float(len(train_dataset))\n","\n","        print(\"Accuracy on training set = \"  + str(accuracy))\n","\n","        \n","\n","        \n","        num_corrects = 0\n","\n","      \n","      params= valOnCartoon()\n","      val_accuracy=params[0]\n","      val_loss=params[1]\n","      if val_loss<min_val_loss:\n","        max_val_accuracy=val_accuracy\n","        min_val_loss=val_loss\n","        \n","        best_LR= lrate\n","        best_epoch_num=epochs\n","        \n","      \n","      if val_loss==min_val_loss:\n","        if val_accuracy>max_val_accuracy:\n","          max_val_accuracy=val_accuracy\n","          min_val_loss=val_loss\n","          \n","          best_LR= lrate\n","          best_epoch_num=epochs  \n","            \n","\n","\n","print (\"best hyperparemeters for validation on cartoon are : LR={}, NUM_EPOCHS= {} having highest validation accuracy = {} and minimum validation loss ={}\".format(best_LR, best_epoch_num,max_val_accuracy,min_val_loss))\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["hyperparameters are: LR=1e-05 and NUM_EPOCHS = 10\n","Step 0, Loss 0.04220133274793625\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.81s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.029134873300790787\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9119760479041916\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.04007086902856827\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9089820359281438\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9119760479041916\n","Step 30, Loss 0.026668664067983627\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.93s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.048981957137584686\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.911377245508982\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.03861016780138016\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9119760479041916\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.911377245508982\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.2685546875\n","hyperparameters are: LR=1e-05 and NUM_EPOCHS = 20\n","Step 0, Loss 0.02707124687731266\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9101796407185628\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.03664877265691757\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.911377245508982\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.40s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.0349898636341095\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9107784431137724\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n","Step 30, Loss 0.018974756821990013\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.99s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.031197896227240562\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.041047513484954834\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9107784431137724\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n","Step 60, Loss 0.04216097295284271\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.90s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 0.028016995638608932\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.911377245508982\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 0.03802359849214554\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.911377245508982\n","Step 90, Loss 0.04623577743768692\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.89s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 0.03975626826286316\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 0.02879166603088379\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.911377245508982\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.2666015625\n","hyperparameters are: LR=1e-05 and NUM_EPOCHS = 30\n","Step 0, Loss 0.019589345902204514\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.020155197009444237\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.031446926295757294\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n","Step 30, Loss 0.033890072256326675\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.01574266515672207\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.034547314047813416\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9101796407185628\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n","Step 60, Loss 0.025107532739639282\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.911377245508982\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 0.04177460819482803\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9107784431137724\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9107784431137724\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:13,  3.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 0.029381006956100464\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9107784431137724\n","Step 90, Loss 0.016843561083078384\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.81s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 0.03251408785581589\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.30s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 0.03125936537981033\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9101796407185628\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9173652694610779\n","Step 120, Loss 0.03808703273534775\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.95s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 130, Loss 0.0420219749212265\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9161676646706587\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:13,  3.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 140, Loss 0.0306828785687685\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n","Step 150, Loss 0.04093019291758537\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9101796407185628\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.90s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 160, Loss 0.03314700722694397\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9155688622754491\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 170, Loss 0.029829885810613632\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9095808383233533\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9107784431137724\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.26513671875\n","hyperparameters are: LR=0.0001 and NUM_EPOCHS = 10\n","Step 0, Loss 0.048704102635383606\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.020481787621974945\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:13,  3.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.027314981445670128\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n","Step 30, Loss 0.02636941336095333\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.025294605642557144\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9155688622754491\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.029165076091885567\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9101796407185628\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9119760479041916\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.2587890625\n","hyperparameters are: LR=0.0001 and NUM_EPOCHS = 20\n","Step 0, Loss 0.03236570209264755\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9107784431137724\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.90s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.021317703649401665\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9155688622754491\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.027861740440130234\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9161676646706587\n","Step 30, Loss 0.036561962217092514\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.911377245508982\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.90s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.023828336969017982\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.018673716112971306\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9155688622754491\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n","Step 60, Loss 0.02320180833339691\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9095808383233533\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.96s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 0.03600715473294258\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 0.024555815383791924\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n","Step 90, Loss 0.034280192106962204\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.96s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 0.013603050261735916\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9167664670658683\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.40s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 0.019577549770474434\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.918562874251497\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.25048828125\n","hyperparameters are: LR=0.0001 and NUM_EPOCHS = 30\n","Step 0, Loss 0.020373113453388214\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9155688622754491\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.018465114757418633\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9179640718562875\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9137724550898204\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.04337442293763161\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9161676646706587\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n","Step 30, Loss 0.025023827329277992\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9155688622754491\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.95s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.018833694979548454\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9179640718562875\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9179640718562875\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.019145147874951363\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9167664670658683\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9155688622754491\n","Step 60, Loss 0.026306254789233208\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9131736526946108\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.95s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 0.0295003280043602\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9161676646706587\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9155688622754491\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:14,  3.67s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 0.016328858211636543\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:08<00:00,  1.34s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9161676646706587\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9155688622754491\n","Step 90, Loss 0.02723921835422516\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 0.015050016343593597\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9191616766467066\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:14,  3.52s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 0.018139662221074104\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n","Step 120, Loss 0.01727217063307762\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9167664670658683\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.89s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 130, Loss 0.02445071190595627\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 140, Loss 0.029852882027626038\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9167664670658683\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9161676646706587\n","Step 150, Loss 0.03145825117826462\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 160, Loss 0.020865820348262787\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9179640718562875\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 170, Loss 0.04800257086753845\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9155688622754491\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.00it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.2509765625\n","hyperparameters are: LR=0.01 and NUM_EPOCHS = 10\n","Step 0, Loss 0.023687122389674187\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.03362096846103668\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.911377245508982\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9029940119760479\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.06594167649745941\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.8976047904191616\n","Step 30, Loss 0.028810925781726837\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9125748502994012\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.92s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.012457930482923985\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9143712574850299\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.010724125429987907\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9149700598802395\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9173652694610779\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.27880859375\n","hyperparameters are: LR=0.01 and NUM_EPOCHS = 20\n","Step 0, Loss 0.029877785593271255\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9161676646706587\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.91s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.008023394271731377\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9191616766467066\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.004630057141184807\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9191616766467066\n","Step 30, Loss 0.0046012792736291885\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9191616766467066\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.96s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.001000950112938881\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.00043743662536144257\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9191616766467066\n","Step 60, Loss 0.0009987317025661469\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.94s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 0.0003395732492208481\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9191616766467066\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.32s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 0.00042840465903282166\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 90, Loss 0.00015553459525108337\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.91s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 0.00035055726766586304\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.31s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.45s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 0.00053379125893116\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.02it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.259765625\n","hyperparameters are: LR=0.01 and NUM_EPOCHS = 30\n","Step 0, Loss 0.0005932562053203583\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.00024341419339179993\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.0008824560791254044\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 30, Loss 0.00023676268756389618\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.86s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.0004432331770658493\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.000873057171702385\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 60, Loss 0.0004027988761663437\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.89s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 0.00017995946109294891\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.39s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 6.980076432228088e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 90, Loss 0.0005241557955741882\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.78s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 0.00020664557814598083\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 0.00011115893721580505\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 120, Loss 0.0001210533082485199\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.93s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 130, Loss 7.786601781845093e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:13,  3.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 140, Loss 0.00025463663041591644\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 150, Loss 0.0003766994923353195\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.89s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 160, Loss 9.199418127536774e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 170, Loss 0.0007855463773012161\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.04it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.28271484375\n","best hyperparemeters for validation on cartoon are : LR=1e-05, NUM_EPOCHS= 10 having highest validation accuracy = 0.2685546875 and minimum validation loss =7.355759620666504\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"5OpFciJo_6tf","colab_type":"text"},"source":["###Validation on Sketch"]},{"cell_type":"code","metadata":{"id":"yoCyc1vQACKC","colab_type":"code","colab":{}},"source":["def valOnSketch():\n","   # net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","    net.train(False) # Set Network to evaluation mode\n","\n","    running_corrects = 0\n","    for images, labels in tqdm(sketch_dataloader):\n","      images = images.to(DEVICE)\n","      labels = labels.to(DEVICE)\n","\n","      # Forward Pass\n","      outputs = net(images)\n","\n","      # Get predictions\n","      _, preds = torch.max(outputs.data, 1)\n","\n","      # Update Corrects\n","      running_corrects += torch.sum(preds == labels.data).data.item()\n","\n","    # Calculate Accuracy\n","    accuracy = running_corrects / float(len(test_dataset))\n","    #Calculate Loss\n","    loss = criterion(outputs, labels)\n","\n","    print('Validation Accuracy on Sketch: {}'.format(accuracy))\n","    return (accuracy, loss.item())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yDlONBJSUkb-","outputId":"7af63082-3069-45cb-cc41-f0fc983fee9e","executionInfo":{"status":"ok","timestamp":1591802877659,"user_tz":-120,"elapsed":4249413,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["max_val_accuracy2=0\n","min_val_loss2=100\n","best_LR2=0\n","best_epoch_num2=0\n","for lrate in Learning_rates:\n","  \n","  for epochs in num_epochs:\n","      print(\"hyperparameters are: LR={} and NUM_EPOCHS = {}\".format(lrate,epochs))\n","      \n","      # Define loss function\n","      criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n","\n","      # Choose parameters to optimize\n","      # To access a different set of parameters, you have to access submodules of AlexNet\n","      # (nn.Module objects, like AlexNet, implement the Composite Pattern)\n","      # e.g.: parameters of the fully connected layers: net.classifier.parameters()\n","      # e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n","      parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n","\n","      # Define optimizer\n","      # An optimizer updates the weights based on loss\n","      # We use SGD with momentum\n","      optimizer = optim.SGD(parameters_to_optimize, lr=lrate, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","\n","      # Define scheduler\n","      # A scheduler dynamically changes learning rate\n","      # The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n","      scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n","      net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","      cudnn.benchmark\n","      \n","      actual_step=0;\n","      num_corrects=0\n","\n","\n","\n","      for epoch in range(epochs):\n","        scheduler.step() \n","        \n","        for images, labels in  tqdm(train_dataloader):\n","\n","          \n","          images = images.to(DEVICE)\n","          labels = labels.to(DEVICE)\n","\n","          net.train() \n","\n","          # PyTorch, by default, accumulates gradients after each backward pass\n","          # We need to manually set the gradients to zero before starting a new iteration\n","          optimizer.zero_grad() # Zero-ing the gradients\n","\n","        \n","          outputs = net(images)\n","\n","          loss = criterion(outputs, labels)\n","\n","          # Log loss\n","          if actual_step % LOG_FREQUENCY == 0:\n","            print('Step {}, Loss {}'.format(actual_step, loss.item()))\n","\n","        \n","\n","          loss.backward() \n","\n","          optimizer.step() \n","\n","          actual_step += 1\n","          # Get predictions\n","          _, preds = torch.max(outputs.data, 1)\n","\n","          # Update Corrects\n","          num_corrects += torch.sum(preds == labels.data).data.item()\n","\n","        # Calculate Accuracy\n","        accuracy = num_corrects / float(len(train_dataset))\n","\n","        print(\"Accuracy on training set = \"  + str(accuracy))\n","\n","        \n","\n","        \n","        num_corrects = 0\n","\n","      \n","      params= valOnSketch()\n","      val_accuracy=params[0]\n","      val_loss=params[1]\n","      if val_loss<min_val_loss2:\n","        max_val_accuracy2=val_accuracy\n","        min_val_loss2=val_loss\n","        \n","        best_LR2= lrate\n","        best_epoch_num2=epochs\n","        \n","      \n","      if val_loss==min_val_loss2:\n","        if val_accuracy>max_val_accuracy2:\n","          max_val_accuracy2=val_accuracy\n","          min_val_loss2=val_loss\n","          \n","          best_LR2= lrate\n","          best_epoch_num2=epochs  \n","            \n","\n","\n","print (\"best hyperparemeters for validation on sketch are : LR={}, NUM_EPOCHS= {} having highest validation accuracy = {} and minimum validation loss ={}\".format(best_LR2, best_epoch_num2,max_val_accuracy2,min_val_loss2))\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","\r  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["hyperparameters are: LR=1e-05 and NUM_EPOCHS = 10\n","Step 0, Loss 9.295716881752014e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 4.972517490386963e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.0002079606056213379\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 30, Loss 0.00029985979199409485\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.00013546645641326904\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.46s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.00010613910853862762\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:14<00:00,  1.07it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.56201171875\n","hyperparameters are: LR=1e-05 and NUM_EPOCHS = 20\n","Step 0, Loss 0.00024172477424144745\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.90s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 8.934363722801208e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.43s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 7.950887084007263e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 30, Loss 2.401694655418396e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.93s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 8.332356810569763e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.00022934004664421082\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 60, Loss 0.00013872981071472168\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.91s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 8.841603994369507e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.44s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 0.00011343508958816528\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 90, Loss 9.981170296669006e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.91s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 0.00013296306133270264\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 0.0004707612097263336\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9191616766467066\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:15<00:00,  1.05it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.56201171875\n","hyperparameters are: LR=1e-05 and NUM_EPOCHS = 30\n","Step 0, Loss 0.00040617212653160095\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.94s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.0001558847725391388\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.42s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.00010784715414047241\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 30, Loss 0.0002879612147808075\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.95s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 9.752437472343445e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.00012742727994918823\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 60, Loss 0.00041490793228149414\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.89s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 7.303431630134583e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.40s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 9.17091965675354e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 90, Loss 0.00010790303349494934\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.98s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 0.00013121217489242554\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.41s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 4.2751431465148926e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 120, Loss 0.00027024373412132263\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.98s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 130, Loss 0.00010519847273826599\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9191616766467066\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 140, Loss 0.0001428760588169098\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 150, Loss 0.0005295351147651672\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.93s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 160, Loss 5.480274558067322e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9191616766467066\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.47s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 170, Loss 0.0003632158041000366\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:14<00:00,  1.07it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.56201171875\n","hyperparameters are: LR=0.0001 and NUM_EPOCHS = 10\n","Step 0, Loss 9.895861148834229e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.95s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.0001016668975353241\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:13,  3.28s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.00022941455245018005\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 30, Loss 0.00013889744877815247\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 0.000142022967338562\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.37s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.00011562928557395935\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.29s/it]\n","  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:14<00:00,  1.08it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.5615234375\n","hyperparameters are: LR=0.0001 and NUM_EPOCHS = 20\n","Step 0, Loss 0.00010699406266212463\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.86s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.00015613995492458344\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.35s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 0.00015265867114067078\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.28s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 30, Loss 0.0001505054533481598\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 4.957243800163269e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.27s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.38s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.00014013051986694336\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 60, Loss 0.00027970969676971436\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.86s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 9.32253897190094e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 0.0005991868674755096\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 90, Loss 0.000304369255900383\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 0.00014356151223182678\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:12,  3.17s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 0.0001886710524559021\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n","  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:14<00:00,  1.08it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.56201171875\n","hyperparameters are: LR=0.0001 and NUM_EPOCHS = 30\n","Step 0, Loss 0.00023763440549373627\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.20s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.77s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 0.0002601891756057739\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.18s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.19s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:12,  3.16s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 8.592009544372559e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.20s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.18s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 30, Loss 6.473064422607422e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.17s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.74s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 8.497387170791626e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:06<00:00,  1.16s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:06<00:00,  1.16s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:12,  3.16s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 4.1212886571884155e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.17s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:06<00:00,  1.16s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 60, Loss 0.00017066672444343567\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 7.949769496917725e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 0.00032060407102108\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 90, Loss 0.00010180473327636719\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 0.0001341216266155243\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.34s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 5.776248872280121e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 120, Loss 0.00013231486082077026\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.84s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 130, Loss 4.762411117553711e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:12,  3.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 140, Loss 0.0002610534429550171\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 150, Loss 6.872788071632385e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.88s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 160, Loss 0.00013495981693267822\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:13,  3.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 170, Loss 0.00018863379955291748\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:14<00:00,  1.10it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.5615234375\n","hyperparameters are: LR=0.01 and NUM_EPOCHS = 10\n","Step 0, Loss 0.00010601058602333069\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 6.941519677639008e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:12,  3.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 6.210431456565857e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 30, Loss 0.00013705715537071228\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.89s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 3.508478403091431e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:12,  3.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.0003659054636955261\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9191616766467066\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:14<00:00,  1.09it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.57275390625\n","hyperparameters are: LR=0.01 and NUM_EPOCHS = 20\n","Step 0, Loss 0.00010999664664268494\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 9.626895189285278e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:13,  3.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 3.723427653312683e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 30, Loss 0.00017232447862625122\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 4.340708255767822e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:12,  3.24s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 5.657970905303955e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 60, Loss 0.000218074768781662\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 3.698468208312988e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.21s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.30s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.33s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 0.00015246868133544922\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 90, Loss 9.636394679546356e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.83s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 4.431977868080139e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:13,  3.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 0.0007909014821052551\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:14<00:00,  1.10it/s]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.56298828125\n","hyperparameters are: LR=0.01 and NUM_EPOCHS = 30\n","Step 0, Loss 8.004903793334961e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.84s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 7.977709174156189e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:12,  3.25s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 6.171688437461853e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 30, Loss 0.00010188482701778412\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.83s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 5.7268887758255005e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:12,  3.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 9.393319487571716e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 60, Loss 6.47231936454773e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.91s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 70, Loss 0.00015515834093093872\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:12,  3.19s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 80, Loss 7.714703679084778e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 90, Loss 0.000493902713060379\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.82s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 100, Loss 5.648285150527954e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.19s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:04<00:13,  3.26s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 110, Loss 4.213675856590271e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 120, Loss 0.00011566653847694397\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.84s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 130, Loss 5.124509334564209e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 140, Loss 2.245977520942688e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 150, Loss 4.6897679567337036e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.86s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 160, Loss 5.23887574672699e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9191616766467066\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 170, Loss 3.601238131523132e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.26s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:14<00:00,  1.08it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.5439453125\n","best hyperparemeters for validation on sketch are : LR=0.0001, NUM_EPOCHS= 30 having highest validation accuracy = 0.5615234375 and minimum validation loss =10.133872032165527\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"lHAiWV9CHmNo","colab_type":"text"},"source":["##Evaluate the best hyperparameters among the two validation sets"]},{"cell_type":"code","metadata":{"id":"1zwC9lvjIM2H","colab_type":"code","outputId":"aea0a757-e143-4de6-c7ca-a2263e78c1a1","executionInfo":{"status":"ok","timestamp":1591802877664,"user_tz":-120,"elapsed":4249403,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#I take the best hyperparameters belonging to the validation set where the loss is smaller\n","\n","if min_val_loss<min_val_loss2:\n","  best_final_LR= best_LR\n","  best_final_epoch_num= best_epoch_num\n","else:\n","    best_final_LR= best_LR2\n","    best_final_epoch_num= best_epoch_num2\n","\n","print(\"best final LR= {}, best final epoch number={}\".format(best_final_LR,best_final_epoch_num))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["best final LR= 1e-05, best final epoch number=10\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"I6duCINF9Gep","colab_type":"text"},"source":["##Train on Photo and Test on Art painting with the best hyperparameters without domain adaptation"]},{"cell_type":"markdown","metadata":{"id":"8f1hr1gF9K7o","colab_type":"text"},"source":["###Train on Photo"]},{"cell_type":"code","metadata":{"id":"pfoXzImG9Coc","colab_type":"code","outputId":"f2722dd0-9039-47f2-ffbf-98d3dfc86fa1","executionInfo":{"status":"ok","timestamp":1591802951744,"user_tz":-120,"elapsed":4323471,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":507}},"source":["\n","# Define loss function\n","criterion = nn.CrossEntropyLoss() # for classification, we use Cross Entropy\n","\n","# Choose parameters to optimize\n","# To access a different set of parameters, you have to access submodules of AlexNet\n","# (nn.Module objects, like AlexNet, implement the Composite Pattern)\n","# e.g.: parameters of the fully connected layers: net.classifier.parameters()\n","# e.g.: parameters of the convolutional layers: look at alexnet's source code ;) \n","parameters_to_optimize = net.parameters() # In this case we optimize over all the parameters of AlexNet\n","\n","# Define optimizer\n","# An optimizer updates the weights based on loss\n","# We use SGD with momentum\n","optimizer = optim.SGD(parameters_to_optimize, lr=best_final_LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","\n","# Define scheduler\n","# A scheduler dynamically changes learning rate\n","# The most common schedule is the step(-down), which multiplies learning rate by gamma every STEP_SIZE epochs\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n","\n","\n","\n","net=net.to(DEVICE)\n","cudnn.benchmark\n","\n","actual_step=0;\n","num_corrects=0\n","\n","for epoch in range(best_final_epoch_num):\n","  scheduler.step() \n","  \n","  for images, labels in  tqdm(train_dataloader):\n","\n","    \n","    images = images.to(DEVICE)\n","    labels = labels.to(DEVICE)\n","\n","    net.train() \n","\n","    # PyTorch, by default, accumulates gradients after each backward pass\n","    # We need to manually set the gradients to zero before starting a new iteration\n","    optimizer.zero_grad() # Zero-ing the gradients\n","\n","  \n","    outputs = net(images)\n","\n","    loss = criterion(outputs, labels)\n","\n","    # Log loss\n","    if actual_step % LOG_FREQUENCY == 0:\n","      print('Step {}, Loss {}'.format(actual_step, loss.item()))\n","\n","  \n","\n","    loss.backward() \n","\n","    optimizer.step() \n","\n","    actual_step += 1\n","    # Get predictions\n","    _, preds = torch.max(outputs.data, 1)\n","\n","    # Update Corrects\n","    num_corrects += torch.sum(preds == labels.data).data.item()\n","\n","  # Calculate Accuracy\n","  accuracy = num_corrects / float(len(train_dataset))\n","  print(\"Accuracy on training set = \"  + str(accuracy))\n","  num_corrects = 0\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","\r  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Step 0, Loss 0.0003589130938053131\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:06<00:03,  1.87s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 10, Loss 3.625452518463135e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.29s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 20, Loss 4.8667192459106445e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n","Step 30, Loss 2.6557594537734985e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.22s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 67%|██████▋   | 4/6 [00:05<00:03,  1.84s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 40, Loss 3.610178828239441e-05\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.24s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":[" 33%|███▎      | 2/6 [00:05<00:13,  3.32s/it]"],"name":"stderr"},{"output_type":"stream","text":["Step 50, Loss 0.00012804754078388214\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.25s/it]\n","  0%|          | 0/6 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 6/6 [00:07<00:00,  1.23s/it]"],"name":"stderr"},{"output_type":"stream","text":["Accuracy on training set = 0.9197604790419162\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"UsN_2Qjq9Nz_","colab_type":"text"},"source":["###Test on Art Painting "]},{"cell_type":"code","metadata":{"id":"PtJm1rd69RkB","colab_type":"code","outputId":"be5722d2-d28b-4bc0-b73e-4d63313c9566","executionInfo":{"status":"ok","timestamp":1591802960257,"user_tz":-120,"elapsed":4331945,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","net.train(False) # Set Network to evaluation mode\n","\n","running_corrects = 0\n","for images, labels in tqdm(test_dataloader):\n","  images = images.to(DEVICE)\n","  labels = labels.to(DEVICE)\n","\n","  # Forward Pass\n","  outputs = net(images)\n","\n","  # Get predictions\n","  _, preds = torch.max(outputs.data, 1)\n","\n","  # Update Corrects\n","  running_corrects += torch.sum(preds == labels.data).data.item()\n","\n","# Calculate Accuracy\n","accuracy = running_corrects / float(len(test_dataset))\n","\n","print('Test Accuracy: {}'.format(accuracy))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 8/8 [00:08<00:00,  1.08s/it]"],"name":"stderr"},{"output_type":"stream","text":["Test Accuracy: 0.4677734375\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"2j0jODGC-lof","colab_type":"text"},"source":["##Grid search on photo to cartoon and sketch with domain adaptation\n"]},{"cell_type":"markdown","metadata":{"id":"njLlYneH_Sbj","colab_type":"text"},"source":["###Validation on Cartoon"]},{"cell_type":"code","metadata":{"id":"raxFNP9p0d8u","colab_type":"code","colab":{}},"source":["#ho provato a mettere 1e-2 (come prima) ma era troppo alto\n","#il test set va bene con i lr alti mentre i due validation vanno bene con quelli piccoli(con quelli grandi divergono), provo quindi a cercare i più grandi tra i parametri possibili che non facciano divergere il modello e in contemporanea massimizzino il rate\n","#Ho visto che 9e-2 ha una test accuracy troppo basso per cui l'ordine di grandezza sarà -3...\n","#Learning_rates = [1e-5, 1e-4,1e-2]\n","Learning_rates = [5e-3,6e-3, 7e-3]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"r8n2ZIPxAe1Y","colab_type":"code","outputId":"7bae79e0-d3f7-49e6-9af3-ae745005fcb8","executionInfo":{"status":"ok","timestamp":1591807757861,"user_tz":-120,"elapsed":2398617,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["max_val_accuracy=0\n","min_val_loss=100\n","best_LR=0\n","best_epoch_num=0\n","for lrate in Learning_rates:\n","   for epochs in num_epochs:\n","\n","      print(\"hyperprameters are: LR={} and NUM_EPOCHS = {}\".format(lrate, epochs))\n","      alpha= 1\n","      net = DANNAlexnet(num_classes = 7)\n","      net = net.to(DEVICE)\n","\n","      class_loss = nn.CrossEntropyLoss() \n","      domain_loss = nn.CrossEntropyLoss()\n","\n","      parameters_to_optimize = net.parameters() \n","\n","      optimizer = optim.SGD(parameters_to_optimize, lr=lrate, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","\n","      scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n","\n","\n","      max_batches = max(len(train_dataloader), len(cartoon_dataloader))\n","      min_batches = min(len(train_dataloader), len(cartoon_dataloader))#\n","      net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","\n","      cudnn.benchmark #function to optimize runtime by finding the best configuration for your hw, useful when input size \n","      running_corrects = 0\n","      current_step = 0\n","      for epoch in range(epochs):\n","        print(f'\\nEpoch {epoch+1:04d} / {epochs:04d}', end='\\n=================\\n')\n","        scheduler.step() \n","        train_iterable = iter(train_dataloader)\n","        test_iterable = iter(cartoon_dataloader)\n","        for batch in range(max_batches):\n","          net.train() # Sets module in training mode\n","          optimizer.zero_grad() # Zero-ing the gradients \n","          if( batch == min_batches):#\n","            train_iterable = iter(train_dataloader)#\n","\n","          images_source, labels_source = next(train_iterable)\n","          labels_domain = torch.zeros(len(images_source), dtype=torch.long)    \n","          \n","          images_source = images_source.to(DEVICE)\n","          labels_source = labels_source.to(DEVICE)\n","          labels_domain = labels_domain.to(DEVICE)\n","          \n","          class_output = net(images_source)\n","          domain_output = net(images_source, alpha)\n","          \n","\n","\n","          loss_s_label = class_loss(class_output, labels_source)\n","          loss_s_domain = domain_loss(domain_output, labels_domain)\n","          \n","\n","        \n","          targets, _ = next(test_iterable)\n","          target_domain = torch.ones(len(targets), dtype=torch.long)\n","\n","      \n","          targets = targets.to(DEVICE)\n","          target_domain = target_domain.to(DEVICE)\n","\n","          target_output = net(targets, alpha)\n","\n","\n","          loss_t_domain = domain_loss(target_output,target_domain)\n","\n","\n","          loss = loss_s_label + loss_s_domain + loss_t_domain\n","          loss.backward() \n","\n","          optimizer.step() \n","\n","          current_step += 1\n","\n","          print(f'[{batch+1}/{max_batches}] '\n","                f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '\n","                f't_domain_loss: {loss_t_domain.item():.4f} '\n","                )  \n","        \n","\n","      params=valOnCartoon()\n","      val_accuracy= params[0]\n","      val_loss=params[1]\n","      \n","      \n","      if val_loss<min_val_loss:\n","        max_val_accuracy=val_accuracy\n","        min_val_loss=val_loss\n","        \n","        best_LR= lrate\n","        best_epoch_num= epochs\n","        \n","      \n","      if val_loss<min_val_loss:\n","        if val_accuracy>max_val_accuracy:\n","          max_val_accuracy=val_accuracy\n","          min_val_loss=val_loss\n","          \n","          best_LR= lrate\n","          best_epoch_num=epochs\n","      \n","      \n","      \n","            \n","\n","\n","print (\"best hyperparemeters after validation on cartoon are : LR={}, NUM_EPOCHS= {} having validation accuracy= {} and validation loss ={}\".format(best_LR, best_epoch_num,max_val_accuracy,min_val_loss))     \n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["hyperprameters are: LR=0.005 and NUM_EPOCHS = 10\n","\n","Epoch 0001 / 0010\n","=================\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[1/10] class_loss: 2.1891 s_domain_loss: 0.5277 t_domain_loss: 0.9407 \n","[2/10] class_loss: 1.3782 s_domain_loss: 1.2009 t_domain_loss: 0.3842 \n","[3/10] class_loss: 0.8773 s_domain_loss: 0.4380 t_domain_loss: 1.0669 \n","[4/10] class_loss: 0.5688 s_domain_loss: 0.7007 t_domain_loss: 0.7003 \n","[5/10] class_loss: 0.4552 s_domain_loss: 0.9893 t_domain_loss: 0.4784 \n","[6/10] class_loss: 0.2760 s_domain_loss: 0.4092 t_domain_loss: 1.0975 \n","[7/10] class_loss: 0.2194 s_domain_loss: 0.8722 t_domain_loss: 0.5253 \n","[8/10] class_loss: 0.2300 s_domain_loss: 0.7537 t_domain_loss: 0.6200 \n","[9/10] class_loss: 0.1697 s_domain_loss: 0.4430 t_domain_loss: 0.9877 \n","[10/10] class_loss: 0.1743 s_domain_loss: 0.9731 t_domain_loss: 0.4710 \n","\n","Epoch 0002 / 0010\n","=================\n","[1/10] class_loss: 0.2037 s_domain_loss: 0.6036 t_domain_loss: 0.7471 \n","[2/10] class_loss: 0.1456 s_domain_loss: 0.5067 t_domain_loss: 0.8401 \n","[3/10] class_loss: 0.1058 s_domain_loss: 0.9711 t_domain_loss: 0.4170 \n","[4/10] class_loss: 0.2269 s_domain_loss: 0.4576 t_domain_loss: 0.8932 \n","[5/10] class_loss: 0.1131 s_domain_loss: 0.6659 t_domain_loss: 0.6287 \n","[6/10] class_loss: 0.1193 s_domain_loss: 0.8072 t_domain_loss: 0.5205 \n","[7/10] class_loss: 0.1303 s_domain_loss: 0.4678 t_domain_loss: 0.8777 \n","[8/10] class_loss: 0.1314 s_domain_loss: 0.7649 t_domain_loss: 0.5179 \n","[9/10] class_loss: 0.0524 s_domain_loss: 0.6868 t_domain_loss: 0.5998 \n","[10/10] class_loss: 0.1199 s_domain_loss: 0.4574 t_domain_loss: 0.8232 \n","\n","Epoch 0003 / 0010\n","=================\n","[1/10] class_loss: 0.0696 s_domain_loss: 0.8483 t_domain_loss: 0.4282 \n","[2/10] class_loss: 0.0945 s_domain_loss: 0.5076 t_domain_loss: 0.7265 \n","[3/10] class_loss: 0.1381 s_domain_loss: 0.5350 t_domain_loss: 0.6706 \n","[4/10] class_loss: 0.0599 s_domain_loss: 0.8103 t_domain_loss: 0.4379 \n","[5/10] class_loss: 0.1140 s_domain_loss: 0.4651 t_domain_loss: 0.7751 \n","[6/10] class_loss: 0.0704 s_domain_loss: 0.5546 t_domain_loss: 0.6073 \n","[7/10] class_loss: 0.0604 s_domain_loss: 0.8382 t_domain_loss: 0.3887 \n","[8/10] class_loss: 0.0484 s_domain_loss: 0.3923 t_domain_loss: 0.8042 \n","[9/10] class_loss: 0.0990 s_domain_loss: 0.5926 t_domain_loss: 0.5257 \n","[10/10] class_loss: 0.0499 s_domain_loss: 0.7407 t_domain_loss: 0.3631 \n","\n","Epoch 0004 / 0010\n","=================\n","[1/10] class_loss: 0.0492 s_domain_loss: 0.3364 t_domain_loss: 0.8565 \n","[2/10] class_loss: 0.0437 s_domain_loss: 0.5685 t_domain_loss: 0.4743 \n","[3/10] class_loss: 0.0495 s_domain_loss: 0.7282 t_domain_loss: 0.3309 \n","[4/10] class_loss: 0.0502 s_domain_loss: 0.3319 t_domain_loss: 0.7682 \n","[5/10] class_loss: 0.0285 s_domain_loss: 0.5360 t_domain_loss: 0.4755 \n","[6/10] class_loss: 0.0815 s_domain_loss: 0.6708 t_domain_loss: 0.3770 \n","[7/10] class_loss: 0.0510 s_domain_loss: 0.3132 t_domain_loss: 0.6925 \n","[8/10] class_loss: 0.0208 s_domain_loss: 0.6204 t_domain_loss: 0.3613 \n","[9/10] class_loss: 0.0288 s_domain_loss: 0.6149 t_domain_loss: 0.3830 \n","[10/10] class_loss: 0.0413 s_domain_loss: 0.3653 t_domain_loss: 0.5862 \n","\n","Epoch 0005 / 0010\n","=================\n","[1/10] class_loss: 0.0299 s_domain_loss: 0.3485 t_domain_loss: 0.5736 \n","[2/10] class_loss: 0.0583 s_domain_loss: 0.8463 t_domain_loss: 0.2467 \n","[3/10] class_loss: 0.0186 s_domain_loss: 0.3426 t_domain_loss: 0.4853 \n","[4/10] class_loss: 0.0356 s_domain_loss: 0.2831 t_domain_loss: 0.5651 \n","[5/10] class_loss: 0.0314 s_domain_loss: 0.7662 t_domain_loss: 0.2332 \n","[6/10] class_loss: 0.0449 s_domain_loss: 0.3266 t_domain_loss: 0.4889 \n","[7/10] class_loss: 0.0356 s_domain_loss: 0.2598 t_domain_loss: 0.5572 \n","[8/10] class_loss: 0.0354 s_domain_loss: 0.6698 t_domain_loss: 0.2197 \n","[9/10] class_loss: 0.0305 s_domain_loss: 0.6049 t_domain_loss: 0.3730 \n","[10/10] class_loss: 0.0384 s_domain_loss: 0.2883 t_domain_loss: 0.4019 \n","\n","Epoch 0006 / 0010\n","=================\n","[1/10] class_loss: 0.0685 s_domain_loss: 0.5962 t_domain_loss: 0.4967 \n","[2/10] class_loss: 0.0494 s_domain_loss: 0.2974 t_domain_loss: 0.5353 \n","[3/10] class_loss: 0.0323 s_domain_loss: 0.3203 t_domain_loss: 0.2435 \n","[4/10] class_loss: 0.0497 s_domain_loss: 0.6598 t_domain_loss: 0.1591 \n","[5/10] class_loss: 0.0695 s_domain_loss: 0.2155 t_domain_loss: 0.4163 \n","[6/10] class_loss: 0.0357 s_domain_loss: 0.1803 t_domain_loss: 0.4606 \n","[7/10] class_loss: 0.0635 s_domain_loss: 0.5400 t_domain_loss: 0.1764 \n","[8/10] class_loss: 0.0599 s_domain_loss: 0.3416 t_domain_loss: 0.2096 \n","[9/10] class_loss: 0.0540 s_domain_loss: 0.1443 t_domain_loss: 0.3348 \n","[10/10] class_loss: 0.0390 s_domain_loss: 0.2966 t_domain_loss: 0.1353 \n","\n","Epoch 0007 / 0010\n","=================\n","[1/10] class_loss: 0.0500 s_domain_loss: 0.1978 t_domain_loss: 0.3057 \n","[2/10] class_loss: 0.0258 s_domain_loss: 0.3148 t_domain_loss: 0.2117 \n","[3/10] class_loss: 0.0393 s_domain_loss: 0.1590 t_domain_loss: 0.1953 \n","[4/10] class_loss: 0.0534 s_domain_loss: 0.1977 t_domain_loss: 0.1853 \n","[5/10] class_loss: 0.0627 s_domain_loss: 0.2459 t_domain_loss: 0.1559 \n","[6/10] class_loss: 0.0424 s_domain_loss: 0.1811 t_domain_loss: 0.1646 \n","[7/10] class_loss: 0.0395 s_domain_loss: 0.1453 t_domain_loss: 0.1976 \n","[8/10] class_loss: 0.0488 s_domain_loss: 0.2061 t_domain_loss: 0.1386 \n","[9/10] class_loss: 0.0535 s_domain_loss: 0.2114 t_domain_loss: 0.1403 \n","[10/10] class_loss: 0.0362 s_domain_loss: 0.1796 t_domain_loss: 0.0842 \n","\n","Epoch 0008 / 0010\n","=================\n","[1/10] class_loss: 0.0762 s_domain_loss: 0.2848 t_domain_loss: 0.2475 \n","[2/10] class_loss: 0.0263 s_domain_loss: 0.0337 t_domain_loss: 0.3483 \n","[3/10] class_loss: 0.0253 s_domain_loss: 0.1490 t_domain_loss: 0.1094 \n","[4/10] class_loss: 0.0626 s_domain_loss: 0.6053 t_domain_loss: 0.0478 \n","[5/10] class_loss: 0.0495 s_domain_loss: 0.3210 t_domain_loss: 0.0738 \n","[6/10] class_loss: 0.1263 s_domain_loss: 0.1067 t_domain_loss: 0.2592 \n","[7/10] class_loss: 0.0532 s_domain_loss: 0.0341 t_domain_loss: 0.4361 \n","[8/10] class_loss: 0.0565 s_domain_loss: 0.1932 t_domain_loss: 0.1340 \n","[9/10] class_loss: 0.0726 s_domain_loss: 0.8608 t_domain_loss: 0.0474 \n","[10/10] class_loss: 0.0724 s_domain_loss: 0.0689 t_domain_loss: 0.1080 \n","\n","Epoch 0009 / 0010\n","=================\n","[1/10] class_loss: 0.0717 s_domain_loss: 0.2529 t_domain_loss: 0.4624 \n","[2/10] class_loss: 0.1085 s_domain_loss: 0.1305 t_domain_loss: 0.3048 \n","[3/10] class_loss: 0.1849 s_domain_loss: 1.0250 t_domain_loss: 0.1047 \n","[4/10] class_loss: 0.1009 s_domain_loss: 0.2850 t_domain_loss: 0.2308 \n","[5/10] class_loss: 0.1006 s_domain_loss: 0.1498 t_domain_loss: 0.3485 \n","[6/10] class_loss: 0.1345 s_domain_loss: 0.1007 t_domain_loss: 0.1835 \n","[7/10] class_loss: 0.1367 s_domain_loss: 0.4864 t_domain_loss: 0.0730 \n","[8/10] class_loss: 0.1549 s_domain_loss: 0.1120 t_domain_loss: 0.1228 \n","[9/10] class_loss: 0.1466 s_domain_loss: 0.3307 t_domain_loss: 0.1785 \n","[10/10] class_loss: 0.1253 s_domain_loss: 0.1128 t_domain_loss: 0.0950 \n","\n","Epoch 0010 / 0010\n","=================\n","[1/10] class_loss: 0.1154 s_domain_loss: 0.1623 t_domain_loss: 0.1318 \n","[2/10] class_loss: 0.0895 s_domain_loss: 0.3709 t_domain_loss: 0.1276 \n","[3/10] class_loss: 0.0821 s_domain_loss: 0.0858 t_domain_loss: 0.2928 \n","[4/10] class_loss: 0.0816 s_domain_loss: 0.0573 t_domain_loss: 0.2117 \n","[5/10] class_loss: 0.1319 s_domain_loss: 0.6246 t_domain_loss: 0.0900 \n","[6/10] class_loss: 0.0774 s_domain_loss: 0.0707 t_domain_loss: 0.0546 \n","[7/10] class_loss: 0.0944 s_domain_loss: 0.0791 t_domain_loss: 0.0427 \n","[8/10] class_loss: 0.1191 s_domain_loss: 0.4411 t_domain_loss: 0.0409 \n","[9/10] class_loss: 0.0605 s_domain_loss: 0.0399 t_domain_loss: 0.1494 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[10/10] class_loss: 0.1297 s_domain_loss: 0.1542 t_domain_loss: 0.4333 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.25634765625\n","hyperprameters are: LR=0.005 and NUM_EPOCHS = 20\n","\n","Epoch 0001 / 0020\n","=================\n","[1/10] class_loss: 2.1570 s_domain_loss: 0.7779 t_domain_loss: 0.6616 \n","[2/10] class_loss: 1.3571 s_domain_loss: 0.5671 t_domain_loss: 0.8844 \n","[3/10] class_loss: 0.8264 s_domain_loss: 0.8379 t_domain_loss: 0.5935 \n","[4/10] class_loss: 0.6413 s_domain_loss: 0.6658 t_domain_loss: 0.7500 \n","[5/10] class_loss: 0.5158 s_domain_loss: 0.6276 t_domain_loss: 0.7715 \n","[6/10] class_loss: 0.3532 s_domain_loss: 0.7977 t_domain_loss: 0.6044 \n","[7/10] class_loss: 0.3112 s_domain_loss: 0.5975 t_domain_loss: 0.8048 \n","[8/10] class_loss: 0.1729 s_domain_loss: 0.7152 t_domain_loss: 0.6569 \n","[9/10] class_loss: 0.2037 s_domain_loss: 0.7266 t_domain_loss: 0.6450 \n","[10/10] class_loss: 0.1729 s_domain_loss: 0.5578 t_domain_loss: 0.8200 \n","\n","Epoch 0002 / 0020\n","=================\n","[1/10] class_loss: 0.2140 s_domain_loss: 0.8043 t_domain_loss: 0.5677 \n","[2/10] class_loss: 0.1367 s_domain_loss: 0.5727 t_domain_loss: 0.7423 \n","[3/10] class_loss: 0.2570 s_domain_loss: 0.6667 t_domain_loss: 0.6443 \n","[4/10] class_loss: 0.1253 s_domain_loss: 0.6873 t_domain_loss: 0.6281 \n","[5/10] class_loss: 0.2131 s_domain_loss: 0.6005 t_domain_loss: 0.6938 \n","[6/10] class_loss: 0.2002 s_domain_loss: 0.6720 t_domain_loss: 0.6341 \n","[7/10] class_loss: 0.1251 s_domain_loss: 0.6282 t_domain_loss: 0.6456 \n","[8/10] class_loss: 0.1171 s_domain_loss: 0.6385 t_domain_loss: 0.6291 \n","[9/10] class_loss: 0.1942 s_domain_loss: 0.6139 t_domain_loss: 0.6395 \n","[10/10] class_loss: 0.0747 s_domain_loss: 0.6397 t_domain_loss: 0.5831 \n","\n","Epoch 0003 / 0020\n","=================\n","[1/10] class_loss: 0.0934 s_domain_loss: 0.5613 t_domain_loss: 0.6717 \n","[2/10] class_loss: 0.1167 s_domain_loss: 0.6203 t_domain_loss: 0.5914 \n","[3/10] class_loss: 0.0976 s_domain_loss: 0.6194 t_domain_loss: 0.5720 \n","[4/10] class_loss: 0.0584 s_domain_loss: 0.5248 t_domain_loss: 0.6657 \n","[5/10] class_loss: 0.0670 s_domain_loss: 0.6879 t_domain_loss: 0.4857 \n","[6/10] class_loss: 0.0832 s_domain_loss: 0.5375 t_domain_loss: 0.6091 \n","[7/10] class_loss: 0.0553 s_domain_loss: 0.5182 t_domain_loss: 0.6091 \n","[8/10] class_loss: 0.0448 s_domain_loss: 0.7173 t_domain_loss: 0.4412 \n","[9/10] class_loss: 0.0524 s_domain_loss: 0.4429 t_domain_loss: 0.6766 \n","[10/10] class_loss: 0.0857 s_domain_loss: 0.5684 t_domain_loss: 0.4598 \n","\n","Epoch 0004 / 0020\n","=================\n","[1/10] class_loss: 0.0499 s_domain_loss: 0.5323 t_domain_loss: 0.5495 \n","[2/10] class_loss: 0.0794 s_domain_loss: 0.4631 t_domain_loss: 0.5649 \n","[3/10] class_loss: 0.0541 s_domain_loss: 0.5581 t_domain_loss: 0.4366 \n","[4/10] class_loss: 0.0519 s_domain_loss: 0.4746 t_domain_loss: 0.5204 \n","[5/10] class_loss: 0.0634 s_domain_loss: 0.4880 t_domain_loss: 0.4782 \n","[6/10] class_loss: 0.0514 s_domain_loss: 0.5930 t_domain_loss: 0.4085 \n","[7/10] class_loss: 0.0446 s_domain_loss: 0.3513 t_domain_loss: 0.6012 \n","[8/10] class_loss: 0.0257 s_domain_loss: 0.6214 t_domain_loss: 0.3711 \n","[9/10] class_loss: 0.0664 s_domain_loss: 0.4694 t_domain_loss: 0.4939 \n","[10/10] class_loss: 0.0464 s_domain_loss: 0.3924 t_domain_loss: 0.3887 \n","\n","Epoch 0005 / 0020\n","=================\n","[1/10] class_loss: 0.0613 s_domain_loss: 0.4576 t_domain_loss: 0.4097 \n","[2/10] class_loss: 0.0365 s_domain_loss: 0.3867 t_domain_loss: 0.4160 \n","[3/10] class_loss: 0.0637 s_domain_loss: 0.5194 t_domain_loss: 0.3719 \n","[4/10] class_loss: 0.0317 s_domain_loss: 0.3463 t_domain_loss: 0.5405 \n","[5/10] class_loss: 0.0506 s_domain_loss: 0.4000 t_domain_loss: 0.3119 \n","[6/10] class_loss: 0.0373 s_domain_loss: 0.5530 t_domain_loss: 0.2417 \n","[7/10] class_loss: 0.0430 s_domain_loss: 0.2555 t_domain_loss: 0.5145 \n","[8/10] class_loss: 0.0525 s_domain_loss: 0.3149 t_domain_loss: 0.3950 \n","[9/10] class_loss: 0.0460 s_domain_loss: 0.4234 t_domain_loss: 0.2093 \n","[10/10] class_loss: 0.0853 s_domain_loss: 0.4551 t_domain_loss: 0.1777 \n","\n","Epoch 0006 / 0020\n","=================\n","[1/10] class_loss: 0.0441 s_domain_loss: 0.2042 t_domain_loss: 0.7034 \n","[2/10] class_loss: 0.0485 s_domain_loss: 0.3418 t_domain_loss: 0.3514 \n","[3/10] class_loss: 0.1031 s_domain_loss: 0.8831 t_domain_loss: 0.1191 \n","[4/10] class_loss: 0.0456 s_domain_loss: 0.1496 t_domain_loss: 0.4374 \n","[5/10] class_loss: 0.0509 s_domain_loss: 0.1251 t_domain_loss: 0.4359 \n","[6/10] class_loss: 0.0828 s_domain_loss: 0.4171 t_domain_loss: 0.1393 \n","[7/10] class_loss: 0.0461 s_domain_loss: 0.6173 t_domain_loss: 0.1128 \n","[8/10] class_loss: 0.0538 s_domain_loss: 0.0813 t_domain_loss: 0.4975 \n","[9/10] class_loss: 0.1446 s_domain_loss: 0.1165 t_domain_loss: 0.3767 \n","[10/10] class_loss: 0.1047 s_domain_loss: 0.3291 t_domain_loss: 0.0584 \n","\n","Epoch 0007 / 0020\n","=================\n","[1/10] class_loss: 0.0759 s_domain_loss: 0.3724 t_domain_loss: 0.0890 \n","[2/10] class_loss: 0.0447 s_domain_loss: 0.2714 t_domain_loss: 0.2412 \n","[3/10] class_loss: 0.0458 s_domain_loss: 0.0864 t_domain_loss: 0.3868 \n","[4/10] class_loss: 0.0663 s_domain_loss: 0.1168 t_domain_loss: 0.1947 \n","[5/10] class_loss: 0.0791 s_domain_loss: 0.5378 t_domain_loss: 0.0685 \n","[6/10] class_loss: 0.0574 s_domain_loss: 0.1593 t_domain_loss: 0.1439 \n","[7/10] class_loss: 0.0589 s_domain_loss: 0.1317 t_domain_loss: 0.2876 \n","[8/10] class_loss: 0.0466 s_domain_loss: 0.1358 t_domain_loss: 0.2419 \n","[9/10] class_loss: 0.0677 s_domain_loss: 0.1415 t_domain_loss: 0.1052 \n","[10/10] class_loss: 0.1559 s_domain_loss: 0.5009 t_domain_loss: 0.0360 \n","\n","Epoch 0008 / 0020\n","=================\n","[1/10] class_loss: 0.0867 s_domain_loss: 0.1136 t_domain_loss: 0.1605 \n","[2/10] class_loss: 0.0359 s_domain_loss: 0.0611 t_domain_loss: 0.2085 \n","[3/10] class_loss: 0.0485 s_domain_loss: 0.2308 t_domain_loss: 0.1442 \n","[4/10] class_loss: 0.0613 s_domain_loss: 0.0994 t_domain_loss: 0.0992 \n","[5/10] class_loss: 0.0947 s_domain_loss: 0.0519 t_domain_loss: 0.0872 \n","[6/10] class_loss: 0.1139 s_domain_loss: 0.6793 t_domain_loss: 0.0626 \n","[7/10] class_loss: 0.1028 s_domain_loss: 0.0240 t_domain_loss: 0.2795 \n","[8/10] class_loss: 0.3007 s_domain_loss: 0.3762 t_domain_loss: 0.3694 \n","[9/10] class_loss: 0.0699 s_domain_loss: 0.1561 t_domain_loss: 0.1750 \n","[10/10] class_loss: 0.1799 s_domain_loss: 0.2158 t_domain_loss: 0.0440 \n","\n","Epoch 0009 / 0020\n","=================\n","[1/10] class_loss: 0.1887 s_domain_loss: 0.2020 t_domain_loss: 0.0463 \n","[2/10] class_loss: 0.2010 s_domain_loss: 0.4010 t_domain_loss: 0.0595 \n","[3/10] class_loss: 0.1488 s_domain_loss: 0.0846 t_domain_loss: 0.2581 \n","[4/10] class_loss: 0.1071 s_domain_loss: 0.0239 t_domain_loss: 0.3450 \n","[5/10] class_loss: 0.1217 s_domain_loss: 0.0478 t_domain_loss: 0.1290 \n","[6/10] class_loss: 0.1276 s_domain_loss: 0.3779 t_domain_loss: 0.0297 \n","[7/10] class_loss: 0.1573 s_domain_loss: 0.1287 t_domain_loss: 0.0310 \n","[8/10] class_loss: 0.1174 s_domain_loss: 0.1716 t_domain_loss: 0.0359 \n","[9/10] class_loss: 0.1196 s_domain_loss: 0.0332 t_domain_loss: 0.1207 \n","[10/10] class_loss: 0.0917 s_domain_loss: 0.0237 t_domain_loss: 0.0862 \n","\n","Epoch 0010 / 0020\n","=================\n","[1/10] class_loss: 0.1011 s_domain_loss: 0.0465 t_domain_loss: 0.1372 \n","[2/10] class_loss: 0.1217 s_domain_loss: 0.0328 t_domain_loss: 0.0482 \n","[3/10] class_loss: 0.0964 s_domain_loss: 0.1655 t_domain_loss: 0.0212 \n","[4/10] class_loss: 0.1452 s_domain_loss: 0.0622 t_domain_loss: 0.0149 \n","[5/10] class_loss: 0.0490 s_domain_loss: 0.0612 t_domain_loss: 0.0182 \n","[6/10] class_loss: 0.0804 s_domain_loss: 0.2354 t_domain_loss: 0.0224 \n","[7/10] class_loss: 0.0719 s_domain_loss: 0.0164 t_domain_loss: 0.0573 \n","[8/10] class_loss: 0.0742 s_domain_loss: 0.0107 t_domain_loss: 0.1074 \n","[9/10] class_loss: 0.0329 s_domain_loss: 0.0239 t_domain_loss: 0.1212 \n","[10/10] class_loss: 0.0622 s_domain_loss: 0.0233 t_domain_loss: 0.0740 \n","\n","Epoch 0011 / 0020\n","=================\n","[1/10] class_loss: 0.0658 s_domain_loss: 0.0401 t_domain_loss: 0.0389 \n","[2/10] class_loss: 0.0674 s_domain_loss: 0.1476 t_domain_loss: 0.0174 \n","[3/10] class_loss: 0.0336 s_domain_loss: 0.0577 t_domain_loss: 0.0151 \n","[4/10] class_loss: 0.0260 s_domain_loss: 0.0385 t_domain_loss: 0.0121 \n","[5/10] class_loss: 0.0361 s_domain_loss: 0.0290 t_domain_loss: 0.0135 \n","[6/10] class_loss: 0.0411 s_domain_loss: 0.0373 t_domain_loss: 0.0155 \n","[7/10] class_loss: 0.0532 s_domain_loss: 0.0078 t_domain_loss: 0.0203 \n","[8/10] class_loss: 0.0371 s_domain_loss: 0.1041 t_domain_loss: 0.0194 \n","[9/10] class_loss: 0.0518 s_domain_loss: 0.0033 t_domain_loss: 0.0314 \n","[10/10] class_loss: 0.0326 s_domain_loss: 0.0095 t_domain_loss: 0.0288 \n","\n","Epoch 0012 / 0020\n","=================\n","[1/10] class_loss: 0.0228 s_domain_loss: 0.0137 t_domain_loss: 0.0600 \n","[2/10] class_loss: 0.0249 s_domain_loss: 0.1354 t_domain_loss: 0.0367 \n","[3/10] class_loss: 0.0465 s_domain_loss: 0.0006 t_domain_loss: 0.0396 \n","[4/10] class_loss: 0.0433 s_domain_loss: 0.0040 t_domain_loss: 0.0326 \n","[5/10] class_loss: 0.0460 s_domain_loss: 0.0108 t_domain_loss: 0.0283 \n","[6/10] class_loss: 0.0656 s_domain_loss: 0.0222 t_domain_loss: 0.0227 \n","[7/10] class_loss: 0.0473 s_domain_loss: 0.1075 t_domain_loss: 0.0169 \n","[8/10] class_loss: 0.0193 s_domain_loss: 0.0363 t_domain_loss: 0.0188 \n","[9/10] class_loss: 0.0147 s_domain_loss: 0.0170 t_domain_loss: 0.0213 \n","[10/10] class_loss: 0.0261 s_domain_loss: 0.0282 t_domain_loss: 0.0174 \n","\n","Epoch 0013 / 0020\n","=================\n","[1/10] class_loss: 0.0384 s_domain_loss: 0.0220 t_domain_loss: 0.0390 \n","[2/10] class_loss: 0.0265 s_domain_loss: 0.0610 t_domain_loss: 0.0287 \n","[3/10] class_loss: 0.0132 s_domain_loss: 0.0151 t_domain_loss: 0.0284 \n","[4/10] class_loss: 0.0210 s_domain_loss: 0.0066 t_domain_loss: 0.0258 \n","[5/10] class_loss: 0.0411 s_domain_loss: 0.0053 t_domain_loss: 0.0271 \n","[6/10] class_loss: 0.0385 s_domain_loss: 0.0509 t_domain_loss: 0.0208 \n","[7/10] class_loss: 0.0692 s_domain_loss: 0.0258 t_domain_loss: 0.0196 \n","[8/10] class_loss: 0.0284 s_domain_loss: 0.1895 t_domain_loss: 0.0170 \n","[9/10] class_loss: 0.0193 s_domain_loss: 0.0120 t_domain_loss: 0.0408 \n","[10/10] class_loss: 0.0409 s_domain_loss: 0.0051 t_domain_loss: 0.0307 \n","\n","Epoch 0014 / 0020\n","=================\n","[1/10] class_loss: 0.0305 s_domain_loss: 0.1468 t_domain_loss: 0.1216 \n","[2/10] class_loss: 0.0359 s_domain_loss: 0.0151 t_domain_loss: 0.0690 \n","[3/10] class_loss: 0.0260 s_domain_loss: 0.0169 t_domain_loss: 0.0560 \n","[4/10] class_loss: 0.0727 s_domain_loss: 0.0123 t_domain_loss: 0.0340 \n","[5/10] class_loss: 0.0529 s_domain_loss: 0.0620 t_domain_loss: 0.0228 \n","[6/10] class_loss: 0.0578 s_domain_loss: 0.0359 t_domain_loss: 0.0170 \n","[7/10] class_loss: 0.0448 s_domain_loss: 0.0031 t_domain_loss: 0.0137 \n","[8/10] class_loss: 0.0481 s_domain_loss: 0.0315 t_domain_loss: 0.0101 \n","[9/10] class_loss: 0.0731 s_domain_loss: 0.0871 t_domain_loss: 0.0076 \n","[10/10] class_loss: 0.0657 s_domain_loss: 0.0188 t_domain_loss: 0.0179 \n","\n","Epoch 0015 / 0020\n","=================\n","[1/10] class_loss: 0.0285 s_domain_loss: 0.0367 t_domain_loss: 0.0122 \n","[2/10] class_loss: 0.0356 s_domain_loss: 0.0280 t_domain_loss: 0.0151 \n","[3/10] class_loss: 0.0346 s_domain_loss: 0.0061 t_domain_loss: 0.0196 \n","[4/10] class_loss: 0.0484 s_domain_loss: 0.0062 t_domain_loss: 0.0190 \n","[5/10] class_loss: 0.0470 s_domain_loss: 0.0010 t_domain_loss: 0.0248 \n","[6/10] class_loss: 0.0640 s_domain_loss: 0.0320 t_domain_loss: 0.0297 \n","[7/10] class_loss: 0.0645 s_domain_loss: 0.0121 t_domain_loss: 0.0193 \n","[8/10] class_loss: 0.0186 s_domain_loss: 0.0052 t_domain_loss: 0.0162 \n","[9/10] class_loss: 0.0386 s_domain_loss: 0.0130 t_domain_loss: 0.0123 \n","[10/10] class_loss: 0.0253 s_domain_loss: 0.0229 t_domain_loss: 0.0060 \n","\n","Epoch 0016 / 0020\n","=================\n","[1/10] class_loss: 0.0209 s_domain_loss: 0.0065 t_domain_loss: 0.0094 \n","[2/10] class_loss: 0.0295 s_domain_loss: 0.0062 t_domain_loss: 0.0069 \n","[3/10] class_loss: 0.0092 s_domain_loss: 0.0036 t_domain_loss: 0.0068 \n","[4/10] class_loss: 0.0083 s_domain_loss: 0.0074 t_domain_loss: 0.0049 \n","[5/10] class_loss: 0.0183 s_domain_loss: 0.0358 t_domain_loss: 0.0050 \n","[6/10] class_loss: 0.0178 s_domain_loss: 0.0303 t_domain_loss: 0.0056 \n","[7/10] class_loss: 0.0101 s_domain_loss: 0.0124 t_domain_loss: 0.0065 \n","[8/10] class_loss: 0.0086 s_domain_loss: 0.0057 t_domain_loss: 0.0072 \n","[9/10] class_loss: 0.0148 s_domain_loss: 0.0058 t_domain_loss: 0.0073 \n","[10/10] class_loss: 0.0160 s_domain_loss: 0.0093 t_domain_loss: 0.0060 \n","\n","Epoch 0017 / 0020\n","=================\n","[1/10] class_loss: 0.0089 s_domain_loss: 0.0185 t_domain_loss: 0.0099 \n","[2/10] class_loss: 0.0143 s_domain_loss: 0.0127 t_domain_loss: 0.0106 \n","[3/10] class_loss: 0.0064 s_domain_loss: 0.0032 t_domain_loss: 0.0122 \n","[4/10] class_loss: 0.0072 s_domain_loss: 0.0017 t_domain_loss: 0.0125 \n","[5/10] class_loss: 0.0097 s_domain_loss: 0.0048 t_domain_loss: 0.0137 \n","[6/10] class_loss: 0.0104 s_domain_loss: 0.0036 t_domain_loss: 0.0139 \n","[7/10] class_loss: 0.0102 s_domain_loss: 0.0259 t_domain_loss: 0.0128 \n","[8/10] class_loss: 0.0110 s_domain_loss: 0.0345 t_domain_loss: 0.0104 \n","[9/10] class_loss: 0.0083 s_domain_loss: 0.0015 t_domain_loss: 0.0100 \n","[10/10] class_loss: 0.0059 s_domain_loss: 0.0027 t_domain_loss: 0.0064 \n","\n","Epoch 0018 / 0020\n","=================\n","[1/10] class_loss: 0.0053 s_domain_loss: 0.0039 t_domain_loss: 0.0097 \n","[2/10] class_loss: 0.0055 s_domain_loss: 0.0094 t_domain_loss: 0.0085 \n","[3/10] class_loss: 0.0073 s_domain_loss: 0.0003 t_domain_loss: 0.0079 \n","[4/10] class_loss: 0.0049 s_domain_loss: 0.0312 t_domain_loss: 0.0071 \n","[5/10] class_loss: 0.0053 s_domain_loss: 0.0043 t_domain_loss: 0.0086 \n","[6/10] class_loss: 0.0156 s_domain_loss: 0.0062 t_domain_loss: 0.0087 \n","[7/10] class_loss: 0.0049 s_domain_loss: 0.0008 t_domain_loss: 0.0084 \n","[8/10] class_loss: 0.0073 s_domain_loss: 0.0082 t_domain_loss: 0.0071 \n","[9/10] class_loss: 0.0068 s_domain_loss: 0.0217 t_domain_loss: 0.0062 \n","[10/10] class_loss: 0.0021 s_domain_loss: 0.0017 t_domain_loss: 0.0035 \n","\n","Epoch 0019 / 0020\n","=================\n","[1/10] class_loss: 0.0053 s_domain_loss: 0.0053 t_domain_loss: 0.0062 \n","[2/10] class_loss: 0.0051 s_domain_loss: 0.0003 t_domain_loss: 0.0059 \n","[3/10] class_loss: 0.0066 s_domain_loss: 0.0018 t_domain_loss: 0.0055 \n","[4/10] class_loss: 0.0048 s_domain_loss: 0.0040 t_domain_loss: 0.0051 \n","[5/10] class_loss: 0.0059 s_domain_loss: 0.0044 t_domain_loss: 0.0052 \n","[6/10] class_loss: 0.0090 s_domain_loss: 0.0059 t_domain_loss: 0.0051 \n","[7/10] class_loss: 0.0054 s_domain_loss: 0.0066 t_domain_loss: 0.0051 \n","[8/10] class_loss: 0.0042 s_domain_loss: 0.0027 t_domain_loss: 0.0045 \n","[9/10] class_loss: 0.0050 s_domain_loss: 0.0061 t_domain_loss: 0.0040 \n","[10/10] class_loss: 0.0045 s_domain_loss: 0.0033 t_domain_loss: 0.0021 \n","\n","Epoch 0020 / 0020\n","=================\n","[1/10] class_loss: 0.0014 s_domain_loss: 0.0022 t_domain_loss: 0.0038 \n","[2/10] class_loss: 0.0057 s_domain_loss: 0.0177 t_domain_loss: 0.0037 \n","[3/10] class_loss: 0.0032 s_domain_loss: 0.0035 t_domain_loss: 0.0036 \n","[4/10] class_loss: 0.0031 s_domain_loss: 0.0070 t_domain_loss: 0.0036 \n","[5/10] class_loss: 0.0029 s_domain_loss: 0.0011 t_domain_loss: 0.0039 \n","[6/10] class_loss: 0.0033 s_domain_loss: 0.0067 t_domain_loss: 0.0041 \n","[7/10] class_loss: 0.0080 s_domain_loss: 0.0207 t_domain_loss: 0.0043 \n","[8/10] class_loss: 0.0031 s_domain_loss: 0.0031 t_domain_loss: 0.0040 \n","[9/10] class_loss: 0.0023 s_domain_loss: 0.0048 t_domain_loss: 0.0039 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[10/10] class_loss: 0.0014 s_domain_loss: 0.0007 t_domain_loss: 0.0021 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.2333984375\n","hyperprameters are: LR=0.005 and NUM_EPOCHS = 30\n","\n","Epoch 0001 / 0030\n","=================\n","[1/10] class_loss: 2.1287 s_domain_loss: 0.5619 t_domain_loss: 0.8853 \n","[2/10] class_loss: 1.2723 s_domain_loss: 1.0683 t_domain_loss: 0.4475 \n","[3/10] class_loss: 0.8202 s_domain_loss: 0.4791 t_domain_loss: 0.9795 \n","[4/10] class_loss: 0.5466 s_domain_loss: 0.6938 t_domain_loss: 0.7049 \n","[5/10] class_loss: 0.4383 s_domain_loss: 0.9202 t_domain_loss: 0.5207 \n","[6/10] class_loss: 0.3227 s_domain_loss: 0.4500 t_domain_loss: 1.0129 \n","[7/10] class_loss: 0.2891 s_domain_loss: 0.8569 t_domain_loss: 0.5415 \n","[8/10] class_loss: 0.2342 s_domain_loss: 0.7333 t_domain_loss: 0.6493 \n","[9/10] class_loss: 0.1923 s_domain_loss: 0.4857 t_domain_loss: 0.9134 \n","[10/10] class_loss: 0.2477 s_domain_loss: 0.8911 t_domain_loss: 0.5043 \n","\n","Epoch 0002 / 0030\n","=================\n","[1/10] class_loss: 0.1334 s_domain_loss: 0.6145 t_domain_loss: 0.7128 \n","[2/10] class_loss: 0.1233 s_domain_loss: 0.5213 t_domain_loss: 0.8282 \n","[3/10] class_loss: 0.1950 s_domain_loss: 0.9056 t_domain_loss: 0.4597 \n","[4/10] class_loss: 0.1434 s_domain_loss: 0.4885 t_domain_loss: 0.8481 \n","[5/10] class_loss: 0.2485 s_domain_loss: 0.6872 t_domain_loss: 0.6223 \n","[6/10] class_loss: 0.1207 s_domain_loss: 0.7331 t_domain_loss: 0.5642 \n","[7/10] class_loss: 0.1424 s_domain_loss: 0.4983 t_domain_loss: 0.8188 \n","[8/10] class_loss: 0.0967 s_domain_loss: 0.7968 t_domain_loss: 0.4959 \n","[9/10] class_loss: 0.0957 s_domain_loss: 0.5902 t_domain_loss: 0.6893 \n","[10/10] class_loss: 0.0797 s_domain_loss: 0.5245 t_domain_loss: 0.7339 \n","\n","Epoch 0003 / 0030\n","=================\n","[1/10] class_loss: 0.0927 s_domain_loss: 0.8027 t_domain_loss: 0.4599 \n","[2/10] class_loss: 0.1303 s_domain_loss: 0.4961 t_domain_loss: 0.7705 \n","[3/10] class_loss: 0.0678 s_domain_loss: 0.5613 t_domain_loss: 0.6177 \n","[4/10] class_loss: 0.0671 s_domain_loss: 0.8082 t_domain_loss: 0.4392 \n","[5/10] class_loss: 0.0823 s_domain_loss: 0.4034 t_domain_loss: 0.8060 \n","[6/10] class_loss: 0.0715 s_domain_loss: 0.6320 t_domain_loss: 0.5120 \n","[7/10] class_loss: 0.0619 s_domain_loss: 0.7693 t_domain_loss: 0.4930 \n","[8/10] class_loss: 0.0971 s_domain_loss: 0.3710 t_domain_loss: 0.8579 \n","[9/10] class_loss: 0.0626 s_domain_loss: 0.7385 t_domain_loss: 0.4238 \n","[10/10] class_loss: 0.0624 s_domain_loss: 0.6074 t_domain_loss: 0.4609 \n","\n","Epoch 0004 / 0030\n","=================\n","[1/10] class_loss: 0.0524 s_domain_loss: 0.3625 t_domain_loss: 0.7674 \n","[2/10] class_loss: 0.0706 s_domain_loss: 0.6917 t_domain_loss: 0.4041 \n","[3/10] class_loss: 0.0518 s_domain_loss: 0.5772 t_domain_loss: 0.4749 \n","[4/10] class_loss: 0.0594 s_domain_loss: 0.4084 t_domain_loss: 0.7362 \n","[5/10] class_loss: 0.0621 s_domain_loss: 0.5627 t_domain_loss: 0.4394 \n","[6/10] class_loss: 0.0488 s_domain_loss: 0.6619 t_domain_loss: 0.3504 \n","[7/10] class_loss: 0.0638 s_domain_loss: 0.3147 t_domain_loss: 0.7087 \n","[8/10] class_loss: 0.0511 s_domain_loss: 0.6582 t_domain_loss: 0.4052 \n","[9/10] class_loss: 0.0628 s_domain_loss: 0.4200 t_domain_loss: 0.4698 \n","[10/10] class_loss: 0.0507 s_domain_loss: 0.5016 t_domain_loss: 0.3713 \n","\n","Epoch 0005 / 0030\n","=================\n","[1/10] class_loss: 0.0447 s_domain_loss: 0.3519 t_domain_loss: 0.5977 \n","[2/10] class_loss: 0.0155 s_domain_loss: 0.4845 t_domain_loss: 0.4111 \n","[3/10] class_loss: 0.0581 s_domain_loss: 0.7236 t_domain_loss: 0.2518 \n","[4/10] class_loss: 0.0560 s_domain_loss: 0.2472 t_domain_loss: 0.6997 \n","[5/10] class_loss: 0.0560 s_domain_loss: 0.3784 t_domain_loss: 0.4031 \n","[6/10] class_loss: 0.0392 s_domain_loss: 0.6819 t_domain_loss: 0.2093 \n","[7/10] class_loss: 0.0381 s_domain_loss: 0.2459 t_domain_loss: 0.5170 \n","[8/10] class_loss: 0.0582 s_domain_loss: 0.3843 t_domain_loss: 0.4105 \n","[9/10] class_loss: 0.0288 s_domain_loss: 0.4658 t_domain_loss: 0.3013 \n","[10/10] class_loss: 0.0243 s_domain_loss: 0.4141 t_domain_loss: 0.2688 \n","\n","Epoch 0006 / 0030\n","=================\n","[1/10] class_loss: 0.0312 s_domain_loss: 0.1683 t_domain_loss: 0.5997 \n","[2/10] class_loss: 0.0299 s_domain_loss: 0.4096 t_domain_loss: 0.2434 \n","[3/10] class_loss: 0.0275 s_domain_loss: 0.4770 t_domain_loss: 0.1658 \n","[4/10] class_loss: 0.0515 s_domain_loss: 0.1742 t_domain_loss: 0.3931 \n","[5/10] class_loss: 0.0415 s_domain_loss: 0.2433 t_domain_loss: 0.3592 \n","[6/10] class_loss: 0.0537 s_domain_loss: 0.5370 t_domain_loss: 0.1806 \n","[7/10] class_loss: 0.0246 s_domain_loss: 0.2391 t_domain_loss: 0.2985 \n","[8/10] class_loss: 0.0447 s_domain_loss: 0.2099 t_domain_loss: 0.3124 \n","[9/10] class_loss: 0.0492 s_domain_loss: 0.2990 t_domain_loss: 0.1962 \n","[10/10] class_loss: 0.0418 s_domain_loss: 0.3726 t_domain_loss: 0.1166 \n","\n","Epoch 0007 / 0030\n","=================\n","[1/10] class_loss: 0.0202 s_domain_loss: 0.1195 t_domain_loss: 0.3914 \n","[2/10] class_loss: 0.0370 s_domain_loss: 0.3040 t_domain_loss: 0.2820 \n","[3/10] class_loss: 0.0473 s_domain_loss: 0.3909 t_domain_loss: 0.1234 \n","[4/10] class_loss: 0.0641 s_domain_loss: 0.3872 t_domain_loss: 0.1756 \n","[5/10] class_loss: 0.0348 s_domain_loss: 0.0417 t_domain_loss: 0.5003 \n","[6/10] class_loss: 0.0461 s_domain_loss: 0.1583 t_domain_loss: 0.2470 \n","[7/10] class_loss: 0.0571 s_domain_loss: 0.5109 t_domain_loss: 0.0669 \n","[8/10] class_loss: 0.0581 s_domain_loss: 0.6058 t_domain_loss: 0.0623 \n","[9/10] class_loss: 0.0846 s_domain_loss: 0.0498 t_domain_loss: 0.3612 \n","[10/10] class_loss: 0.0716 s_domain_loss: 0.1052 t_domain_loss: 0.3169 \n","\n","Epoch 0008 / 0030\n","=================\n","[1/10] class_loss: 0.0607 s_domain_loss: 0.0840 t_domain_loss: 0.1997 \n","[2/10] class_loss: 0.0311 s_domain_loss: 0.2608 t_domain_loss: 0.0553 \n","[3/10] class_loss: 0.0365 s_domain_loss: 0.3533 t_domain_loss: 0.0349 \n","[4/10] class_loss: 0.0506 s_domain_loss: 0.1437 t_domain_loss: 0.0900 \n","[5/10] class_loss: 0.0854 s_domain_loss: 0.0426 t_domain_loss: 0.2063 \n","[6/10] class_loss: 0.0711 s_domain_loss: 0.1341 t_domain_loss: 0.2376 \n","[7/10] class_loss: 0.0485 s_domain_loss: 0.1500 t_domain_loss: 0.1572 \n","[8/10] class_loss: 0.0552 s_domain_loss: 0.1728 t_domain_loss: 0.1088 \n","[9/10] class_loss: 0.0312 s_domain_loss: 0.1112 t_domain_loss: 0.0625 \n","[10/10] class_loss: 0.0495 s_domain_loss: 0.1221 t_domain_loss: 0.0247 \n","\n","Epoch 0009 / 0030\n","=================\n","[1/10] class_loss: 0.0888 s_domain_loss: 0.1741 t_domain_loss: 0.0521 \n","[2/10] class_loss: 0.0475 s_domain_loss: 0.0429 t_domain_loss: 0.1008 \n","[3/10] class_loss: 0.0373 s_domain_loss: 0.0559 t_domain_loss: 0.1214 \n","[4/10] class_loss: 0.0215 s_domain_loss: 0.0712 t_domain_loss: 0.0893 \n","[5/10] class_loss: 0.0483 s_domain_loss: 0.0831 t_domain_loss: 0.0699 \n","[6/10] class_loss: 0.0541 s_domain_loss: 0.1191 t_domain_loss: 0.0492 \n","[7/10] class_loss: 0.0455 s_domain_loss: 0.0601 t_domain_loss: 0.0457 \n","[8/10] class_loss: 0.0574 s_domain_loss: 0.1385 t_domain_loss: 0.0429 \n","[9/10] class_loss: 0.0218 s_domain_loss: 0.0668 t_domain_loss: 0.0543 \n","[10/10] class_loss: 0.0656 s_domain_loss: 0.0472 t_domain_loss: 0.0400 \n","\n","Epoch 0010 / 0030\n","=================\n","[1/10] class_loss: 0.0493 s_domain_loss: 0.0318 t_domain_loss: 0.1402 \n","[2/10] class_loss: 0.0448 s_domain_loss: 0.0157 t_domain_loss: 0.0535 \n","[3/10] class_loss: 0.0573 s_domain_loss: 0.1029 t_domain_loss: 0.0318 \n","[4/10] class_loss: 0.0285 s_domain_loss: 0.1142 t_domain_loss: 0.0224 \n","[5/10] class_loss: 0.0206 s_domain_loss: 0.0562 t_domain_loss: 0.0228 \n","[6/10] class_loss: 0.0355 s_domain_loss: 0.0234 t_domain_loss: 0.0353 \n","[7/10] class_loss: 0.0380 s_domain_loss: 0.2303 t_domain_loss: 0.0481 \n","[8/10] class_loss: 0.0290 s_domain_loss: 0.0255 t_domain_loss: 0.1070 \n","[9/10] class_loss: 0.0893 s_domain_loss: 0.0787 t_domain_loss: 0.1286 \n","[10/10] class_loss: 0.0459 s_domain_loss: 0.2479 t_domain_loss: 0.0874 \n","\n","Epoch 0011 / 0030\n","=================\n","[1/10] class_loss: 0.1139 s_domain_loss: 0.1602 t_domain_loss: 0.1208 \n","[2/10] class_loss: 0.1423 s_domain_loss: 0.6889 t_domain_loss: 0.1719 \n","[3/10] class_loss: 0.3719 s_domain_loss: 0.1170 t_domain_loss: 1.1302 \n","[4/10] class_loss: 0.3874 s_domain_loss: 0.4213 t_domain_loss: 0.2076 \n","[5/10] class_loss: 0.3635 s_domain_loss: 0.7749 t_domain_loss: 0.1036 \n","[6/10] class_loss: 0.2580 s_domain_loss: 0.0795 t_domain_loss: 0.2435 \n","[7/10] class_loss: 0.2000 s_domain_loss: 0.0954 t_domain_loss: 0.2820 \n","[8/10] class_loss: 0.3057 s_domain_loss: 0.4032 t_domain_loss: 0.1243 \n","[9/10] class_loss: 0.2250 s_domain_loss: 0.1216 t_domain_loss: 0.0654 \n","[10/10] class_loss: 0.1857 s_domain_loss: 1.5967 t_domain_loss: 0.0357 \n","\n","Epoch 0012 / 0030\n","=================\n","[1/10] class_loss: 0.1579 s_domain_loss: 0.0266 t_domain_loss: 0.7179 \n","[2/10] class_loss: 0.1953 s_domain_loss: 0.0717 t_domain_loss: 0.7778 \n","[3/10] class_loss: 0.1938 s_domain_loss: 0.7490 t_domain_loss: 0.1039 \n","[4/10] class_loss: 0.3286 s_domain_loss: 0.2950 t_domain_loss: 0.0272 \n","[5/10] class_loss: 0.4240 s_domain_loss: 1.4315 t_domain_loss: 0.0223 \n","[6/10] class_loss: 0.2027 s_domain_loss: 0.0258 t_domain_loss: 0.3961 \n","[7/10] class_loss: 0.3088 s_domain_loss: 0.0185 t_domain_loss: 0.9272 \n","[8/10] class_loss: 0.3926 s_domain_loss: 0.1344 t_domain_loss: 0.5245 \n","[9/10] class_loss: 0.2335 s_domain_loss: 0.4955 t_domain_loss: 0.0269 \n","[10/10] class_loss: 0.2619 s_domain_loss: 0.7485 t_domain_loss: 0.0028 \n","\n","Epoch 0013 / 0030\n","=================\n","[1/10] class_loss: 0.3123 s_domain_loss: 0.3383 t_domain_loss: 0.0138 \n","[2/10] class_loss: 0.2584 s_domain_loss: 0.0361 t_domain_loss: 0.0464 \n","[3/10] class_loss: 0.2391 s_domain_loss: 0.0167 t_domain_loss: 0.1469 \n","[4/10] class_loss: 0.1922 s_domain_loss: 0.0129 t_domain_loss: 0.1914 \n","[5/10] class_loss: 0.1826 s_domain_loss: 0.0229 t_domain_loss: 0.1305 \n","[6/10] class_loss: 0.1254 s_domain_loss: 0.0541 t_domain_loss: 0.0697 \n","[7/10] class_loss: 0.1238 s_domain_loss: 0.0978 t_domain_loss: 0.0327 \n","[8/10] class_loss: 0.1483 s_domain_loss: 0.1673 t_domain_loss: 0.0187 \n","[9/10] class_loss: 0.1611 s_domain_loss: 0.1008 t_domain_loss: 0.0142 \n","[10/10] class_loss: 0.1351 s_domain_loss: 0.1641 t_domain_loss: 0.0149 \n","\n","Epoch 0014 / 0030\n","=================\n","[1/10] class_loss: 0.1206 s_domain_loss: 0.0152 t_domain_loss: 0.0917 \n","[2/10] class_loss: 0.1268 s_domain_loss: 0.0058 t_domain_loss: 0.0566 \n","[3/10] class_loss: 0.1629 s_domain_loss: 0.0105 t_domain_loss: 0.0666 \n","[4/10] class_loss: 0.1967 s_domain_loss: 0.0456 t_domain_loss: 0.0446 \n","[5/10] class_loss: 0.1161 s_domain_loss: 0.0252 t_domain_loss: 0.0215 \n","[6/10] class_loss: 0.0738 s_domain_loss: 0.0235 t_domain_loss: 0.0221 \n","[7/10] class_loss: 0.0800 s_domain_loss: 0.0540 t_domain_loss: 0.0166 \n","[8/10] class_loss: 0.0659 s_domain_loss: 0.0251 t_domain_loss: 0.0203 \n","[9/10] class_loss: 0.1126 s_domain_loss: 0.0154 t_domain_loss: 0.0275 \n","[10/10] class_loss: 0.0667 s_domain_loss: 0.0047 t_domain_loss: 0.0109 \n","\n","Epoch 0015 / 0030\n","=================\n","[1/10] class_loss: 0.0443 s_domain_loss: 0.0137 t_domain_loss: 0.0178 \n","[2/10] class_loss: 0.0396 s_domain_loss: 0.0592 t_domain_loss: 0.0124 \n","[3/10] class_loss: 0.0419 s_domain_loss: 0.0504 t_domain_loss: 0.0103 \n","[4/10] class_loss: 0.0435 s_domain_loss: 0.0188 t_domain_loss: 0.0091 \n","[5/10] class_loss: 0.0374 s_domain_loss: 0.0080 t_domain_loss: 0.0116 \n","[6/10] class_loss: 0.0439 s_domain_loss: 0.0092 t_domain_loss: 0.0162 \n","[7/10] class_loss: 0.0550 s_domain_loss: 0.0101 t_domain_loss: 0.0171 \n","[8/10] class_loss: 0.0535 s_domain_loss: 0.0038 t_domain_loss: 0.0193 \n","[9/10] class_loss: 0.0448 s_domain_loss: 0.0415 t_domain_loss: 0.0163 \n","[10/10] class_loss: 0.0394 s_domain_loss: 0.0248 t_domain_loss: 0.0128 \n","\n","Epoch 0016 / 0030\n","=================\n","[1/10] class_loss: 0.0361 s_domain_loss: 0.0081 t_domain_loss: 0.0159 \n","[2/10] class_loss: 0.0167 s_domain_loss: 0.0029 t_domain_loss: 0.0146 \n","[3/10] class_loss: 0.0303 s_domain_loss: 0.0083 t_domain_loss: 0.0135 \n","[4/10] class_loss: 0.0178 s_domain_loss: 0.0103 t_domain_loss: 0.0110 \n","[5/10] class_loss: 0.0242 s_domain_loss: 0.0013 t_domain_loss: 0.0095 \n","[6/10] class_loss: 0.0262 s_domain_loss: 0.0038 t_domain_loss: 0.0083 \n","[7/10] class_loss: 0.0174 s_domain_loss: 0.0018 t_domain_loss: 0.0078 \n","[8/10] class_loss: 0.0226 s_domain_loss: 0.0153 t_domain_loss: 0.0080 \n","[9/10] class_loss: 0.0339 s_domain_loss: 0.0127 t_domain_loss: 0.0064 \n","[10/10] class_loss: 0.0121 s_domain_loss: 0.0090 t_domain_loss: 0.0032 \n","\n","Epoch 0017 / 0030\n","=================\n","[1/10] class_loss: 0.0168 s_domain_loss: 0.0020 t_domain_loss: 0.0049 \n","[2/10] class_loss: 0.0121 s_domain_loss: 0.0025 t_domain_loss: 0.0034 \n","[3/10] class_loss: 0.0091 s_domain_loss: 0.0048 t_domain_loss: 0.0037 \n","[4/10] class_loss: 0.0187 s_domain_loss: 0.0229 t_domain_loss: 0.0032 \n","[5/10] class_loss: 0.0183 s_domain_loss: 0.0208 t_domain_loss: 0.0033 \n","[6/10] class_loss: 0.0206 s_domain_loss: 0.0007 t_domain_loss: 0.0038 \n","[7/10] class_loss: 0.0169 s_domain_loss: 0.0147 t_domain_loss: 0.0043 \n","[8/10] class_loss: 0.0160 s_domain_loss: 0.0221 t_domain_loss: 0.0058 \n","[9/10] class_loss: 0.0205 s_domain_loss: 0.0021 t_domain_loss: 0.0070 \n","[10/10] class_loss: 0.0099 s_domain_loss: 0.0140 t_domain_loss: 0.0039 \n","\n","Epoch 0018 / 0030\n","=================\n","[1/10] class_loss: 0.0066 s_domain_loss: 0.0051 t_domain_loss: 0.0089 \n","[2/10] class_loss: 0.0116 s_domain_loss: 0.0025 t_domain_loss: 0.0070 \n","[3/10] class_loss: 0.0087 s_domain_loss: 0.0680 t_domain_loss: 0.0089 \n","[4/10] class_loss: 0.0075 s_domain_loss: 0.0097 t_domain_loss: 0.0106 \n","[5/10] class_loss: 0.0099 s_domain_loss: 0.0005 t_domain_loss: 0.0129 \n","[6/10] class_loss: 0.0129 s_domain_loss: 0.0016 t_domain_loss: 0.0154 \n","[7/10] class_loss: 0.0096 s_domain_loss: 0.0006 t_domain_loss: 0.0195 \n","[8/10] class_loss: 0.0087 s_domain_loss: 0.0026 t_domain_loss: 0.0197 \n","[9/10] class_loss: 0.0098 s_domain_loss: 0.0058 t_domain_loss: 0.0176 \n","[10/10] class_loss: 0.0123 s_domain_loss: 0.0035 t_domain_loss: 0.0083 \n","\n","Epoch 0019 / 0030\n","=================\n","[1/10] class_loss: 0.0108 s_domain_loss: 0.0004 t_domain_loss: 0.0083 \n","[2/10] class_loss: 0.0096 s_domain_loss: 0.0007 t_domain_loss: 0.0063 \n","[3/10] class_loss: 0.0109 s_domain_loss: 0.0063 t_domain_loss: 0.0055 \n","[4/10] class_loss: 0.0081 s_domain_loss: 0.0561 t_domain_loss: 0.0040 \n","[5/10] class_loss: 0.0110 s_domain_loss: 0.0112 t_domain_loss: 0.0043 \n","[6/10] class_loss: 0.0051 s_domain_loss: 0.3559 t_domain_loss: 0.0047 \n","[7/10] class_loss: 0.0075 s_domain_loss: 0.0033 t_domain_loss: 0.0205 \n","[8/10] class_loss: 0.3235 s_domain_loss: 0.7236 t_domain_loss: 0.2189 \n","[9/10] class_loss: 0.0114 s_domain_loss: 0.0000 t_domain_loss: 0.3652 \n","[10/10] class_loss: 0.1830 s_domain_loss: 0.0872 t_domain_loss: 0.2814 \n","\n","Epoch 0020 / 0030\n","=================\n","[1/10] class_loss: 0.2669 s_domain_loss: 1.1606 t_domain_loss: 0.1125 \n","[2/10] class_loss: 0.2255 s_domain_loss: 0.9718 t_domain_loss: 0.1182 \n","[3/10] class_loss: 0.2047 s_domain_loss: 1.5088 t_domain_loss: 0.1409 \n","[4/10] class_loss: 0.1778 s_domain_loss: 2.4611 t_domain_loss: 0.2307 \n","[5/10] class_loss: 0.2132 s_domain_loss: 0.4448 t_domain_loss: 0.3460 \n","[6/10] class_loss: 0.1530 s_domain_loss: 0.4697 t_domain_loss: 0.6116 \n","[7/10] class_loss: 0.1217 s_domain_loss: 0.3344 t_domain_loss: 0.8933 \n","[8/10] class_loss: 0.0943 s_domain_loss: 0.0950 t_domain_loss: 0.9484 \n","[9/10] class_loss: 0.1131 s_domain_loss: 0.4017 t_domain_loss: 0.8234 \n","[10/10] class_loss: 0.1221 s_domain_loss: 0.0400 t_domain_loss: 0.4853 \n","\n","Epoch 0021 / 0030\n","=================\n","[1/10] class_loss: 0.1165 s_domain_loss: 0.1852 t_domain_loss: 0.4223 \n","[2/10] class_loss: 0.0939 s_domain_loss: 0.0454 t_domain_loss: 0.2561 \n","[3/10] class_loss: 0.0747 s_domain_loss: 0.0743 t_domain_loss: 0.1449 \n","[4/10] class_loss: 0.0575 s_domain_loss: 0.1660 t_domain_loss: 0.0748 \n","[5/10] class_loss: 0.0652 s_domain_loss: 0.4923 t_domain_loss: 0.0468 \n","[6/10] class_loss: 0.0404 s_domain_loss: 0.1993 t_domain_loss: 0.0334 \n","[7/10] class_loss: 0.0608 s_domain_loss: 0.4204 t_domain_loss: 0.0304 \n","[8/10] class_loss: 0.0603 s_domain_loss: 0.0454 t_domain_loss: 0.0294 \n","[9/10] class_loss: 0.0257 s_domain_loss: 0.0113 t_domain_loss: 0.0254 \n","[10/10] class_loss: 0.0704 s_domain_loss: 0.0143 t_domain_loss: 0.0172 \n","\n","Epoch 0022 / 0030\n","=================\n","[1/10] class_loss: 0.0515 s_domain_loss: 0.0037 t_domain_loss: 0.0249 \n","[2/10] class_loss: 0.0305 s_domain_loss: 0.0039 t_domain_loss: 0.0202 \n","[3/10] class_loss: 0.0281 s_domain_loss: 0.0042 t_domain_loss: 0.0210 \n","[4/10] class_loss: 0.0345 s_domain_loss: 0.0012 t_domain_loss: 0.0171 \n","[5/10] class_loss: 0.0305 s_domain_loss: 0.0007 t_domain_loss: 0.0181 \n","[6/10] class_loss: 0.0261 s_domain_loss: 0.0315 t_domain_loss: 0.0177 \n","[7/10] class_loss: 0.0294 s_domain_loss: 0.0367 t_domain_loss: 0.0174 \n","[8/10] class_loss: 0.0266 s_domain_loss: 0.0015 t_domain_loss: 0.0170 \n","[9/10] class_loss: 0.0442 s_domain_loss: 0.0033 t_domain_loss: 0.0189 \n","[10/10] class_loss: 0.0421 s_domain_loss: 0.0177 t_domain_loss: 0.0147 \n","\n","Epoch 0023 / 0030\n","=================\n","[1/10] class_loss: 0.0298 s_domain_loss: 0.0041 t_domain_loss: 0.0433 \n","[2/10] class_loss: 0.0384 s_domain_loss: 0.0074 t_domain_loss: 0.0189 \n","[3/10] class_loss: 0.0284 s_domain_loss: 0.0187 t_domain_loss: 0.0175 \n","[4/10] class_loss: 0.0175 s_domain_loss: 0.0078 t_domain_loss: 0.0107 \n","[5/10] class_loss: 0.0301 s_domain_loss: 0.0440 t_domain_loss: 0.0123 \n","[6/10] class_loss: 0.0285 s_domain_loss: 0.0140 t_domain_loss: 0.0179 \n","[7/10] class_loss: 0.0432 s_domain_loss: 0.0221 t_domain_loss: 0.0111 \n","[8/10] class_loss: 0.0273 s_domain_loss: 0.0653 t_domain_loss: 0.0107 \n","[9/10] class_loss: 0.0231 s_domain_loss: 0.0041 t_domain_loss: 0.0142 \n","[10/10] class_loss: 0.0236 s_domain_loss: 0.0027 t_domain_loss: 0.0140 \n","\n","Epoch 0024 / 0030\n","=================\n","[1/10] class_loss: 0.0188 s_domain_loss: 0.0064 t_domain_loss: 0.0325 \n","[2/10] class_loss: 0.0128 s_domain_loss: 0.0012 t_domain_loss: 0.0117 \n","[3/10] class_loss: 0.0378 s_domain_loss: 0.0087 t_domain_loss: 0.0115 \n","[4/10] class_loss: 0.0178 s_domain_loss: 0.0069 t_domain_loss: 0.0079 \n","[5/10] class_loss: 0.0173 s_domain_loss: 0.0048 t_domain_loss: 0.0084 \n","[6/10] class_loss: 0.0096 s_domain_loss: 0.0036 t_domain_loss: 0.0099 \n","[7/10] class_loss: 0.0109 s_domain_loss: 0.0043 t_domain_loss: 0.0077 \n","[8/10] class_loss: 0.0192 s_domain_loss: 0.0459 t_domain_loss: 0.0082 \n","[9/10] class_loss: 0.0159 s_domain_loss: 0.0051 t_domain_loss: 0.0086 \n","[10/10] class_loss: 0.0148 s_domain_loss: 0.0065 t_domain_loss: 0.0049 \n","\n","Epoch 0025 / 0030\n","=================\n","[1/10] class_loss: 0.0159 s_domain_loss: 0.0025 t_domain_loss: 0.0132 \n","[2/10] class_loss: 0.0161 s_domain_loss: 0.0168 t_domain_loss: 0.0069 \n","[3/10] class_loss: 0.0139 s_domain_loss: 0.0088 t_domain_loss: 0.0074 \n","[4/10] class_loss: 0.0179 s_domain_loss: 0.0083 t_domain_loss: 0.0065 \n","[5/10] class_loss: 0.0105 s_domain_loss: 0.0019 t_domain_loss: 0.0067 \n","[6/10] class_loss: 0.0103 s_domain_loss: 0.0093 t_domain_loss: 0.0070 \n","[7/10] class_loss: 0.0103 s_domain_loss: 0.0038 t_domain_loss: 0.0065 \n","[8/10] class_loss: 0.0126 s_domain_loss: 0.0091 t_domain_loss: 0.0074 \n","[9/10] class_loss: 0.0125 s_domain_loss: 0.0295 t_domain_loss: 0.0072 \n","[10/10] class_loss: 0.0112 s_domain_loss: 0.0050 t_domain_loss: 0.0040 \n","\n","Epoch 0026 / 0030\n","=================\n","[1/10] class_loss: 0.0103 s_domain_loss: 0.0017 t_domain_loss: 0.0094 \n","[2/10] class_loss: 0.0069 s_domain_loss: 0.0008 t_domain_loss: 0.0061 \n","[3/10] class_loss: 0.0251 s_domain_loss: 0.0026 t_domain_loss: 0.0065 \n","[4/10] class_loss: 0.0125 s_domain_loss: 0.0029 t_domain_loss: 0.0061 \n","[5/10] class_loss: 0.0121 s_domain_loss: 0.0421 t_domain_loss: 0.0062 \n","[6/10] class_loss: 0.0108 s_domain_loss: 0.0105 t_domain_loss: 0.0063 \n","[7/10] class_loss: 0.0142 s_domain_loss: 0.0007 t_domain_loss: 0.0063 \n","[8/10] class_loss: 0.0126 s_domain_loss: 0.0032 t_domain_loss: 0.0073 \n","[9/10] class_loss: 0.0103 s_domain_loss: 0.0025 t_domain_loss: 0.0069 \n","[10/10] class_loss: 0.0169 s_domain_loss: 0.0007 t_domain_loss: 0.0039 \n","\n","Epoch 0027 / 0030\n","=================\n","[1/10] class_loss: 0.0085 s_domain_loss: 0.0037 t_domain_loss: 0.0085 \n","[2/10] class_loss: 0.0075 s_domain_loss: 0.0573 t_domain_loss: 0.0059 \n","[3/10] class_loss: 0.0136 s_domain_loss: 0.0023 t_domain_loss: 0.0065 \n","[4/10] class_loss: 0.0089 s_domain_loss: 0.0018 t_domain_loss: 0.0063 \n","[5/10] class_loss: 0.0112 s_domain_loss: 0.0012 t_domain_loss: 0.0065 \n","[6/10] class_loss: 0.0085 s_domain_loss: 0.0152 t_domain_loss: 0.0067 \n","[7/10] class_loss: 0.0153 s_domain_loss: 0.0010 t_domain_loss: 0.0067 \n","[8/10] class_loss: 0.0153 s_domain_loss: 0.0028 t_domain_loss: 0.0077 \n","[9/10] class_loss: 0.0076 s_domain_loss: 0.0016 t_domain_loss: 0.0072 \n","[10/10] class_loss: 0.0057 s_domain_loss: 0.0009 t_domain_loss: 0.0041 \n","\n","Epoch 0028 / 0030\n","=================\n","[1/10] class_loss: 0.0070 s_domain_loss: 0.0021 t_domain_loss: 0.0090 \n","[2/10] class_loss: 0.0096 s_domain_loss: 0.0019 t_domain_loss: 0.0063 \n","[3/10] class_loss: 0.0098 s_domain_loss: 0.0022 t_domain_loss: 0.0067 \n","[4/10] class_loss: 0.0084 s_domain_loss: 0.0008 t_domain_loss: 0.0063 \n","[5/10] class_loss: 0.0108 s_domain_loss: 0.0082 t_domain_loss: 0.0063 \n","[6/10] class_loss: 0.0145 s_domain_loss: 0.0061 t_domain_loss: 0.0064 \n","[7/10] class_loss: 0.0079 s_domain_loss: 0.0007 t_domain_loss: 0.0063 \n","[8/10] class_loss: 0.0085 s_domain_loss: 0.0005 t_domain_loss: 0.0071 \n","[9/10] class_loss: 0.0153 s_domain_loss: 0.0248 t_domain_loss: 0.0066 \n","[10/10] class_loss: 0.0079 s_domain_loss: 0.0035 t_domain_loss: 0.0036 \n","\n","Epoch 0029 / 0030\n","=================\n","[1/10] class_loss: 0.0076 s_domain_loss: 0.0006 t_domain_loss: 0.0082 \n","[2/10] class_loss: 0.0081 s_domain_loss: 0.0110 t_domain_loss: 0.0057 \n","[3/10] class_loss: 0.0095 s_domain_loss: 0.0024 t_domain_loss: 0.0061 \n","[4/10] class_loss: 0.0109 s_domain_loss: 0.0015 t_domain_loss: 0.0058 \n","[5/10] class_loss: 0.0092 s_domain_loss: 0.0032 t_domain_loss: 0.0058 \n","[6/10] class_loss: 0.0057 s_domain_loss: 0.0011 t_domain_loss: 0.0059 \n","[7/10] class_loss: 0.0085 s_domain_loss: 0.0127 t_domain_loss: 0.0058 \n","[8/10] class_loss: 0.0134 s_domain_loss: 0.0020 t_domain_loss: 0.0065 \n","[9/10] class_loss: 0.0054 s_domain_loss: 0.0065 t_domain_loss: 0.0061 \n","[10/10] class_loss: 0.0061 s_domain_loss: 0.0007 t_domain_loss: 0.0033 \n","\n","Epoch 0030 / 0030\n","=================\n","[1/10] class_loss: 0.0078 s_domain_loss: 0.0030 t_domain_loss: 0.0075 \n","[2/10] class_loss: 0.0091 s_domain_loss: 0.0015 t_domain_loss: 0.0052 \n","[3/10] class_loss: 0.0069 s_domain_loss: 0.0044 t_domain_loss: 0.0055 \n","[4/10] class_loss: 0.0092 s_domain_loss: 0.0010 t_domain_loss: 0.0053 \n","[5/10] class_loss: 0.0049 s_domain_loss: 0.0006 t_domain_loss: 0.0052 \n","[6/10] class_loss: 0.0053 s_domain_loss: 0.0027 t_domain_loss: 0.0053 \n","[7/10] class_loss: 0.0096 s_domain_loss: 0.0027 t_domain_loss: 0.0051 \n","[8/10] class_loss: 0.0091 s_domain_loss: 0.0399 t_domain_loss: 0.0058 \n","[9/10] class_loss: 0.0064 s_domain_loss: 0.0005 t_domain_loss: 0.0054 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[10/10] class_loss: 0.0051 s_domain_loss: 0.0155 t_domain_loss: 0.0030 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.22119140625\n","hyperprameters are: LR=0.006 and NUM_EPOCHS = 10\n","\n","Epoch 0001 / 0010\n","=================\n","[1/10] class_loss: 2.2389 s_domain_loss: 0.5348 t_domain_loss: 0.9450 \n","[2/10] class_loss: 1.2596 s_domain_loss: 1.3099 t_domain_loss: 0.3537 \n","[3/10] class_loss: 0.7342 s_domain_loss: 0.2499 t_domain_loss: 1.5570 \n","[4/10] class_loss: 0.6463 s_domain_loss: 1.3456 t_domain_loss: 0.3148 \n","[5/10] class_loss: 0.4344 s_domain_loss: 0.4493 t_domain_loss: 1.0336 \n","[6/10] class_loss: 0.3380 s_domain_loss: 0.7293 t_domain_loss: 0.6574 \n","[7/10] class_loss: 0.2176 s_domain_loss: 0.8823 t_domain_loss: 0.5190 \n","[8/10] class_loss: 0.2422 s_domain_loss: 0.3599 t_domain_loss: 1.1586 \n","[9/10] class_loss: 0.1829 s_domain_loss: 1.3293 t_domain_loss: 0.3022 \n","[10/10] class_loss: 0.3248 s_domain_loss: 0.3050 t_domain_loss: 1.2808 \n","\n","Epoch 0002 / 0010\n","=================\n","[1/10] class_loss: 0.2344 s_domain_loss: 1.0537 t_domain_loss: 0.4008 \n","[2/10] class_loss: 0.1689 s_domain_loss: 0.5122 t_domain_loss: 0.8467 \n","[3/10] class_loss: 0.1176 s_domain_loss: 0.6691 t_domain_loss: 0.6306 \n","[4/10] class_loss: 0.1364 s_domain_loss: 0.7704 t_domain_loss: 0.5598 \n","[5/10] class_loss: 0.1799 s_domain_loss: 0.4248 t_domain_loss: 0.9068 \n","[6/10] class_loss: 0.1912 s_domain_loss: 1.0334 t_domain_loss: 0.3775 \n","[7/10] class_loss: 0.0982 s_domain_loss: 0.3281 t_domain_loss: 1.1231 \n","[8/10] class_loss: 0.1096 s_domain_loss: 1.1254 t_domain_loss: 0.3257 \n","[9/10] class_loss: 0.0863 s_domain_loss: 0.3908 t_domain_loss: 0.9733 \n","[10/10] class_loss: 0.1476 s_domain_loss: 0.7858 t_domain_loss: 0.4408 \n","\n","Epoch 0003 / 0010\n","=================\n","[1/10] class_loss: 0.0627 s_domain_loss: 0.5524 t_domain_loss: 0.6983 \n","[2/10] class_loss: 0.0624 s_domain_loss: 0.5109 t_domain_loss: 0.6702 \n","[3/10] class_loss: 0.0857 s_domain_loss: 0.8134 t_domain_loss: 0.3887 \n","[4/10] class_loss: 0.0844 s_domain_loss: 0.3669 t_domain_loss: 0.9141 \n","[5/10] class_loss: 0.0804 s_domain_loss: 0.8747 t_domain_loss: 0.3651 \n","[6/10] class_loss: 0.0872 s_domain_loss: 0.4107 t_domain_loss: 0.8159 \n","[7/10] class_loss: 0.0882 s_domain_loss: 0.5944 t_domain_loss: 0.5234 \n","[8/10] class_loss: 0.0946 s_domain_loss: 0.7646 t_domain_loss: 0.4091 \n","[9/10] class_loss: 0.0443 s_domain_loss: 0.2959 t_domain_loss: 0.9746 \n","[10/10] class_loss: 0.0791 s_domain_loss: 0.8557 t_domain_loss: 0.2587 \n","\n","Epoch 0004 / 0010\n","=================\n","[1/10] class_loss: 0.0316 s_domain_loss: 0.3829 t_domain_loss: 0.7012 \n","[2/10] class_loss: 0.0524 s_domain_loss: 0.5110 t_domain_loss: 0.5288 \n","[3/10] class_loss: 0.0591 s_domain_loss: 0.6365 t_domain_loss: 0.3736 \n","[4/10] class_loss: 0.0657 s_domain_loss: 0.3423 t_domain_loss: 0.7084 \n","[5/10] class_loss: 0.0372 s_domain_loss: 0.6226 t_domain_loss: 0.3589 \n","[6/10] class_loss: 0.0525 s_domain_loss: 0.4392 t_domain_loss: 0.4586 \n","[7/10] class_loss: 0.0998 s_domain_loss: 0.4585 t_domain_loss: 0.5008 \n","[8/10] class_loss: 0.0485 s_domain_loss: 0.4614 t_domain_loss: 0.4338 \n","[9/10] class_loss: 0.0494 s_domain_loss: 0.4329 t_domain_loss: 0.3996 \n","[10/10] class_loss: 0.0337 s_domain_loss: 0.4716 t_domain_loss: 0.3077 \n","\n","Epoch 0005 / 0010\n","=================\n","[1/10] class_loss: 0.0153 s_domain_loss: 0.2458 t_domain_loss: 0.6475 \n","[2/10] class_loss: 0.0800 s_domain_loss: 0.4985 t_domain_loss: 0.2657 \n","[3/10] class_loss: 0.0857 s_domain_loss: 0.5264 t_domain_loss: 0.2520 \n","[4/10] class_loss: 0.0555 s_domain_loss: 0.1911 t_domain_loss: 0.7098 \n","[5/10] class_loss: 0.0439 s_domain_loss: 0.4132 t_domain_loss: 0.2632 \n","[6/10] class_loss: 0.0381 s_domain_loss: 0.5758 t_domain_loss: 0.1842 \n","[7/10] class_loss: 0.0354 s_domain_loss: 0.1534 t_domain_loss: 0.6168 \n","[8/10] class_loss: 0.0233 s_domain_loss: 0.4567 t_domain_loss: 0.2677 \n","[9/10] class_loss: 0.0537 s_domain_loss: 0.4769 t_domain_loss: 0.2301 \n","[10/10] class_loss: 0.0563 s_domain_loss: 0.3736 t_domain_loss: 0.3987 \n","\n","Epoch 0006 / 0010\n","=================\n","[1/10] class_loss: 0.0408 s_domain_loss: 0.1565 t_domain_loss: 0.5154 \n","[2/10] class_loss: 0.0707 s_domain_loss: 0.4463 t_domain_loss: 0.1200 \n","[3/10] class_loss: 0.0942 s_domain_loss: 0.7191 t_domain_loss: 0.1064 \n","[4/10] class_loss: 0.0438 s_domain_loss: 0.1184 t_domain_loss: 0.8417 \n","[5/10] class_loss: 0.0860 s_domain_loss: 0.9908 t_domain_loss: 0.5154 \n","[6/10] class_loss: 0.0417 s_domain_loss: 0.4782 t_domain_loss: 0.1240 \n","[7/10] class_loss: 0.1284 s_domain_loss: 0.4269 t_domain_loss: 0.1645 \n","[8/10] class_loss: 0.1226 s_domain_loss: 0.5007 t_domain_loss: 0.4007 \n","[9/10] class_loss: 0.0443 s_domain_loss: 0.0710 t_domain_loss: 0.8393 \n","[10/10] class_loss: 0.0614 s_domain_loss: 0.5732 t_domain_loss: 0.0787 \n","\n","Epoch 0007 / 0010\n","=================\n","[1/10] class_loss: 0.0521 s_domain_loss: 0.6190 t_domain_loss: 0.0692 \n","[2/10] class_loss: 0.0531 s_domain_loss: 0.1262 t_domain_loss: 0.4452 \n","[3/10] class_loss: 0.0577 s_domain_loss: 0.0916 t_domain_loss: 0.6120 \n","[4/10] class_loss: 0.0482 s_domain_loss: 0.3902 t_domain_loss: 0.0694 \n","[5/10] class_loss: 0.0636 s_domain_loss: 0.4931 t_domain_loss: 0.0347 \n","[6/10] class_loss: 0.0588 s_domain_loss: 0.2569 t_domain_loss: 0.1423 \n","[7/10] class_loss: 0.0614 s_domain_loss: 0.0443 t_domain_loss: 0.6434 \n","[8/10] class_loss: 0.0677 s_domain_loss: 0.1183 t_domain_loss: 0.1818 \n","[9/10] class_loss: 0.0552 s_domain_loss: 0.5689 t_domain_loss: 0.0336 \n","[10/10] class_loss: 0.0532 s_domain_loss: 0.2830 t_domain_loss: 0.0548 \n","\n","Epoch 0008 / 0010\n","=================\n","[1/10] class_loss: 0.0723 s_domain_loss: 0.0834 t_domain_loss: 0.3509 \n","[2/10] class_loss: 0.0383 s_domain_loss: 0.1091 t_domain_loss: 0.2714 \n","[3/10] class_loss: 0.0722 s_domain_loss: 0.2149 t_domain_loss: 0.0747 \n","[4/10] class_loss: 0.0508 s_domain_loss: 0.1377 t_domain_loss: 0.0371 \n","[5/10] class_loss: 0.0515 s_domain_loss: 0.1607 t_domain_loss: 0.0373 \n","[6/10] class_loss: 0.0540 s_domain_loss: 0.0921 t_domain_loss: 0.0724 \n","[7/10] class_loss: 0.0406 s_domain_loss: 0.0945 t_domain_loss: 0.1050 \n","[8/10] class_loss: 0.0398 s_domain_loss: 0.0756 t_domain_loss: 0.1432 \n","[9/10] class_loss: 0.0309 s_domain_loss: 0.0180 t_domain_loss: 0.1310 \n","[10/10] class_loss: 0.0439 s_domain_loss: 0.2409 t_domain_loss: 0.0308 \n","\n","Epoch 0009 / 0010\n","=================\n","[1/10] class_loss: 0.0540 s_domain_loss: 0.0675 t_domain_loss: 0.0546 \n","[2/10] class_loss: 0.0374 s_domain_loss: 0.0363 t_domain_loss: 0.0712 \n","[3/10] class_loss: 0.0346 s_domain_loss: 0.0537 t_domain_loss: 0.0679 \n","[4/10] class_loss: 0.0367 s_domain_loss: 0.0294 t_domain_loss: 0.0662 \n","[5/10] class_loss: 0.0449 s_domain_loss: 0.1295 t_domain_loss: 0.0512 \n","[6/10] class_loss: 0.0323 s_domain_loss: 0.1748 t_domain_loss: 0.0355 \n","[7/10] class_loss: 0.0244 s_domain_loss: 0.1021 t_domain_loss: 0.0647 \n","[8/10] class_loss: 0.0231 s_domain_loss: 0.0264 t_domain_loss: 0.0910 \n","[9/10] class_loss: 0.0492 s_domain_loss: 0.0408 t_domain_loss: 0.0894 \n","[10/10] class_loss: 0.0228 s_domain_loss: 0.0974 t_domain_loss: 0.0555 \n","\n","Epoch 0010 / 0010\n","=================\n","[1/10] class_loss: 0.1139 s_domain_loss: 0.0865 t_domain_loss: 0.0376 \n","[2/10] class_loss: 0.1501 s_domain_loss: 0.0548 t_domain_loss: 0.0307 \n","[3/10] class_loss: 0.0429 s_domain_loss: 0.0131 t_domain_loss: 0.0458 \n","[4/10] class_loss: 0.0481 s_domain_loss: 0.0117 t_domain_loss: 0.0258 \n","[5/10] class_loss: 0.0290 s_domain_loss: 0.0302 t_domain_loss: 0.0264 \n","[6/10] class_loss: 0.0521 s_domain_loss: 0.0537 t_domain_loss: 0.0195 \n","[7/10] class_loss: 0.0768 s_domain_loss: 0.0326 t_domain_loss: 0.0172 \n","[8/10] class_loss: 0.0862 s_domain_loss: 0.0442 t_domain_loss: 0.0151 \n","[9/10] class_loss: 0.0513 s_domain_loss: 0.0623 t_domain_loss: 0.0212 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[10/10] class_loss: 0.0489 s_domain_loss: 0.0713 t_domain_loss: 0.0126 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.01it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.25341796875\n","hyperprameters are: LR=0.006 and NUM_EPOCHS = 20\n","\n","Epoch 0001 / 0020\n","=================\n","[1/10] class_loss: 1.9241 s_domain_loss: 0.6877 t_domain_loss: 0.7388 \n","[2/10] class_loss: 1.2732 s_domain_loss: 0.7731 t_domain_loss: 0.6560 \n","[3/10] class_loss: 0.7029 s_domain_loss: 0.6019 t_domain_loss: 0.8263 \n","[4/10] class_loss: 0.4226 s_domain_loss: 0.8209 t_domain_loss: 0.6015 \n","[5/10] class_loss: 0.3354 s_domain_loss: 0.5671 t_domain_loss: 0.8528 \n","[6/10] class_loss: 0.3175 s_domain_loss: 0.8321 t_domain_loss: 0.5790 \n","[7/10] class_loss: 0.2625 s_domain_loss: 0.5418 t_domain_loss: 0.8585 \n","[8/10] class_loss: 0.2399 s_domain_loss: 0.8941 t_domain_loss: 0.5116 \n","[9/10] class_loss: 0.1903 s_domain_loss: 0.4614 t_domain_loss: 0.9569 \n","[10/10] class_loss: 0.2038 s_domain_loss: 0.9988 t_domain_loss: 0.4371 \n","\n","Epoch 0002 / 0020\n","=================\n","[1/10] class_loss: 0.2613 s_domain_loss: 0.3883 t_domain_loss: 1.0365 \n","[2/10] class_loss: 0.1310 s_domain_loss: 0.9862 t_domain_loss: 0.4133 \n","[3/10] class_loss: 0.1255 s_domain_loss: 0.4492 t_domain_loss: 0.9155 \n","[4/10] class_loss: 0.1992 s_domain_loss: 0.7866 t_domain_loss: 0.5316 \n","[5/10] class_loss: 0.1456 s_domain_loss: 0.6130 t_domain_loss: 0.6645 \n","[6/10] class_loss: 0.0860 s_domain_loss: 0.5410 t_domain_loss: 0.7340 \n","[7/10] class_loss: 0.0601 s_domain_loss: 0.9087 t_domain_loss: 0.4233 \n","[8/10] class_loss: 0.1061 s_domain_loss: 0.3307 t_domain_loss: 1.0708 \n","[9/10] class_loss: 0.0735 s_domain_loss: 1.1151 t_domain_loss: 0.3183 \n","[10/10] class_loss: 0.0473 s_domain_loss: 0.3553 t_domain_loss: 0.9729 \n","\n","Epoch 0003 / 0020\n","=================\n","[1/10] class_loss: 0.0579 s_domain_loss: 0.7778 t_domain_loss: 0.4369 \n","[2/10] class_loss: 0.0369 s_domain_loss: 0.5584 t_domain_loss: 0.6138 \n","[3/10] class_loss: 0.0821 s_domain_loss: 0.5039 t_domain_loss: 0.6839 \n","[4/10] class_loss: 0.0555 s_domain_loss: 0.7235 t_domain_loss: 0.4599 \n","[5/10] class_loss: 0.0807 s_domain_loss: 0.4451 t_domain_loss: 0.7033 \n","[6/10] class_loss: 0.0829 s_domain_loss: 0.7052 t_domain_loss: 0.4406 \n","[7/10] class_loss: 0.0370 s_domain_loss: 0.4594 t_domain_loss: 0.6478 \n","[8/10] class_loss: 0.0503 s_domain_loss: 0.6201 t_domain_loss: 0.4725 \n","[9/10] class_loss: 0.0374 s_domain_loss: 0.5109 t_domain_loss: 0.5981 \n","[10/10] class_loss: 0.0464 s_domain_loss: 0.5589 t_domain_loss: 0.4378 \n","\n","Epoch 0004 / 0020\n","=================\n","[1/10] class_loss: 0.0345 s_domain_loss: 0.4595 t_domain_loss: 0.5723 \n","[2/10] class_loss: 0.0353 s_domain_loss: 0.5115 t_domain_loss: 0.4580 \n","[3/10] class_loss: 0.0384 s_domain_loss: 0.4870 t_domain_loss: 0.4412 \n","[4/10] class_loss: 0.0446 s_domain_loss: 0.4729 t_domain_loss: 0.5415 \n","[5/10] class_loss: 0.0297 s_domain_loss: 0.4413 t_domain_loss: 0.4772 \n","[6/10] class_loss: 0.0387 s_domain_loss: 0.5660 t_domain_loss: 0.3444 \n","[7/10] class_loss: 0.0249 s_domain_loss: 0.3326 t_domain_loss: 0.5507 \n","[8/10] class_loss: 0.0497 s_domain_loss: 0.6531 t_domain_loss: 0.3210 \n","[9/10] class_loss: 0.0301 s_domain_loss: 0.3075 t_domain_loss: 0.6017 \n","[10/10] class_loss: 0.0269 s_domain_loss: 0.4445 t_domain_loss: 0.2658 \n","\n","Epoch 0005 / 0020\n","=================\n","[1/10] class_loss: 0.0257 s_domain_loss: 0.3879 t_domain_loss: 0.4463 \n","[2/10] class_loss: 0.0269 s_domain_loss: 0.3569 t_domain_loss: 0.3687 \n","[3/10] class_loss: 0.0260 s_domain_loss: 0.4084 t_domain_loss: 0.2662 \n","[4/10] class_loss: 0.0876 s_domain_loss: 0.6266 t_domain_loss: 0.3377 \n","[5/10] class_loss: 0.0251 s_domain_loss: 0.1026 t_domain_loss: 0.8641 \n","[6/10] class_loss: 0.0665 s_domain_loss: 0.7509 t_domain_loss: 0.1633 \n","[7/10] class_loss: 0.0218 s_domain_loss: 0.4955 t_domain_loss: 0.2412 \n","[8/10] class_loss: 0.0348 s_domain_loss: 0.1089 t_domain_loss: 0.8233 \n","[9/10] class_loss: 0.0402 s_domain_loss: 0.3877 t_domain_loss: 0.1852 \n","[10/10] class_loss: 0.0728 s_domain_loss: 0.6649 t_domain_loss: 0.0529 \n","\n","Epoch 0006 / 0020\n","=================\n","[1/10] class_loss: 0.0312 s_domain_loss: 0.1962 t_domain_loss: 0.5537 \n","[2/10] class_loss: 0.0601 s_domain_loss: 0.1026 t_domain_loss: 0.6752 \n","[3/10] class_loss: 0.0348 s_domain_loss: 0.5290 t_domain_loss: 0.0902 \n","[4/10] class_loss: 0.0898 s_domain_loss: 0.2894 t_domain_loss: 0.0971 \n","[5/10] class_loss: 0.0588 s_domain_loss: 0.4413 t_domain_loss: 0.1873 \n","[6/10] class_loss: 0.0587 s_domain_loss: 0.0498 t_domain_loss: 0.8619 \n","[7/10] class_loss: 0.1194 s_domain_loss: 0.1964 t_domain_loss: 0.1790 \n","[8/10] class_loss: 0.0411 s_domain_loss: 1.1591 t_domain_loss: 0.0244 \n","[9/10] class_loss: 0.0480 s_domain_loss: 0.2040 t_domain_loss: 0.3011 \n","[10/10] class_loss: 0.0465 s_domain_loss: 0.0166 t_domain_loss: 0.8127 \n","\n","Epoch 0007 / 0020\n","=================\n","[1/10] class_loss: 0.0696 s_domain_loss: 0.1751 t_domain_loss: 0.1813 \n","[2/10] class_loss: 0.0954 s_domain_loss: 0.8575 t_domain_loss: 0.0166 \n","[3/10] class_loss: 0.1591 s_domain_loss: 0.4313 t_domain_loss: 0.0610 \n","[4/10] class_loss: 0.0840 s_domain_loss: 0.0329 t_domain_loss: 0.6430 \n","[5/10] class_loss: 0.0983 s_domain_loss: 0.0328 t_domain_loss: 0.4951 \n","[6/10] class_loss: 0.0668 s_domain_loss: 0.1622 t_domain_loss: 0.0433 \n","[7/10] class_loss: 0.0667 s_domain_loss: 1.2278 t_domain_loss: 0.0060 \n","[8/10] class_loss: 0.0681 s_domain_loss: 0.1437 t_domain_loss: 0.0575 \n","[9/10] class_loss: 0.0773 s_domain_loss: 0.2036 t_domain_loss: 0.5254 \n","[10/10] class_loss: 0.2005 s_domain_loss: 0.0032 t_domain_loss: 0.3574 \n","\n","Epoch 0008 / 0020\n","=================\n","[1/10] class_loss: 0.1838 s_domain_loss: 0.1100 t_domain_loss: 0.1192 \n","[2/10] class_loss: 0.0905 s_domain_loss: 0.0587 t_domain_loss: 0.0337 \n","[3/10] class_loss: 0.0602 s_domain_loss: 0.3721 t_domain_loss: 0.0083 \n","[4/10] class_loss: 0.0644 s_domain_loss: 0.6167 t_domain_loss: 0.0117 \n","[5/10] class_loss: 0.0887 s_domain_loss: 0.0519 t_domain_loss: 0.1241 \n","[6/10] class_loss: 0.1594 s_domain_loss: 0.1699 t_domain_loss: 0.5734 \n","[7/10] class_loss: 0.1586 s_domain_loss: 0.4943 t_domain_loss: 0.4040 \n","[8/10] class_loss: 0.0779 s_domain_loss: 0.1784 t_domain_loss: 0.1428 \n","[9/10] class_loss: 0.1661 s_domain_loss: 0.0867 t_domain_loss: 0.1007 \n","[10/10] class_loss: 0.2682 s_domain_loss: 0.9830 t_domain_loss: 0.2406 \n","\n","Epoch 0009 / 0020\n","=================\n","[1/10] class_loss: 0.3764 s_domain_loss: 3.0671 t_domain_loss: 0.0414 \n","[2/10] class_loss: 0.7537 s_domain_loss: 0.4603 t_domain_loss: 1.2268 \n","[3/10] class_loss: 1.1071 s_domain_loss: 0.1430 t_domain_loss: 2.5770 \n","[4/10] class_loss: 0.3890 s_domain_loss: 1.3202 t_domain_loss: 0.3584 \n","[5/10] class_loss: 0.7328 s_domain_loss: 1.7190 t_domain_loss: 0.1945 \n","[6/10] class_loss: 0.5836 s_domain_loss: 0.2090 t_domain_loss: 1.6636 \n","[7/10] class_loss: 0.3965 s_domain_loss: 0.2549 t_domain_loss: 1.3946 \n","[8/10] class_loss: 0.4338 s_domain_loss: 2.4044 t_domain_loss: 0.0703 \n","[9/10] class_loss: 0.6717 s_domain_loss: 0.6694 t_domain_loss: 0.4405 \n","[10/10] class_loss: 0.5964 s_domain_loss: 0.0891 t_domain_loss: 1.7415 \n","\n","Epoch 0010 / 0020\n","=================\n","[1/10] class_loss: 0.3208 s_domain_loss: 0.4545 t_domain_loss: 0.4206 \n","[2/10] class_loss: 0.3590 s_domain_loss: 1.8066 t_domain_loss: 0.0501 \n","[3/10] class_loss: 0.5387 s_domain_loss: 0.7125 t_domain_loss: 0.3644 \n","[4/10] class_loss: 0.3553 s_domain_loss: 0.1712 t_domain_loss: 1.1586 \n","[5/10] class_loss: 0.4491 s_domain_loss: 0.7899 t_domain_loss: 0.5720 \n","[6/10] class_loss: 0.4000 s_domain_loss: 0.1243 t_domain_loss: 0.4156 \n","[7/10] class_loss: 0.3386 s_domain_loss: 0.9450 t_domain_loss: 0.1302 \n","[8/10] class_loss: 0.3632 s_domain_loss: 0.3509 t_domain_loss: 0.1026 \n","[9/10] class_loss: 0.4193 s_domain_loss: 0.7759 t_domain_loss: 0.1994 \n","[10/10] class_loss: 0.3264 s_domain_loss: 0.0614 t_domain_loss: 0.9752 \n","\n","Epoch 0011 / 0020\n","=================\n","[1/10] class_loss: 0.2589 s_domain_loss: 0.0337 t_domain_loss: 0.7256 \n","[2/10] class_loss: 0.3474 s_domain_loss: 0.4124 t_domain_loss: 0.0339 \n","[3/10] class_loss: 0.2867 s_domain_loss: 1.0020 t_domain_loss: 0.0128 \n","[4/10] class_loss: 0.1955 s_domain_loss: 0.7537 t_domain_loss: 0.0139 \n","[5/10] class_loss: 0.4352 s_domain_loss: 0.0495 t_domain_loss: 0.2128 \n","[6/10] class_loss: 0.3439 s_domain_loss: 0.0037 t_domain_loss: 0.9385 \n","[7/10] class_loss: 0.3345 s_domain_loss: 0.0342 t_domain_loss: 0.4194 \n","[8/10] class_loss: 0.3150 s_domain_loss: 0.0196 t_domain_loss: 0.0392 \n","[9/10] class_loss: 0.2820 s_domain_loss: 0.2636 t_domain_loss: 0.0030 \n","[10/10] class_loss: 0.2374 s_domain_loss: 0.1420 t_domain_loss: 0.0012 \n","\n","Epoch 0012 / 0020\n","=================\n","[1/10] class_loss: 0.2274 s_domain_loss: 0.6687 t_domain_loss: 0.0006 \n","[2/10] class_loss: 0.1681 s_domain_loss: 0.1055 t_domain_loss: 0.0028 \n","[3/10] class_loss: 0.2530 s_domain_loss: 0.0396 t_domain_loss: 0.0212 \n","[4/10] class_loss: 0.2118 s_domain_loss: 0.0074 t_domain_loss: 0.0525 \n","[5/10] class_loss: 0.1717 s_domain_loss: 0.0037 t_domain_loss: 0.0763 \n","[6/10] class_loss: 0.1221 s_domain_loss: 0.0074 t_domain_loss: 0.1704 \n","[7/10] class_loss: 0.1994 s_domain_loss: 0.0009 t_domain_loss: 0.0858 \n","[8/10] class_loss: 0.1267 s_domain_loss: 0.0016 t_domain_loss: 0.0453 \n","[9/10] class_loss: 0.1924 s_domain_loss: 0.0050 t_domain_loss: 0.0285 \n","[10/10] class_loss: 0.1868 s_domain_loss: 1.6476 t_domain_loss: 0.0208 \n","\n","Epoch 0013 / 0020\n","=================\n","[1/10] class_loss: 1.8095 s_domain_loss: 5.5132 t_domain_loss: 3.6699 \n","[2/10] class_loss: 0.7482 s_domain_loss: 0.0266 t_domain_loss: 3.7101 \n","[3/10] class_loss: 0.5141 s_domain_loss: 0.7654 t_domain_loss: 1.1200 \n","[4/10] class_loss: 0.7421 s_domain_loss: 2.2755 t_domain_loss: 0.0921 \n","[5/10] class_loss: 0.5601 s_domain_loss: 0.9213 t_domain_loss: 0.3870 \n","[6/10] class_loss: 0.6646 s_domain_loss: 0.1018 t_domain_loss: 2.3866 \n","[7/10] class_loss: 0.8481 s_domain_loss: 0.2435 t_domain_loss: 1.4760 \n","[8/10] class_loss: 0.6922 s_domain_loss: 2.3991 t_domain_loss: 0.0595 \n","[9/10] class_loss: 0.7001 s_domain_loss: 1.1149 t_domain_loss: 0.1123 \n","[10/10] class_loss: 0.8333 s_domain_loss: 0.1554 t_domain_loss: 0.7613 \n","\n","Epoch 0014 / 0020\n","=================\n","[1/10] class_loss: 0.5231 s_domain_loss: 0.1898 t_domain_loss: 0.6172 \n","[2/10] class_loss: 0.6340 s_domain_loss: 0.4379 t_domain_loss: 0.1765 \n","[3/10] class_loss: 0.9125 s_domain_loss: 0.2611 t_domain_loss: 0.2008 \n","[4/10] class_loss: 0.5900 s_domain_loss: 0.3671 t_domain_loss: 0.1328 \n","[5/10] class_loss: 0.6709 s_domain_loss: 0.2857 t_domain_loss: 0.1558 \n","[6/10] class_loss: 0.6346 s_domain_loss: 0.3426 t_domain_loss: 0.2984 \n","[7/10] class_loss: 0.7724 s_domain_loss: 0.5363 t_domain_loss: 0.5068 \n","[8/10] class_loss: 0.8840 s_domain_loss: 0.3856 t_domain_loss: 0.5321 \n","[9/10] class_loss: 0.8829 s_domain_loss: 0.4782 t_domain_loss: 0.2184 \n","[10/10] class_loss: 0.4772 s_domain_loss: 0.0186 t_domain_loss: 0.3067 \n","\n","Epoch 0015 / 0020\n","=================\n","[1/10] class_loss: 0.5527 s_domain_loss: 0.1825 t_domain_loss: 0.4999 \n","[2/10] class_loss: 0.6520 s_domain_loss: 0.2116 t_domain_loss: 0.0174 \n","[3/10] class_loss: 0.6304 s_domain_loss: 2.3430 t_domain_loss: 0.0024 \n","[4/10] class_loss: 0.9287 s_domain_loss: 0.5003 t_domain_loss: 0.4897 \n","[5/10] class_loss: 0.7015 s_domain_loss: 0.2102 t_domain_loss: 0.6881 \n","[6/10] class_loss: 0.5504 s_domain_loss: 0.0364 t_domain_loss: 1.4589 \n","[7/10] class_loss: 0.5897 s_domain_loss: 0.0584 t_domain_loss: 0.6702 \n","[8/10] class_loss: 0.7893 s_domain_loss: 0.0068 t_domain_loss: 0.1012 \n","[9/10] class_loss: 0.7529 s_domain_loss: 0.1280 t_domain_loss: 0.0129 \n","[10/10] class_loss: 0.7152 s_domain_loss: 0.7014 t_domain_loss: 0.0414 \n","\n","Epoch 0016 / 0020\n","=================\n","[1/10] class_loss: 0.6260 s_domain_loss: 0.1259 t_domain_loss: 0.0668 \n","[2/10] class_loss: 0.7512 s_domain_loss: 0.5336 t_domain_loss: 0.0110 \n","[3/10] class_loss: 0.6441 s_domain_loss: 0.0297 t_domain_loss: 0.0226 \n","[4/10] class_loss: 0.5522 s_domain_loss: 0.0054 t_domain_loss: 0.0062 \n","[5/10] class_loss: 0.4148 s_domain_loss: 0.0313 t_domain_loss: 0.0137 \n","[6/10] class_loss: 0.5186 s_domain_loss: 0.1394 t_domain_loss: 0.2798 \n","[7/10] class_loss: 0.6217 s_domain_loss: 0.1214 t_domain_loss: 0.1250 \n","[8/10] class_loss: 0.5695 s_domain_loss: 0.0030 t_domain_loss: 0.0998 \n","[9/10] class_loss: 0.4984 s_domain_loss: 0.0002 t_domain_loss: 0.0479 \n","[10/10] class_loss: 0.5237 s_domain_loss: 0.0036 t_domain_loss: 0.8274 \n","\n","Epoch 0017 / 0020\n","=================\n","[1/10] class_loss: 0.4808 s_domain_loss: 0.0036 t_domain_loss: 0.1884 \n","[2/10] class_loss: 0.4899 s_domain_loss: 0.1069 t_domain_loss: 0.0015 \n","[3/10] class_loss: 0.5786 s_domain_loss: 1.8739 t_domain_loss: 0.0008 \n","[4/10] class_loss: 2.1335 s_domain_loss: 6.8180 t_domain_loss: 0.1370 \n","[5/10] class_loss: 1.3187 s_domain_loss: 0.0798 t_domain_loss: 0.4702 \n","[6/10] class_loss: 1.1022 s_domain_loss: 0.0172 t_domain_loss: 1.1374 \n","[7/10] class_loss: 1.3443 s_domain_loss: 2.4545 t_domain_loss: 0.0664 \n","[8/10] class_loss: 2.0483 s_domain_loss: 0.1279 t_domain_loss: 0.8082 \n","[9/10] class_loss: 2.1140 s_domain_loss: 0.0177 t_domain_loss: 0.5849 \n","[10/10] class_loss: 1.7301 s_domain_loss: 0.0021 t_domain_loss: 9.4611 \n","\n","Epoch 0018 / 0020\n","=================\n","[1/10] class_loss: 1.9483 s_domain_loss: 1.8977 t_domain_loss: 1.6732 \n","[2/10] class_loss: 5.8275 s_domain_loss: 5.5515 t_domain_loss: 0.2539 \n","[3/10] class_loss: 1.9742 s_domain_loss: 3.0889 t_domain_loss: 0.0584 \n","[4/10] class_loss: 1.8644 s_domain_loss: 0.7064 t_domain_loss: 0.1170 \n","[5/10] class_loss: 5.4874 s_domain_loss: 0.5496 t_domain_loss: 4.0593 \n","[6/10] class_loss: 1.8144 s_domain_loss: 0.1276 t_domain_loss: 0.0772 \n","[7/10] class_loss: 2.0571 s_domain_loss: 0.8353 t_domain_loss: 0.6482 \n","[8/10] class_loss: 2.0837 s_domain_loss: 0.3704 t_domain_loss: 0.5530 \n","[9/10] class_loss: 1.8867 s_domain_loss: 0.0586 t_domain_loss: 0.1557 \n","[10/10] class_loss: 1.9464 s_domain_loss: 0.0118 t_domain_loss: 1.5885 \n","\n","Epoch 0019 / 0020\n","=================\n","[1/10] class_loss: 2.0906 s_domain_loss: 4.8655 t_domain_loss: 5.6908 \n","[2/10] class_loss: 1.9433 s_domain_loss: 3.2469 t_domain_loss: 1.0059 \n","[3/10] class_loss: 2.4340 s_domain_loss: 0.1234 t_domain_loss: 0.9692 \n","[4/10] class_loss: 11.7600 s_domain_loss: 0.1610 t_domain_loss: 6.1395 \n","[5/10] class_loss: 2.0130 s_domain_loss: 1.3214 t_domain_loss: 0.9265 \n","[6/10] class_loss: 3.1113 s_domain_loss: 3.0137 t_domain_loss: 0.3383 \n","[7/10] class_loss: 3.2717 s_domain_loss: 1.8381 t_domain_loss: 0.5383 \n","[8/10] class_loss: 2.8273 s_domain_loss: 0.0587 t_domain_loss: 1.1115 \n","[9/10] class_loss: 2.3784 s_domain_loss: 0.0277 t_domain_loss: 1.8351 \n","[10/10] class_loss: 2.2879 s_domain_loss: 0.0070 t_domain_loss: 11.4386 \n","\n","Epoch 0020 / 0020\n","=================\n","[1/10] class_loss: 28.6917 s_domain_loss: 0.2418 t_domain_loss: 7.0466 \n","[2/10] class_loss: 2.2220 s_domain_loss: 0.3973 t_domain_loss: 1.1534 \n","[3/10] class_loss: 2.1949 s_domain_loss: 0.1510 t_domain_loss: 0.9463 \n","[4/10] class_loss: 2.3002 s_domain_loss: 0.1541 t_domain_loss: 0.8555 \n","[5/10] class_loss: 2.1570 s_domain_loss: 0.1815 t_domain_loss: 0.9551 \n","[6/10] class_loss: 3.0353 s_domain_loss: 0.1951 t_domain_loss: 0.5611 \n","[7/10] class_loss: 2.1265 s_domain_loss: 0.6925 t_domain_loss: 0.5175 \n","[8/10] class_loss: 2.1848 s_domain_loss: 0.3274 t_domain_loss: 0.4885 \n","[9/10] class_loss: 2.4067 s_domain_loss: 0.6478 t_domain_loss: 0.5423 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[10/10] class_loss: 3.7749 s_domain_loss: 0.5218 t_domain_loss: 1.3792 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.1826171875\n","hyperprameters are: LR=0.006 and NUM_EPOCHS = 30\n","\n","Epoch 0001 / 0030\n","=================\n","[1/10] class_loss: 2.1539 s_domain_loss: 0.6345 t_domain_loss: 0.7997 \n","[2/10] class_loss: 1.2495 s_domain_loss: 0.9327 t_domain_loss: 0.5289 \n","[3/10] class_loss: 0.8542 s_domain_loss: 0.4184 t_domain_loss: 1.1082 \n","[4/10] class_loss: 0.5817 s_domain_loss: 1.2163 t_domain_loss: 0.3684 \n","[5/10] class_loss: 0.3847 s_domain_loss: 0.3440 t_domain_loss: 1.2403 \n","[6/10] class_loss: 0.3046 s_domain_loss: 1.0905 t_domain_loss: 0.4196 \n","[7/10] class_loss: 0.2115 s_domain_loss: 0.4807 t_domain_loss: 0.9533 \n","[8/10] class_loss: 0.2187 s_domain_loss: 0.8508 t_domain_loss: 0.5480 \n","[9/10] class_loss: 0.2358 s_domain_loss: 0.5681 t_domain_loss: 0.8139 \n","[10/10] class_loss: 0.2053 s_domain_loss: 0.7625 t_domain_loss: 0.5996 \n","\n","Epoch 0002 / 0030\n","=================\n","[1/10] class_loss: 0.1593 s_domain_loss: 0.5897 t_domain_loss: 0.7474 \n","[2/10] class_loss: 0.1837 s_domain_loss: 0.7296 t_domain_loss: 0.6211 \n","[3/10] class_loss: 0.2491 s_domain_loss: 0.5806 t_domain_loss: 0.7358 \n","[4/10] class_loss: 0.0877 s_domain_loss: 0.7333 t_domain_loss: 0.5778 \n","[5/10] class_loss: 0.1162 s_domain_loss: 0.5985 t_domain_loss: 0.6855 \n","[6/10] class_loss: 0.1298 s_domain_loss: 0.6175 t_domain_loss: 0.6764 \n","[7/10] class_loss: 0.0643 s_domain_loss: 0.7604 t_domain_loss: 0.5449 \n","[8/10] class_loss: 0.1783 s_domain_loss: 0.4848 t_domain_loss: 0.8268 \n","[9/10] class_loss: 0.0462 s_domain_loss: 0.8657 t_domain_loss: 0.4487 \n","[10/10] class_loss: 0.0747 s_domain_loss: 0.4051 t_domain_loss: 0.8434 \n","\n","Epoch 0003 / 0030\n","=================\n","[1/10] class_loss: 0.1120 s_domain_loss: 0.8796 t_domain_loss: 0.4078 \n","[2/10] class_loss: 0.0451 s_domain_loss: 0.3732 t_domain_loss: 0.8900 \n","[3/10] class_loss: 0.0849 s_domain_loss: 0.8943 t_domain_loss: 0.3838 \n","[4/10] class_loss: 0.1144 s_domain_loss: 0.3756 t_domain_loss: 0.8676 \n","[5/10] class_loss: 0.1023 s_domain_loss: 0.8908 t_domain_loss: 0.3857 \n","[6/10] class_loss: 0.0685 s_domain_loss: 0.3775 t_domain_loss: 0.8914 \n","[7/10] class_loss: 0.0919 s_domain_loss: 0.8646 t_domain_loss: 0.3873 \n","[8/10] class_loss: 0.0414 s_domain_loss: 0.5124 t_domain_loss: 0.6475 \n","[9/10] class_loss: 0.0875 s_domain_loss: 0.4632 t_domain_loss: 0.6628 \n","[10/10] class_loss: 0.0387 s_domain_loss: 0.8664 t_domain_loss: 0.3149 \n","\n","Epoch 0004 / 0030\n","=================\n","[1/10] class_loss: 0.0391 s_domain_loss: 0.2658 t_domain_loss: 1.0727 \n","[2/10] class_loss: 0.0709 s_domain_loss: 0.9227 t_domain_loss: 0.2960 \n","[3/10] class_loss: 0.0428 s_domain_loss: 0.6474 t_domain_loss: 0.3762 \n","[4/10] class_loss: 0.0306 s_domain_loss: 0.1827 t_domain_loss: 1.1142 \n","[5/10] class_loss: 0.0354 s_domain_loss: 1.0623 t_domain_loss: 0.1819 \n","[6/10] class_loss: 0.0560 s_domain_loss: 0.3814 t_domain_loss: 0.5683 \n","[7/10] class_loss: 0.0397 s_domain_loss: 0.2539 t_domain_loss: 0.8180 \n","[8/10] class_loss: 0.0440 s_domain_loss: 1.1338 t_domain_loss: 0.1501 \n","[9/10] class_loss: 0.0490 s_domain_loss: 0.3076 t_domain_loss: 0.6815 \n","[10/10] class_loss: 0.0371 s_domain_loss: 0.2470 t_domain_loss: 0.5066 \n","\n","Epoch 0005 / 0030\n","=================\n","[1/10] class_loss: 0.0449 s_domain_loss: 1.0620 t_domain_loss: 0.1716 \n","[2/10] class_loss: 0.0273 s_domain_loss: 0.1928 t_domain_loss: 0.7970 \n","[3/10] class_loss: 0.0448 s_domain_loss: 0.4930 t_domain_loss: 0.3565 \n","[4/10] class_loss: 0.0371 s_domain_loss: 0.4998 t_domain_loss: 0.2623 \n","[5/10] class_loss: 0.0388 s_domain_loss: 0.2439 t_domain_loss: 0.4490 \n","[6/10] class_loss: 0.0603 s_domain_loss: 0.3901 t_domain_loss: 0.2997 \n","[7/10] class_loss: 0.0564 s_domain_loss: 0.4513 t_domain_loss: 0.2899 \n","[8/10] class_loss: 0.0257 s_domain_loss: 0.2159 t_domain_loss: 0.4875 \n","[9/10] class_loss: 0.0818 s_domain_loss: 0.4134 t_domain_loss: 0.2835 \n","[10/10] class_loss: 0.0637 s_domain_loss: 0.4692 t_domain_loss: 0.1446 \n","\n","Epoch 0006 / 0030\n","=================\n","[1/10] class_loss: 0.0628 s_domain_loss: 0.3220 t_domain_loss: 0.4446 \n","[2/10] class_loss: 0.0514 s_domain_loss: 0.1771 t_domain_loss: 0.5038 \n","[3/10] class_loss: 0.0396 s_domain_loss: 0.5857 t_domain_loss: 0.1436 \n","[4/10] class_loss: 0.0281 s_domain_loss: 0.3479 t_domain_loss: 0.2694 \n","[5/10] class_loss: 0.0341 s_domain_loss: 0.2515 t_domain_loss: 0.4911 \n","[6/10] class_loss: 0.0143 s_domain_loss: 0.2468 t_domain_loss: 0.2160 \n","[7/10] class_loss: 0.0763 s_domain_loss: 0.5738 t_domain_loss: 0.0963 \n","[8/10] class_loss: 0.0469 s_domain_loss: 0.3133 t_domain_loss: 0.2222 \n","[9/10] class_loss: 0.0357 s_domain_loss: 0.0775 t_domain_loss: 0.5579 \n","[10/10] class_loss: 0.0478 s_domain_loss: 0.3688 t_domain_loss: 0.1193 \n","\n","Epoch 0007 / 0030\n","=================\n","[1/10] class_loss: 0.0431 s_domain_loss: 0.2662 t_domain_loss: 0.1137 \n","[2/10] class_loss: 0.1000 s_domain_loss: 0.2773 t_domain_loss: 0.1546 \n","[3/10] class_loss: 0.0477 s_domain_loss: 0.0814 t_domain_loss: 0.3443 \n","[4/10] class_loss: 0.0372 s_domain_loss: 0.1225 t_domain_loss: 0.1954 \n","[5/10] class_loss: 0.0549 s_domain_loss: 0.3607 t_domain_loss: 0.0634 \n","[6/10] class_loss: 0.0903 s_domain_loss: 0.2034 t_domain_loss: 0.0888 \n","[7/10] class_loss: 0.0872 s_domain_loss: 0.1038 t_domain_loss: 0.1903 \n","[8/10] class_loss: 0.0828 s_domain_loss: 0.1189 t_domain_loss: 0.1768 \n","[9/10] class_loss: 0.0636 s_domain_loss: 0.1516 t_domain_loss: 0.0914 \n","[10/10] class_loss: 0.0774 s_domain_loss: 0.2450 t_domain_loss: 0.0483 \n","\n","Epoch 0008 / 0030\n","=================\n","[1/10] class_loss: 0.0655 s_domain_loss: 0.0836 t_domain_loss: 0.2052 \n","[2/10] class_loss: 0.0323 s_domain_loss: 0.1523 t_domain_loss: 0.1591 \n","[3/10] class_loss: 0.0322 s_domain_loss: 0.0679 t_domain_loss: 0.0841 \n","[4/10] class_loss: 0.0427 s_domain_loss: 0.0988 t_domain_loss: 0.0654 \n","[5/10] class_loss: 0.0978 s_domain_loss: 0.1937 t_domain_loss: 0.0567 \n","[6/10] class_loss: 0.0551 s_domain_loss: 0.0966 t_domain_loss: 0.0875 \n","[7/10] class_loss: 0.0360 s_domain_loss: 0.0310 t_domain_loss: 0.1290 \n","[8/10] class_loss: 0.0271 s_domain_loss: 0.0808 t_domain_loss: 0.0824 \n","[9/10] class_loss: 0.0489 s_domain_loss: 0.2963 t_domain_loss: 0.0580 \n","[10/10] class_loss: 0.0483 s_domain_loss: 0.0478 t_domain_loss: 0.0399 \n","\n","Epoch 0009 / 0030\n","=================\n","[1/10] class_loss: 0.1074 s_domain_loss: 0.2759 t_domain_loss: 0.0842 \n","[2/10] class_loss: 0.0512 s_domain_loss: 0.0179 t_domain_loss: 0.1642 \n","[3/10] class_loss: 0.0423 s_domain_loss: 0.0369 t_domain_loss: 0.1473 \n","[4/10] class_loss: 0.0465 s_domain_loss: 0.0294 t_domain_loss: 0.0582 \n","[5/10] class_loss: 0.0854 s_domain_loss: 0.1918 t_domain_loss: 0.0221 \n","[6/10] class_loss: 0.0424 s_domain_loss: 0.1090 t_domain_loss: 0.0149 \n","[7/10] class_loss: 0.0328 s_domain_loss: 0.3326 t_domain_loss: 0.0215 \n","[8/10] class_loss: 0.0220 s_domain_loss: 0.0186 t_domain_loss: 0.1162 \n","[9/10] class_loss: 0.0248 s_domain_loss: 0.0328 t_domain_loss: 0.2449 \n","[10/10] class_loss: 0.0663 s_domain_loss: 0.0440 t_domain_loss: 0.1371 \n","\n","Epoch 0010 / 0030\n","=================\n","[1/10] class_loss: 0.0533 s_domain_loss: 0.0424 t_domain_loss: 0.0515 \n","[2/10] class_loss: 0.0661 s_domain_loss: 0.0860 t_domain_loss: 0.0126 \n","[3/10] class_loss: 0.0586 s_domain_loss: 0.2126 t_domain_loss: 0.0076 \n","[4/10] class_loss: 0.0234 s_domain_loss: 0.0498 t_domain_loss: 0.0144 \n","[5/10] class_loss: 0.0504 s_domain_loss: 0.0585 t_domain_loss: 0.0416 \n","[6/10] class_loss: 0.0590 s_domain_loss: 0.0162 t_domain_loss: 0.0720 \n","[7/10] class_loss: 0.0514 s_domain_loss: 0.0057 t_domain_loss: 0.0606 \n","[8/10] class_loss: 0.0420 s_domain_loss: 0.0237 t_domain_loss: 0.0580 \n","[9/10] class_loss: 0.0435 s_domain_loss: 0.0149 t_domain_loss: 0.0306 \n","[10/10] class_loss: 0.0288 s_domain_loss: 0.0773 t_domain_loss: 0.0151 \n","\n","Epoch 0011 / 0030\n","=================\n","[1/10] class_loss: 0.0548 s_domain_loss: 0.0450 t_domain_loss: 0.0160 \n","[2/10] class_loss: 0.0338 s_domain_loss: 0.0477 t_domain_loss: 0.0131 \n","[3/10] class_loss: 0.0262 s_domain_loss: 0.0140 t_domain_loss: 0.0155 \n","[4/10] class_loss: 0.0113 s_domain_loss: 0.0655 t_domain_loss: 0.0195 \n","[5/10] class_loss: 0.0223 s_domain_loss: 0.0187 t_domain_loss: 0.0338 \n","[6/10] class_loss: 0.0198 s_domain_loss: 0.0027 t_domain_loss: 0.0358 \n","[7/10] class_loss: 0.0377 s_domain_loss: 0.0170 t_domain_loss: 0.0339 \n","[8/10] class_loss: 0.0311 s_domain_loss: 0.0305 t_domain_loss: 0.0264 \n","[9/10] class_loss: 0.0216 s_domain_loss: 0.0144 t_domain_loss: 0.0274 \n","[10/10] class_loss: 0.0196 s_domain_loss: 0.0051 t_domain_loss: 0.0104 \n","\n","Epoch 0012 / 0030\n","=================\n","[1/10] class_loss: 0.0252 s_domain_loss: 0.0165 t_domain_loss: 0.0226 \n","[2/10] class_loss: 0.0154 s_domain_loss: 0.0261 t_domain_loss: 0.0081 \n","[3/10] class_loss: 0.0139 s_domain_loss: 0.0160 t_domain_loss: 0.0069 \n","[4/10] class_loss: 0.0163 s_domain_loss: 0.0088 t_domain_loss: 0.0064 \n","[5/10] class_loss: 0.0081 s_domain_loss: 0.0328 t_domain_loss: 0.0062 \n","[6/10] class_loss: 0.0076 s_domain_loss: 0.9165 t_domain_loss: 0.0066 \n","[7/10] class_loss: 0.3618 s_domain_loss: 1.7057 t_domain_loss: 0.2971 \n","[8/10] class_loss: 0.1590 s_domain_loss: 0.0017 t_domain_loss: 1.3904 \n","[9/10] class_loss: 0.3302 s_domain_loss: 1.0897 t_domain_loss: 0.3518 \n","[10/10] class_loss: 0.7387 s_domain_loss: 0.6480 t_domain_loss: 0.1240 \n","\n","Epoch 0013 / 0030\n","=================\n","[1/10] class_loss: 0.5366 s_domain_loss: 1.3859 t_domain_loss: 0.2921 \n","[2/10] class_loss: 0.8097 s_domain_loss: 0.6613 t_domain_loss: 1.0728 \n","[3/10] class_loss: 0.7630 s_domain_loss: 0.3317 t_domain_loss: 1.4225 \n","[4/10] class_loss: 0.5711 s_domain_loss: 1.3592 t_domain_loss: 0.2193 \n","[5/10] class_loss: 0.7138 s_domain_loss: 0.9670 t_domain_loss: 0.4325 \n","[6/10] class_loss: 0.5119 s_domain_loss: 0.1798 t_domain_loss: 1.5387 \n","[7/10] class_loss: 0.5745 s_domain_loss: 0.5777 t_domain_loss: 0.7668 \n","[8/10] class_loss: 0.5457 s_domain_loss: 1.9136 t_domain_loss: 0.1025 \n","[9/10] class_loss: 0.5104 s_domain_loss: 0.6837 t_domain_loss: 0.7816 \n","[10/10] class_loss: 0.6101 s_domain_loss: 0.4441 t_domain_loss: 1.2385 \n","\n","Epoch 0014 / 0030\n","=================\n","[1/10] class_loss: 0.7026 s_domain_loss: 0.4534 t_domain_loss: 0.4648 \n","[2/10] class_loss: 0.6646 s_domain_loss: 1.7044 t_domain_loss: 0.0973 \n","[3/10] class_loss: 0.5947 s_domain_loss: 0.4028 t_domain_loss: 0.7104 \n","[4/10] class_loss: 0.4623 s_domain_loss: 0.0609 t_domain_loss: 1.3393 \n","[5/10] class_loss: 0.4702 s_domain_loss: 0.8964 t_domain_loss: 0.2453 \n","[6/10] class_loss: 0.4337 s_domain_loss: 0.7433 t_domain_loss: 0.1658 \n","[7/10] class_loss: 0.4466 s_domain_loss: 0.1450 t_domain_loss: 0.5728 \n","[8/10] class_loss: 0.5041 s_domain_loss: 0.1288 t_domain_loss: 0.5264 \n","[9/10] class_loss: 0.3830 s_domain_loss: 0.2049 t_domain_loss: 0.1420 \n","[10/10] class_loss: 0.4095 s_domain_loss: 1.6727 t_domain_loss: 0.0360 \n","\n","Epoch 0015 / 0030\n","=================\n","[1/10] class_loss: 0.2963 s_domain_loss: 0.4172 t_domain_loss: 0.2137 \n","[2/10] class_loss: 0.3627 s_domain_loss: 0.0257 t_domain_loss: 0.9735 \n","[3/10] class_loss: 0.4602 s_domain_loss: 0.4410 t_domain_loss: 0.2918 \n","[4/10] class_loss: 0.4122 s_domain_loss: 0.6384 t_domain_loss: 0.1063 \n","[5/10] class_loss: 0.4265 s_domain_loss: 0.1792 t_domain_loss: 0.3442 \n","[6/10] class_loss: 0.2895 s_domain_loss: 0.1230 t_domain_loss: 0.2165 \n","[7/10] class_loss: 0.2086 s_domain_loss: 0.4525 t_domain_loss: 0.1077 \n","[8/10] class_loss: 0.2643 s_domain_loss: 0.2968 t_domain_loss: 0.1106 \n","[9/10] class_loss: 0.4044 s_domain_loss: 0.0279 t_domain_loss: 0.1450 \n","[10/10] class_loss: 0.3198 s_domain_loss: 0.0361 t_domain_loss: 0.1397 \n","\n","Epoch 0016 / 0030\n","=================\n","[1/10] class_loss: 0.2440 s_domain_loss: 0.0373 t_domain_loss: 0.1175 \n","[2/10] class_loss: 0.2387 s_domain_loss: 0.0554 t_domain_loss: 0.0375 \n","[3/10] class_loss: 0.3130 s_domain_loss: 0.1627 t_domain_loss: 0.0149 \n","[4/10] class_loss: 0.2379 s_domain_loss: 0.2629 t_domain_loss: 0.0661 \n","[5/10] class_loss: 0.2182 s_domain_loss: 0.5382 t_domain_loss: 0.2138 \n","[6/10] class_loss: 0.2956 s_domain_loss: 0.0727 t_domain_loss: 0.1099 \n","[7/10] class_loss: 0.3119 s_domain_loss: 0.5472 t_domain_loss: 0.2559 \n","[8/10] class_loss: 0.3108 s_domain_loss: 0.7686 t_domain_loss: 0.6851 \n","[9/10] class_loss: 0.2313 s_domain_loss: 0.0339 t_domain_loss: 0.6607 \n","[10/10] class_loss: 0.2341 s_domain_loss: 0.2312 t_domain_loss: 0.1701 \n","\n","Epoch 0017 / 0030\n","=================\n","[1/10] class_loss: 0.2507 s_domain_loss: 0.2927 t_domain_loss: 0.0296 \n","[2/10] class_loss: 0.2291 s_domain_loss: 1.7744 t_domain_loss: 0.0253 \n","[3/10] class_loss: 0.1834 s_domain_loss: 0.0708 t_domain_loss: 0.2601 \n","[4/10] class_loss: 0.1818 s_domain_loss: 0.0159 t_domain_loss: 0.7466 \n","[5/10] class_loss: 0.2615 s_domain_loss: 0.1990 t_domain_loss: 0.3924 \n","[6/10] class_loss: 0.2001 s_domain_loss: 0.0605 t_domain_loss: 0.0674 \n","[7/10] class_loss: 0.1894 s_domain_loss: 0.3752 t_domain_loss: 0.0122 \n","[8/10] class_loss: 0.1701 s_domain_loss: 2.7493 t_domain_loss: 0.0041 \n","[9/10] class_loss: 0.2184 s_domain_loss: 0.0289 t_domain_loss: 0.0786 \n","[10/10] class_loss: 0.3018 s_domain_loss: 0.0670 t_domain_loss: 1.0014 \n","\n","Epoch 0018 / 0030\n","=================\n","[1/10] class_loss: 0.2438 s_domain_loss: 0.0339 t_domain_loss: 0.9985 \n","[2/10] class_loss: 0.2241 s_domain_loss: 0.1951 t_domain_loss: 0.0796 \n","[3/10] class_loss: 0.2457 s_domain_loss: 1.4564 t_domain_loss: 0.0272 \n","[4/10] class_loss: 0.2109 s_domain_loss: 0.2667 t_domain_loss: 0.0086 \n","[5/10] class_loss: 0.3413 s_domain_loss: 0.2611 t_domain_loss: 0.0104 \n","[6/10] class_loss: 0.2779 s_domain_loss: 0.3895 t_domain_loss: 0.0237 \n","[7/10] class_loss: 0.4452 s_domain_loss: 0.1361 t_domain_loss: 0.1021 \n","[8/10] class_loss: 0.3897 s_domain_loss: 0.1474 t_domain_loss: 0.2817 \n","[9/10] class_loss: 0.2350 s_domain_loss: 0.0195 t_domain_loss: 0.1830 \n","[10/10] class_loss: 0.3925 s_domain_loss: 0.7719 t_domain_loss: 0.1587 \n","\n","Epoch 0019 / 0030\n","=================\n","[1/10] class_loss: 0.2057 s_domain_loss: 0.0135 t_domain_loss: 0.8020 \n","[2/10] class_loss: 0.2421 s_domain_loss: 0.1770 t_domain_loss: 0.1267 \n","[3/10] class_loss: 0.2273 s_domain_loss: 0.0409 t_domain_loss: 0.0670 \n","[4/10] class_loss: 0.2397 s_domain_loss: 0.6108 t_domain_loss: 0.0315 \n","[5/10] class_loss: 0.2341 s_domain_loss: 0.0451 t_domain_loss: 0.1187 \n","[6/10] class_loss: 0.3386 s_domain_loss: 0.3207 t_domain_loss: 0.1724 \n","[7/10] class_loss: 0.2905 s_domain_loss: 0.3947 t_domain_loss: 0.0755 \n","[8/10] class_loss: 0.2376 s_domain_loss: 0.4309 t_domain_loss: 0.0782 \n","[9/10] class_loss: 0.2461 s_domain_loss: 0.1082 t_domain_loss: 0.1766 \n","[10/10] class_loss: 0.3147 s_domain_loss: 0.0303 t_domain_loss: 0.4580 \n","\n","Epoch 0020 / 0030\n","=================\n","[1/10] class_loss: 0.1921 s_domain_loss: 0.0440 t_domain_loss: 0.3697 \n","[2/10] class_loss: 0.1461 s_domain_loss: 0.0873 t_domain_loss: 0.3199 \n","[3/10] class_loss: 0.2069 s_domain_loss: 0.0204 t_domain_loss: 0.3006 \n","[4/10] class_loss: 0.1820 s_domain_loss: 0.0036 t_domain_loss: 0.2172 \n","[5/10] class_loss: 0.1778 s_domain_loss: 0.0039 t_domain_loss: 0.1616 \n","[6/10] class_loss: 0.1617 s_domain_loss: 0.0885 t_domain_loss: 0.0907 \n","[7/10] class_loss: 0.1446 s_domain_loss: 0.0084 t_domain_loss: 0.0505 \n","[8/10] class_loss: 0.1397 s_domain_loss: 0.2563 t_domain_loss: 0.0207 \n","[9/10] class_loss: 0.1475 s_domain_loss: 0.0225 t_domain_loss: 0.0102 \n","[10/10] class_loss: 0.1143 s_domain_loss: 0.0078 t_domain_loss: 0.0140 \n","\n","Epoch 0021 / 0030\n","=================\n","[1/10] class_loss: 0.1362 s_domain_loss: 0.0775 t_domain_loss: 0.0086 \n","[2/10] class_loss: 0.1064 s_domain_loss: 0.0777 t_domain_loss: 0.0060 \n","[3/10] class_loss: 0.0761 s_domain_loss: 0.0176 t_domain_loss: 0.0062 \n","[4/10] class_loss: 0.1081 s_domain_loss: 0.0075 t_domain_loss: 0.0069 \n","[5/10] class_loss: 0.1400 s_domain_loss: 0.0075 t_domain_loss: 0.0054 \n","[6/10] class_loss: 0.0954 s_domain_loss: 0.0572 t_domain_loss: 0.0093 \n","[7/10] class_loss: 0.1117 s_domain_loss: 0.0335 t_domain_loss: 0.0061 \n","[8/10] class_loss: 0.0790 s_domain_loss: 0.0239 t_domain_loss: 0.0081 \n","[9/10] class_loss: 0.0919 s_domain_loss: 0.1108 t_domain_loss: 0.0058 \n","[10/10] class_loss: 0.0723 s_domain_loss: 0.0043 t_domain_loss: 0.0118 \n","\n","Epoch 0022 / 0030\n","=================\n","[1/10] class_loss: 0.0942 s_domain_loss: 0.0023 t_domain_loss: 0.0048 \n","[2/10] class_loss: 0.1034 s_domain_loss: 0.0085 t_domain_loss: 0.0037 \n","[3/10] class_loss: 0.0854 s_domain_loss: 0.0030 t_domain_loss: 0.0060 \n","[4/10] class_loss: 0.0885 s_domain_loss: 0.2439 t_domain_loss: 0.0067 \n","[5/10] class_loss: 0.0771 s_domain_loss: 0.0317 t_domain_loss: 0.0064 \n","[6/10] class_loss: 0.1116 s_domain_loss: 0.0758 t_domain_loss: 0.0103 \n","[7/10] class_loss: 0.0774 s_domain_loss: 0.0121 t_domain_loss: 0.0095 \n","[8/10] class_loss: 0.0819 s_domain_loss: 0.0257 t_domain_loss: 0.0182 \n","[9/10] class_loss: 0.1082 s_domain_loss: 0.0018 t_domain_loss: 0.0133 \n","[10/10] class_loss: 0.0719 s_domain_loss: 0.0137 t_domain_loss: 0.0225 \n","\n","Epoch 0023 / 0030\n","=================\n","[1/10] class_loss: 0.0845 s_domain_loss: 0.0294 t_domain_loss: 0.0090 \n","[2/10] class_loss: 0.0923 s_domain_loss: 0.0211 t_domain_loss: 0.0072 \n","[3/10] class_loss: 0.0772 s_domain_loss: 0.0068 t_domain_loss: 0.0131 \n","[4/10] class_loss: 0.1064 s_domain_loss: 0.0112 t_domain_loss: 0.0137 \n","[5/10] class_loss: 0.0907 s_domain_loss: 0.0071 t_domain_loss: 0.0143 \n","[6/10] class_loss: 0.0613 s_domain_loss: 0.0069 t_domain_loss: 0.0187 \n","[7/10] class_loss: 0.0747 s_domain_loss: 0.0031 t_domain_loss: 0.0179 \n","[8/10] class_loss: 0.0738 s_domain_loss: 0.0037 t_domain_loss: 0.0316 \n","[9/10] class_loss: 0.0531 s_domain_loss: 0.0016 t_domain_loss: 0.0210 \n","[10/10] class_loss: 0.0773 s_domain_loss: 0.0463 t_domain_loss: 0.0271 \n","\n","Epoch 0024 / 0030\n","=================\n","[1/10] class_loss: 0.0602 s_domain_loss: 0.0020 t_domain_loss: 0.0117 \n","[2/10] class_loss: 0.0520 s_domain_loss: 0.0062 t_domain_loss: 0.0085 \n","[3/10] class_loss: 0.0542 s_domain_loss: 0.0015 t_domain_loss: 0.0140 \n","[4/10] class_loss: 0.0807 s_domain_loss: 0.0027 t_domain_loss: 0.0134 \n","[5/10] class_loss: 0.0763 s_domain_loss: 0.0130 t_domain_loss: 0.0135 \n","[6/10] class_loss: 0.0742 s_domain_loss: 0.0289 t_domain_loss: 0.0167 \n","[7/10] class_loss: 0.0797 s_domain_loss: 0.0031 t_domain_loss: 0.0156 \n","[8/10] class_loss: 0.0450 s_domain_loss: 0.0026 t_domain_loss: 0.0234 \n","[9/10] class_loss: 0.0610 s_domain_loss: 0.0033 t_domain_loss: 0.0159 \n","[10/10] class_loss: 0.0697 s_domain_loss: 0.0095 t_domain_loss: 0.0185 \n","\n","Epoch 0025 / 0030\n","=================\n","[1/10] class_loss: 0.0621 s_domain_loss: 0.0056 t_domain_loss: 0.0095 \n","[2/10] class_loss: 0.0529 s_domain_loss: 0.0136 t_domain_loss: 0.0066 \n","[3/10] class_loss: 0.0833 s_domain_loss: 0.0351 t_domain_loss: 0.0101 \n","[4/10] class_loss: 0.0402 s_domain_loss: 0.0025 t_domain_loss: 0.0099 \n","[5/10] class_loss: 0.0449 s_domain_loss: 0.0029 t_domain_loss: 0.0101 \n","[6/10] class_loss: 0.0744 s_domain_loss: 0.0032 t_domain_loss: 0.0128 \n","[7/10] class_loss: 0.0456 s_domain_loss: 0.0019 t_domain_loss: 0.0117 \n","[8/10] class_loss: 0.0278 s_domain_loss: 0.0020 t_domain_loss: 0.0154 \n","[9/10] class_loss: 0.0754 s_domain_loss: 0.0035 t_domain_loss: 0.0113 \n","[10/10] class_loss: 0.0473 s_domain_loss: 0.0016 t_domain_loss: 0.0121 \n","\n","Epoch 0026 / 0030\n","=================\n","[1/10] class_loss: 0.0489 s_domain_loss: 0.0019 t_domain_loss: 0.0076 \n","[2/10] class_loss: 0.0652 s_domain_loss: 0.0021 t_domain_loss: 0.0052 \n","[3/10] class_loss: 0.0452 s_domain_loss: 0.0259 t_domain_loss: 0.0076 \n","[4/10] class_loss: 0.0334 s_domain_loss: 0.0069 t_domain_loss: 0.0074 \n","[5/10] class_loss: 0.0375 s_domain_loss: 0.0124 t_domain_loss: 0.0076 \n","[6/10] class_loss: 0.0654 s_domain_loss: 0.0216 t_domain_loss: 0.0098 \n","[7/10] class_loss: 0.0627 s_domain_loss: 0.0045 t_domain_loss: 0.0089 \n","[8/10] class_loss: 0.0630 s_domain_loss: 0.0024 t_domain_loss: 0.0109 \n","[9/10] class_loss: 0.0300 s_domain_loss: 0.0051 t_domain_loss: 0.0087 \n","[10/10] class_loss: 0.0637 s_domain_loss: 0.0040 t_domain_loss: 0.0089 \n","\n","Epoch 0027 / 0030\n","=================\n","[1/10] class_loss: 0.0626 s_domain_loss: 0.0100 t_domain_loss: 0.0065 \n","[2/10] class_loss: 0.0388 s_domain_loss: 0.0052 t_domain_loss: 0.0045 \n","[3/10] class_loss: 0.0341 s_domain_loss: 0.0025 t_domain_loss: 0.0064 \n","[4/10] class_loss: 0.0630 s_domain_loss: 0.0099 t_domain_loss: 0.0063 \n","[5/10] class_loss: 0.0418 s_domain_loss: 0.0042 t_domain_loss: 0.0066 \n","[6/10] class_loss: 0.0431 s_domain_loss: 0.0095 t_domain_loss: 0.0085 \n","[7/10] class_loss: 0.0525 s_domain_loss: 0.0074 t_domain_loss: 0.0077 \n","[8/10] class_loss: 0.0545 s_domain_loss: 0.0049 t_domain_loss: 0.0089 \n","[9/10] class_loss: 0.0290 s_domain_loss: 0.0113 t_domain_loss: 0.0074 \n","[10/10] class_loss: 0.0542 s_domain_loss: 0.0062 t_domain_loss: 0.0073 \n","\n","Epoch 0028 / 0030\n","=================\n","[1/10] class_loss: 0.0619 s_domain_loss: 0.0032 t_domain_loss: 0.0059 \n","[2/10] class_loss: 0.0561 s_domain_loss: 0.0035 t_domain_loss: 0.0041 \n","[3/10] class_loss: 0.0390 s_domain_loss: 0.0028 t_domain_loss: 0.0057 \n","[4/10] class_loss: 0.0198 s_domain_loss: 0.0058 t_domain_loss: 0.0056 \n","[5/10] class_loss: 0.0320 s_domain_loss: 0.0629 t_domain_loss: 0.0059 \n","[6/10] class_loss: 0.0356 s_domain_loss: 0.0026 t_domain_loss: 0.0078 \n","[7/10] class_loss: 0.0651 s_domain_loss: 0.0197 t_domain_loss: 0.0072 \n","[8/10] class_loss: 0.0264 s_domain_loss: 0.0043 t_domain_loss: 0.0082 \n","[9/10] class_loss: 0.0552 s_domain_loss: 0.1952 t_domain_loss: 0.0073 \n","[10/10] class_loss: 0.0319 s_domain_loss: 0.0063 t_domain_loss: 0.0075 \n","\n","Epoch 0029 / 0030\n","=================\n","[1/10] class_loss: 0.0492 s_domain_loss: 0.0064 t_domain_loss: 0.0068 \n","[2/10] class_loss: 0.0342 s_domain_loss: 0.0022 t_domain_loss: 0.0050 \n","[3/10] class_loss: 0.0495 s_domain_loss: 0.0038 t_domain_loss: 0.0071 \n","[4/10] class_loss: 0.0333 s_domain_loss: 0.0055 t_domain_loss: 0.0074 \n","[5/10] class_loss: 0.0613 s_domain_loss: 0.0049 t_domain_loss: 0.0083 \n","[6/10] class_loss: 0.0512 s_domain_loss: 0.0925 t_domain_loss: 0.0108 \n","[7/10] class_loss: 0.0308 s_domain_loss: 0.0019 t_domain_loss: 0.0111 \n","[8/10] class_loss: 0.0507 s_domain_loss: 0.0068 t_domain_loss: 0.0134 \n","[9/10] class_loss: 0.0314 s_domain_loss: 0.0037 t_domain_loss: 0.0118 \n","[10/10] class_loss: 0.0594 s_domain_loss: 0.0035 t_domain_loss: 0.0123 \n","\n","Epoch 0030 / 0030\n","=================\n","[1/10] class_loss: 0.0382 s_domain_loss: 0.0085 t_domain_loss: 0.0101 \n","[2/10] class_loss: 0.0427 s_domain_loss: 0.0149 t_domain_loss: 0.0074 \n","[3/10] class_loss: 0.0336 s_domain_loss: 0.0148 t_domain_loss: 0.0097 \n","[4/10] class_loss: 0.0336 s_domain_loss: 0.0718 t_domain_loss: 0.0102 \n","[5/10] class_loss: 0.0407 s_domain_loss: 0.0016 t_domain_loss: 0.0117 \n","[6/10] class_loss: 0.0522 s_domain_loss: 0.0032 t_domain_loss: 0.0147 \n","[7/10] class_loss: 0.0349 s_domain_loss: 0.0005 t_domain_loss: 0.0155 \n","[8/10] class_loss: 0.0299 s_domain_loss: 0.0004 t_domain_loss: 0.0181 \n","[9/10] class_loss: 0.0498 s_domain_loss: 0.0051 t_domain_loss: 0.0148 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[10/10] class_loss: 0.0419 s_domain_loss: 0.0414 t_domain_loss: 0.0153 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.06it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.3544921875\n","hyperprameters are: LR=0.007 and NUM_EPOCHS = 10\n","\n","Epoch 0001 / 0010\n","=================\n","[1/10] class_loss: 2.0706 s_domain_loss: 0.7264 t_domain_loss: 0.7003 \n","[2/10] class_loss: 1.2468 s_domain_loss: 0.6267 t_domain_loss: 0.8083 \n","[3/10] class_loss: 0.7907 s_domain_loss: 0.8871 t_domain_loss: 0.5456 \n","[4/10] class_loss: 0.5267 s_domain_loss: 0.3826 t_domain_loss: 1.1672 \n","[5/10] class_loss: 0.3850 s_domain_loss: 1.7062 t_domain_loss: 0.2142 \n","[6/10] class_loss: 0.3330 s_domain_loss: 0.1109 t_domain_loss: 2.2434 \n","[7/10] class_loss: 0.1864 s_domain_loss: 1.8061 t_domain_loss: 0.1821 \n","[8/10] class_loss: 0.2801 s_domain_loss: 0.2844 t_domain_loss: 1.3399 \n","[9/10] class_loss: 0.2104 s_domain_loss: 1.2267 t_domain_loss: 0.3423 \n","[10/10] class_loss: 0.2385 s_domain_loss: 0.2539 t_domain_loss: 1.4422 \n","\n","Epoch 0002 / 0010\n","=================\n","[1/10] class_loss: 0.1234 s_domain_loss: 1.8656 t_domain_loss: 0.1516 \n","[2/10] class_loss: 0.2010 s_domain_loss: 0.1390 t_domain_loss: 1.9388 \n","[3/10] class_loss: 0.1224 s_domain_loss: 1.4141 t_domain_loss: 0.2329 \n","[4/10] class_loss: 0.1659 s_domain_loss: 0.3037 t_domain_loss: 1.1568 \n","[5/10] class_loss: 0.0886 s_domain_loss: 1.1692 t_domain_loss: 0.3063 \n","[6/10] class_loss: 0.1388 s_domain_loss: 0.2381 t_domain_loss: 1.3176 \n","[7/10] class_loss: 0.0727 s_domain_loss: 1.5641 t_domain_loss: 0.1968 \n","[8/10] class_loss: 0.1238 s_domain_loss: 0.1738 t_domain_loss: 1.5984 \n","[9/10] class_loss: 0.1130 s_domain_loss: 1.4493 t_domain_loss: 0.1935 \n","[10/10] class_loss: 0.0713 s_domain_loss: 0.2458 t_domain_loss: 1.1595 \n","\n","Epoch 0003 / 0010\n","=================\n","[1/10] class_loss: 0.0699 s_domain_loss: 0.9822 t_domain_loss: 0.3027 \n","[2/10] class_loss: 0.0867 s_domain_loss: 0.3831 t_domain_loss: 0.7586 \n","[3/10] class_loss: 0.0717 s_domain_loss: 0.7804 t_domain_loss: 0.4395 \n","[4/10] class_loss: 0.0858 s_domain_loss: 0.3509 t_domain_loss: 0.8094 \n","[5/10] class_loss: 0.1258 s_domain_loss: 1.0313 t_domain_loss: 0.2621 \n","[6/10] class_loss: 0.0813 s_domain_loss: 0.2564 t_domain_loss: 1.1134 \n","[7/10] class_loss: 0.0741 s_domain_loss: 1.0066 t_domain_loss: 0.2480 \n","[8/10] class_loss: 0.0428 s_domain_loss: 0.3387 t_domain_loss: 0.7118 \n","[9/10] class_loss: 0.0575 s_domain_loss: 0.6184 t_domain_loss: 0.4327 \n","[10/10] class_loss: 0.0748 s_domain_loss: 0.4284 t_domain_loss: 0.3806 \n","\n","Epoch 0004 / 0010\n","=================\n","[1/10] class_loss: 0.0866 s_domain_loss: 0.2954 t_domain_loss: 0.6612 \n","[2/10] class_loss: 0.1091 s_domain_loss: 0.7944 t_domain_loss: 0.1778 \n","[3/10] class_loss: 0.0578 s_domain_loss: 0.2851 t_domain_loss: 0.5961 \n","[4/10] class_loss: 0.0540 s_domain_loss: 0.4897 t_domain_loss: 0.4390 \n","[5/10] class_loss: 0.0949 s_domain_loss: 0.5183 t_domain_loss: 0.4042 \n","[6/10] class_loss: 0.0291 s_domain_loss: 0.3401 t_domain_loss: 0.4880 \n","[7/10] class_loss: 0.0238 s_domain_loss: 0.5670 t_domain_loss: 0.3404 \n","[8/10] class_loss: 0.0417 s_domain_loss: 0.5535 t_domain_loss: 0.2058 \n","[9/10] class_loss: 0.0947 s_domain_loss: 0.4254 t_domain_loss: 0.6604 \n","[10/10] class_loss: 0.0400 s_domain_loss: 0.2572 t_domain_loss: 0.4712 \n","\n","Epoch 0005 / 0010\n","=================\n","[1/10] class_loss: 0.0550 s_domain_loss: 0.4383 t_domain_loss: 0.2553 \n","[2/10] class_loss: 0.0436 s_domain_loss: 0.4644 t_domain_loss: 0.2255 \n","[3/10] class_loss: 0.0458 s_domain_loss: 0.1905 t_domain_loss: 0.4124 \n","[4/10] class_loss: 0.0886 s_domain_loss: 0.2502 t_domain_loss: 0.2310 \n","[5/10] class_loss: 0.0960 s_domain_loss: 0.4670 t_domain_loss: 0.1276 \n","[6/10] class_loss: 0.0694 s_domain_loss: 0.2053 t_domain_loss: 0.3309 \n","[7/10] class_loss: 0.0480 s_domain_loss: 0.1235 t_domain_loss: 0.4847 \n","[8/10] class_loss: 0.0398 s_domain_loss: 0.4938 t_domain_loss: 0.0769 \n","[9/10] class_loss: 0.0482 s_domain_loss: 0.2508 t_domain_loss: 0.0970 \n","[10/10] class_loss: 0.0540 s_domain_loss: 0.1518 t_domain_loss: 0.1727 \n","\n","Epoch 0006 / 0010\n","=================\n","[1/10] class_loss: 0.0385 s_domain_loss: 0.0511 t_domain_loss: 0.6013 \n","[2/10] class_loss: 0.0651 s_domain_loss: 0.2496 t_domain_loss: 0.0735 \n","[3/10] class_loss: 0.0419 s_domain_loss: 0.5354 t_domain_loss: 0.0208 \n","[4/10] class_loss: 0.0415 s_domain_loss: 0.1450 t_domain_loss: 0.1220 \n","[5/10] class_loss: 0.0370 s_domain_loss: 0.0390 t_domain_loss: 0.4626 \n","[6/10] class_loss: 0.0778 s_domain_loss: 0.1716 t_domain_loss: 0.1377 \n","[7/10] class_loss: 0.0764 s_domain_loss: 0.1457 t_domain_loss: 0.0661 \n","[8/10] class_loss: 0.0534 s_domain_loss: 0.1869 t_domain_loss: 0.0374 \n","[9/10] class_loss: 0.0463 s_domain_loss: 0.2487 t_domain_loss: 0.0507 \n","[10/10] class_loss: 0.0635 s_domain_loss: 0.0413 t_domain_loss: 0.1342 \n","\n","Epoch 0007 / 0010\n","=================\n","[1/10] class_loss: 0.0598 s_domain_loss: 0.0113 t_domain_loss: 0.4149 \n","[2/10] class_loss: 0.1277 s_domain_loss: 0.0432 t_domain_loss: 0.0865 \n","[3/10] class_loss: 0.1159 s_domain_loss: 1.0652 t_domain_loss: 0.0134 \n","[4/10] class_loss: 0.2925 s_domain_loss: 0.6932 t_domain_loss: 0.2023 \n","[5/10] class_loss: 0.2329 s_domain_loss: 0.0266 t_domain_loss: 0.6290 \n","[6/10] class_loss: 0.5066 s_domain_loss: 0.3995 t_domain_loss: 0.3020 \n","[7/10] class_loss: 0.2899 s_domain_loss: 0.4742 t_domain_loss: 0.2130 \n","[8/10] class_loss: 1.1775 s_domain_loss: 1.4160 t_domain_loss: 0.3583 \n","[9/10] class_loss: 0.7258 s_domain_loss: 1.0082 t_domain_loss: 0.3137 \n","[10/10] class_loss: 0.7814 s_domain_loss: 0.6244 t_domain_loss: 1.0055 \n","\n","Epoch 0008 / 0010\n","=================\n","[1/10] class_loss: 0.7114 s_domain_loss: 0.6894 t_domain_loss: 0.9419 \n","[2/10] class_loss: 0.6961 s_domain_loss: 0.9552 t_domain_loss: 0.5163 \n","[3/10] class_loss: 0.6781 s_domain_loss: 0.4614 t_domain_loss: 0.6776 \n","[4/10] class_loss: 0.6195 s_domain_loss: 0.4701 t_domain_loss: 0.4633 \n","[5/10] class_loss: 0.6470 s_domain_loss: 0.8620 t_domain_loss: 0.2062 \n","[6/10] class_loss: 0.7744 s_domain_loss: 0.4760 t_domain_loss: 0.6467 \n","[7/10] class_loss: 0.6827 s_domain_loss: 0.4751 t_domain_loss: 0.5677 \n","[8/10] class_loss: 0.7948 s_domain_loss: 0.9959 t_domain_loss: 0.2596 \n","[9/10] class_loss: 0.5931 s_domain_loss: 0.2189 t_domain_loss: 0.7358 \n","[10/10] class_loss: 0.5473 s_domain_loss: 0.9821 t_domain_loss: 0.2994 \n","\n","Epoch 0009 / 0010\n","=================\n","[1/10] class_loss: 0.4997 s_domain_loss: 0.5185 t_domain_loss: 0.2093 \n","[2/10] class_loss: 0.4002 s_domain_loss: 0.3882 t_domain_loss: 0.2286 \n","[3/10] class_loss: 0.4534 s_domain_loss: 0.3030 t_domain_loss: 0.3246 \n","[4/10] class_loss: 0.3990 s_domain_loss: 0.1782 t_domain_loss: 0.3858 \n","[5/10] class_loss: 0.4686 s_domain_loss: 0.1491 t_domain_loss: 0.1824 \n","[6/10] class_loss: 0.4190 s_domain_loss: 0.7563 t_domain_loss: 0.0717 \n","[7/10] class_loss: 0.3699 s_domain_loss: 0.0957 t_domain_loss: 0.4923 \n","[8/10] class_loss: 0.4207 s_domain_loss: 0.0827 t_domain_loss: 0.4375 \n","[9/10] class_loss: 0.3744 s_domain_loss: 0.0800 t_domain_loss: 0.0747 \n","[10/10] class_loss: 0.3216 s_domain_loss: 0.7553 t_domain_loss: 0.0190 \n","\n","Epoch 0010 / 0010\n","=================\n","[1/10] class_loss: 0.3441 s_domain_loss: 0.1195 t_domain_loss: 0.0233 \n","[2/10] class_loss: 0.3122 s_domain_loss: 0.4080 t_domain_loss: 0.0494 \n","[3/10] class_loss: 0.3857 s_domain_loss: 0.0523 t_domain_loss: 0.4098 \n","[4/10] class_loss: 0.2485 s_domain_loss: 0.0063 t_domain_loss: 0.4045 \n","[5/10] class_loss: 0.2187 s_domain_loss: 0.2898 t_domain_loss: 0.0534 \n","[6/10] class_loss: 0.3085 s_domain_loss: 0.1444 t_domain_loss: 0.0269 \n","[7/10] class_loss: 0.2118 s_domain_loss: 0.1365 t_domain_loss: 0.0293 \n","[8/10] class_loss: 0.2781 s_domain_loss: 0.0702 t_domain_loss: 0.0438 \n","[9/10] class_loss: 0.2651 s_domain_loss: 0.2538 t_domain_loss: 0.0899 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[10/10] class_loss: 0.2658 s_domain_loss: 0.0195 t_domain_loss: 0.0834 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.23681640625\n","hyperprameters are: LR=0.007 and NUM_EPOCHS = 20\n","\n","Epoch 0001 / 0020\n","=================\n","[1/10] class_loss: 1.9728 s_domain_loss: 0.6798 t_domain_loss: 0.7586 \n","[2/10] class_loss: 1.2400 s_domain_loss: 0.7683 t_domain_loss: 0.6547 \n","[3/10] class_loss: 0.8205 s_domain_loss: 0.5328 t_domain_loss: 0.9020 \n","[4/10] class_loss: 0.4753 s_domain_loss: 1.1746 t_domain_loss: 0.3770 \n","[5/10] class_loss: 0.4015 s_domain_loss: 0.1755 t_domain_loss: 1.8384 \n","[6/10] class_loss: 0.2882 s_domain_loss: 2.2252 t_domain_loss: 0.1202 \n","[7/10] class_loss: 0.2714 s_domain_loss: 0.1837 t_domain_loss: 1.8184 \n","[8/10] class_loss: 0.2109 s_domain_loss: 1.3404 t_domain_loss: 0.3060 \n","[9/10] class_loss: 0.2304 s_domain_loss: 0.3309 t_domain_loss: 1.2251 \n","[10/10] class_loss: 0.1514 s_domain_loss: 1.3553 t_domain_loss: 0.2854 \n","\n","Epoch 0002 / 0020\n","=================\n","[1/10] class_loss: 0.2802 s_domain_loss: 0.1755 t_domain_loss: 1.7350 \n","[2/10] class_loss: 0.1383 s_domain_loss: 1.9093 t_domain_loss: 0.1480 \n","[3/10] class_loss: 0.1304 s_domain_loss: 0.1784 t_domain_loss: 1.6753 \n","[4/10] class_loss: 0.1385 s_domain_loss: 1.3657 t_domain_loss: 0.2507 \n","[5/10] class_loss: 0.1997 s_domain_loss: 0.2803 t_domain_loss: 1.2456 \n","[6/10] class_loss: 0.2959 s_domain_loss: 1.1961 t_domain_loss: 0.3116 \n","[7/10] class_loss: 0.1899 s_domain_loss: 0.2617 t_domain_loss: 1.3362 \n","[8/10] class_loss: 0.1751 s_domain_loss: 1.5312 t_domain_loss: 0.1922 \n","[9/10] class_loss: 0.1649 s_domain_loss: 0.1808 t_domain_loss: 1.6052 \n","[10/10] class_loss: 0.1512 s_domain_loss: 1.3096 t_domain_loss: 0.2399 \n","\n","Epoch 0003 / 0020\n","=================\n","[1/10] class_loss: 0.1421 s_domain_loss: 0.3979 t_domain_loss: 0.9160 \n","[2/10] class_loss: 0.1479 s_domain_loss: 0.5839 t_domain_loss: 0.5831 \n","[3/10] class_loss: 0.0979 s_domain_loss: 0.8608 t_domain_loss: 0.3379 \n","[4/10] class_loss: 0.0548 s_domain_loss: 0.2118 t_domain_loss: 1.2200 \n","[5/10] class_loss: 0.1069 s_domain_loss: 1.5862 t_domain_loss: 0.1311 \n","[6/10] class_loss: 0.0735 s_domain_loss: 0.1634 t_domain_loss: 1.4520 \n","[7/10] class_loss: 0.0698 s_domain_loss: 0.9913 t_domain_loss: 0.2608 \n","[8/10] class_loss: 0.0847 s_domain_loss: 0.4910 t_domain_loss: 0.5880 \n","[9/10] class_loss: 0.0798 s_domain_loss: 0.3291 t_domain_loss: 0.7364 \n","[10/10] class_loss: 0.0663 s_domain_loss: 1.0283 t_domain_loss: 0.1827 \n","\n","Epoch 0004 / 0020\n","=================\n","[1/10] class_loss: 0.0897 s_domain_loss: 0.1623 t_domain_loss: 1.1219 \n","[2/10] class_loss: 0.0479 s_domain_loss: 0.9069 t_domain_loss: 0.2441 \n","[3/10] class_loss: 0.0459 s_domain_loss: 0.3510 t_domain_loss: 0.5738 \n","[4/10] class_loss: 0.0752 s_domain_loss: 0.3755 t_domain_loss: 0.4134 \n","[5/10] class_loss: 0.0879 s_domain_loss: 1.0834 t_domain_loss: 0.2236 \n","[6/10] class_loss: 0.0469 s_domain_loss: 0.0848 t_domain_loss: 1.5810 \n","[7/10] class_loss: 0.0541 s_domain_loss: 1.0818 t_domain_loss: 0.1425 \n","[8/10] class_loss: 0.0843 s_domain_loss: 0.6477 t_domain_loss: 0.1856 \n","[9/10] class_loss: 0.0844 s_domain_loss: 0.1099 t_domain_loss: 1.1503 \n","[10/10] class_loss: 0.1017 s_domain_loss: 0.9950 t_domain_loss: 0.1558 \n","\n","Epoch 0005 / 0020\n","=================\n","[1/10] class_loss: 0.0656 s_domain_loss: 0.2479 t_domain_loss: 0.5128 \n","[2/10] class_loss: 0.0883 s_domain_loss: 0.4167 t_domain_loss: 0.4109 \n","[3/10] class_loss: 0.0729 s_domain_loss: 0.4542 t_domain_loss: 0.1736 \n","[4/10] class_loss: 0.0579 s_domain_loss: 0.2976 t_domain_loss: 0.2404 \n","[5/10] class_loss: 0.0628 s_domain_loss: 0.3730 t_domain_loss: 0.3337 \n","[6/10] class_loss: 0.0814 s_domain_loss: 0.2759 t_domain_loss: 0.4466 \n","[7/10] class_loss: 0.0759 s_domain_loss: 0.2363 t_domain_loss: 0.3513 \n","[8/10] class_loss: 0.0515 s_domain_loss: 0.5250 t_domain_loss: 0.0954 \n","[9/10] class_loss: 0.0388 s_domain_loss: 0.3095 t_domain_loss: 0.2170 \n","[10/10] class_loss: 0.0567 s_domain_loss: 0.0772 t_domain_loss: 0.5968 \n","\n","Epoch 0006 / 0020\n","=================\n","[1/10] class_loss: 0.0723 s_domain_loss: 0.3261 t_domain_loss: 0.1747 \n","[2/10] class_loss: 0.0858 s_domain_loss: 0.4925 t_domain_loss: 0.0444 \n","[3/10] class_loss: 0.0899 s_domain_loss: 0.2644 t_domain_loss: 0.1018 \n","[4/10] class_loss: 0.0617 s_domain_loss: 0.0547 t_domain_loss: 0.5317 \n","[5/10] class_loss: 0.0698 s_domain_loss: 0.3589 t_domain_loss: 0.2792 \n","[6/10] class_loss: 0.0858 s_domain_loss: 0.2687 t_domain_loss: 0.0432 \n","[7/10] class_loss: 0.1145 s_domain_loss: 0.3026 t_domain_loss: 0.0480 \n","[8/10] class_loss: 0.0756 s_domain_loss: 0.1096 t_domain_loss: 0.1652 \n","[9/10] class_loss: 0.0770 s_domain_loss: 0.0332 t_domain_loss: 0.2334 \n","[10/10] class_loss: 0.1273 s_domain_loss: 0.0637 t_domain_loss: 0.0873 \n","\n","Epoch 0007 / 0020\n","=================\n","[1/10] class_loss: 0.0669 s_domain_loss: 0.2406 t_domain_loss: 0.0493 \n","[2/10] class_loss: 0.0788 s_domain_loss: 0.2079 t_domain_loss: 0.0668 \n","[3/10] class_loss: 0.1022 s_domain_loss: 0.1206 t_domain_loss: 0.1230 \n","[4/10] class_loss: 0.0577 s_domain_loss: 0.0537 t_domain_loss: 0.3399 \n","[5/10] class_loss: 0.0544 s_domain_loss: 0.0677 t_domain_loss: 0.0592 \n","[6/10] class_loss: 0.0634 s_domain_loss: 0.2474 t_domain_loss: 0.0201 \n","[7/10] class_loss: 0.1272 s_domain_loss: 0.1513 t_domain_loss: 0.0281 \n","[8/10] class_loss: 0.0458 s_domain_loss: 0.0513 t_domain_loss: 0.0823 \n","[9/10] class_loss: 0.0743 s_domain_loss: 0.1080 t_domain_loss: 0.1336 \n","[10/10] class_loss: 0.0458 s_domain_loss: 0.0376 t_domain_loss: 0.0962 \n","\n","Epoch 0008 / 0020\n","=================\n","[1/10] class_loss: 0.0671 s_domain_loss: 0.0180 t_domain_loss: 0.0950 \n","[2/10] class_loss: 0.0890 s_domain_loss: 0.0805 t_domain_loss: 0.0371 \n","[3/10] class_loss: 0.1192 s_domain_loss: 0.2937 t_domain_loss: 0.0133 \n","[4/10] class_loss: 0.1676 s_domain_loss: 0.1869 t_domain_loss: 0.0573 \n","[5/10] class_loss: 0.0543 s_domain_loss: 0.0140 t_domain_loss: 0.0994 \n","[6/10] class_loss: 0.0563 s_domain_loss: 0.0446 t_domain_loss: 0.1448 \n","[7/10] class_loss: 0.0557 s_domain_loss: 0.0123 t_domain_loss: 0.1329 \n","[8/10] class_loss: 0.1204 s_domain_loss: 0.0349 t_domain_loss: 0.0398 \n","[9/10] class_loss: 0.1059 s_domain_loss: 0.2857 t_domain_loss: 0.0111 \n","[10/10] class_loss: 0.0732 s_domain_loss: 0.2415 t_domain_loss: 0.1105 \n","\n","Epoch 0009 / 0020\n","=================\n","[1/10] class_loss: 0.0429 s_domain_loss: 0.0323 t_domain_loss: 0.0200 \n","[2/10] class_loss: 0.0406 s_domain_loss: 0.0790 t_domain_loss: 0.0301 \n","[3/10] class_loss: 0.0548 s_domain_loss: 0.0046 t_domain_loss: 0.1254 \n","[4/10] class_loss: 0.0839 s_domain_loss: 0.0211 t_domain_loss: 0.0652 \n","[5/10] class_loss: 0.0769 s_domain_loss: 0.0117 t_domain_loss: 0.0209 \n","[6/10] class_loss: 0.0532 s_domain_loss: 0.1166 t_domain_loss: 0.0186 \n","[7/10] class_loss: 0.0585 s_domain_loss: 0.0091 t_domain_loss: 0.0132 \n","[8/10] class_loss: 0.0612 s_domain_loss: 0.0186 t_domain_loss: 0.0112 \n","[9/10] class_loss: 0.0425 s_domain_loss: 0.0113 t_domain_loss: 0.0137 \n","[10/10] class_loss: 0.0755 s_domain_loss: 0.1372 t_domain_loss: 0.0096 \n","\n","Epoch 0010 / 0020\n","=================\n","[1/10] class_loss: 0.0507 s_domain_loss: 0.0239 t_domain_loss: 0.0309 \n","[2/10] class_loss: 0.0330 s_domain_loss: 0.0261 t_domain_loss: 0.0331 \n","[3/10] class_loss: 0.0413 s_domain_loss: 0.0038 t_domain_loss: 0.0350 \n","[4/10] class_loss: 0.0212 s_domain_loss: 0.0348 t_domain_loss: 0.0198 \n","[5/10] class_loss: 0.0192 s_domain_loss: 0.0055 t_domain_loss: 0.0198 \n","[6/10] class_loss: 0.0257 s_domain_loss: 0.0036 t_domain_loss: 0.0218 \n","[7/10] class_loss: 0.0294 s_domain_loss: 0.0103 t_domain_loss: 0.0232 \n","[8/10] class_loss: 0.0428 s_domain_loss: 0.0138 t_domain_loss: 0.0247 \n","[9/10] class_loss: 0.0200 s_domain_loss: 0.0065 t_domain_loss: 0.0123 \n","[10/10] class_loss: 0.0191 s_domain_loss: 0.1259 t_domain_loss: 0.0052 \n","\n","Epoch 0011 / 0020\n","=================\n","[1/10] class_loss: 0.0330 s_domain_loss: 0.0097 t_domain_loss: 0.0078 \n","[2/10] class_loss: 0.0432 s_domain_loss: 0.1111 t_domain_loss: 0.0084 \n","[3/10] class_loss: 0.0389 s_domain_loss: 0.0066 t_domain_loss: 0.0172 \n","[4/10] class_loss: 0.0158 s_domain_loss: 0.0008 t_domain_loss: 0.0301 \n","[5/10] class_loss: 0.0126 s_domain_loss: 0.0292 t_domain_loss: 0.0339 \n","[6/10] class_loss: 0.0190 s_domain_loss: 0.0782 t_domain_loss: 0.0383 \n","[7/10] class_loss: 0.0369 s_domain_loss: 0.0020 t_domain_loss: 0.0577 \n","[8/10] class_loss: 0.0515 s_domain_loss: 0.0177 t_domain_loss: 0.1077 \n","[9/10] class_loss: 0.0280 s_domain_loss: 0.0011 t_domain_loss: 0.0283 \n","[10/10] class_loss: 0.0168 s_domain_loss: 0.0117 t_domain_loss: 0.0035 \n","\n","Epoch 0012 / 0020\n","=================\n","[1/10] class_loss: 0.0233 s_domain_loss: 0.0057 t_domain_loss: 0.0037 \n","[2/10] class_loss: 0.0157 s_domain_loss: 0.0280 t_domain_loss: 0.0017 \n","[3/10] class_loss: 0.0542 s_domain_loss: 0.0903 t_domain_loss: 0.0010 \n","[4/10] class_loss: 0.0125 s_domain_loss: 0.0188 t_domain_loss: 0.0009 \n","[5/10] class_loss: 0.0112 s_domain_loss: 0.0111 t_domain_loss: 0.0013 \n","[6/10] class_loss: 0.0171 s_domain_loss: 0.0867 t_domain_loss: 0.0015 \n","[7/10] class_loss: 0.0114 s_domain_loss: 0.0050 t_domain_loss: 0.0032 \n","[8/10] class_loss: 0.0162 s_domain_loss: 0.0018 t_domain_loss: 0.0078 \n","[9/10] class_loss: 0.0223 s_domain_loss: 0.0038 t_domain_loss: 0.0111 \n","[10/10] class_loss: 0.0328 s_domain_loss: 0.0040 t_domain_loss: 0.0079 \n","\n","Epoch 0013 / 0020\n","=================\n","[1/10] class_loss: 0.0277 s_domain_loss: 0.0078 t_domain_loss: 0.0216 \n","[2/10] class_loss: 0.0124 s_domain_loss: 0.0006 t_domain_loss: 0.0240 \n","[3/10] class_loss: 0.0304 s_domain_loss: 0.0055 t_domain_loss: 0.0327 \n","[4/10] class_loss: 0.0125 s_domain_loss: 0.0031 t_domain_loss: 0.0128 \n","[5/10] class_loss: 0.0168 s_domain_loss: 0.0125 t_domain_loss: 0.0104 \n","[6/10] class_loss: 0.0258 s_domain_loss: 0.0031 t_domain_loss: 0.0065 \n","[7/10] class_loss: 0.0105 s_domain_loss: 0.0264 t_domain_loss: 0.0063 \n","[8/10] class_loss: 0.0138 s_domain_loss: 0.0070 t_domain_loss: 0.0061 \n","[9/10] class_loss: 0.0046 s_domain_loss: 0.0559 t_domain_loss: 0.0052 \n","[10/10] class_loss: 0.0185 s_domain_loss: 0.0029 t_domain_loss: 0.0043 \n","\n","Epoch 0014 / 0020\n","=================\n","[1/10] class_loss: 0.0098 s_domain_loss: 0.0074 t_domain_loss: 0.0213 \n","[2/10] class_loss: 0.0099 s_domain_loss: 0.0092 t_domain_loss: 0.0084 \n","[3/10] class_loss: 0.0084 s_domain_loss: 0.0031 t_domain_loss: 0.0068 \n","[4/10] class_loss: 0.0105 s_domain_loss: 0.0004 t_domain_loss: 0.0077 \n","[5/10] class_loss: 0.0148 s_domain_loss: 0.0004 t_domain_loss: 0.0069 \n","[6/10] class_loss: 0.0360 s_domain_loss: 0.0005 t_domain_loss: 0.0064 \n","[7/10] class_loss: 0.0151 s_domain_loss: 0.0004 t_domain_loss: 0.0076 \n","[8/10] class_loss: 0.0062 s_domain_loss: 0.0053 t_domain_loss: 0.0071 \n","[9/10] class_loss: 0.0145 s_domain_loss: 0.0052 t_domain_loss: 0.0053 \n","[10/10] class_loss: 0.0093 s_domain_loss: 0.0023 t_domain_loss: 0.0027 \n","\n","Epoch 0015 / 0020\n","=================\n","[1/10] class_loss: 0.0038 s_domain_loss: 0.0076 t_domain_loss: 0.0035 \n","[2/10] class_loss: 0.0150 s_domain_loss: 0.0060 t_domain_loss: 0.0031 \n","[3/10] class_loss: 0.0085 s_domain_loss: 0.0087 t_domain_loss: 0.0027 \n","[4/10] class_loss: 0.0132 s_domain_loss: 0.0040 t_domain_loss: 0.0024 \n","[5/10] class_loss: 0.0044 s_domain_loss: 0.0053 t_domain_loss: 0.0020 \n","[6/10] class_loss: 0.0088 s_domain_loss: 0.0123 t_domain_loss: 0.0023 \n","[7/10] class_loss: 0.0061 s_domain_loss: 0.0067 t_domain_loss: 0.0026 \n","[8/10] class_loss: 0.0032 s_domain_loss: 0.0005 t_domain_loss: 0.0033 \n","[9/10] class_loss: 0.0023 s_domain_loss: 0.0495 t_domain_loss: 0.0033 \n","[10/10] class_loss: 0.0027 s_domain_loss: 0.0011 t_domain_loss: 0.0018 \n","\n","Epoch 0016 / 0020\n","=================\n","[1/10] class_loss: 0.0030 s_domain_loss: 0.0004 t_domain_loss: 0.0047 \n","[2/10] class_loss: 0.0102 s_domain_loss: 0.0090 t_domain_loss: 0.0054 \n","[3/10] class_loss: 0.0035 s_domain_loss: 0.0002 t_domain_loss: 0.0061 \n","[4/10] class_loss: 0.0098 s_domain_loss: 0.1066 t_domain_loss: 0.0068 \n","[5/10] class_loss: 0.0023 s_domain_loss: 0.0054 t_domain_loss: 0.0096 \n","[6/10] class_loss: 0.0058 s_domain_loss: 0.0001 t_domain_loss: 0.0160 \n","[7/10] class_loss: 0.0072 s_domain_loss: 0.0018 t_domain_loss: 0.0261 \n","[8/10] class_loss: 0.0098 s_domain_loss: 0.0008 t_domain_loss: 0.0334 \n","[9/10] class_loss: 0.0225 s_domain_loss: 0.0265 t_domain_loss: 0.0233 \n","[10/10] class_loss: 0.0227 s_domain_loss: 0.0204 t_domain_loss: 0.0077 \n","\n","Epoch 0017 / 0020\n","=================\n","[1/10] class_loss: 0.0049 s_domain_loss: 0.0029 t_domain_loss: 0.0172 \n","[2/10] class_loss: 0.0067 s_domain_loss: 0.0001 t_domain_loss: 0.0102 \n","[3/10] class_loss: 0.0228 s_domain_loss: 0.0006 t_domain_loss: 0.0085 \n","[4/10] class_loss: 0.0111 s_domain_loss: 0.0017 t_domain_loss: 0.0056 \n","[5/10] class_loss: 0.0149 s_domain_loss: 0.0004 t_domain_loss: 0.0034 \n","[6/10] class_loss: 0.0436 s_domain_loss: 0.0022 t_domain_loss: 0.0026 \n","[7/10] class_loss: 0.0167 s_domain_loss: 0.0029 t_domain_loss: 0.0018 \n","[8/10] class_loss: 0.0187 s_domain_loss: 0.0052 t_domain_loss: 0.0014 \n","[9/10] class_loss: 0.0064 s_domain_loss: 0.0101 t_domain_loss: 0.0010 \n","[10/10] class_loss: 0.0176 s_domain_loss: 0.3858 t_domain_loss: 0.0006 \n","\n","Epoch 0018 / 0020\n","=================\n","[1/10] class_loss: 0.1760 s_domain_loss: 0.5045 t_domain_loss: 0.2444 \n","[2/10] class_loss: 0.0129 s_domain_loss: 0.0001 t_domain_loss: 0.0364 \n","[3/10] class_loss: 0.0750 s_domain_loss: 0.0006 t_domain_loss: 0.1562 \n","[4/10] class_loss: 0.2153 s_domain_loss: 0.1919 t_domain_loss: 0.1745 \n","[5/10] class_loss: 0.2283 s_domain_loss: 0.2754 t_domain_loss: 0.1171 \n","[6/10] class_loss: 0.0824 s_domain_loss: 0.1109 t_domain_loss: 0.1025 \n","[7/10] class_loss: 0.1424 s_domain_loss: 0.0117 t_domain_loss: 0.1153 \n","[8/10] class_loss: 0.3112 s_domain_loss: 2.0288 t_domain_loss: 0.3281 \n","[9/10] class_loss: 0.7514 s_domain_loss: 2.1630 t_domain_loss: 0.1586 \n","[10/10] class_loss: 0.8175 s_domain_loss: 0.5984 t_domain_loss: 3.2679 \n","\n","Epoch 0019 / 0020\n","=================\n","[1/10] class_loss: 2.7437 s_domain_loss: 0.1449 t_domain_loss: 3.0074 \n","[2/10] class_loss: 1.3135 s_domain_loss: 3.7114 t_domain_loss: 0.1093 \n","[3/10] class_loss: 1.7015 s_domain_loss: 2.8484 t_domain_loss: 0.2525 \n","[4/10] class_loss: 1.6601 s_domain_loss: 0.0884 t_domain_loss: 3.4138 \n","[5/10] class_loss: 1.5316 s_domain_loss: 0.3019 t_domain_loss: 1.9994 \n","[6/10] class_loss: 1.7859 s_domain_loss: 3.1055 t_domain_loss: 0.2850 \n","[7/10] class_loss: 2.3055 s_domain_loss: 2.2082 t_domain_loss: 0.4517 \n","[8/10] class_loss: 2.0225 s_domain_loss: 0.3167 t_domain_loss: 3.4124 \n","[9/10] class_loss: 1.7571 s_domain_loss: 0.2180 t_domain_loss: 2.4661 \n","[10/10] class_loss: 1.8505 s_domain_loss: 2.2407 t_domain_loss: 0.4766 \n","\n","Epoch 0020 / 0020\n","=================\n","[1/10] class_loss: 4.9553 s_domain_loss: 1.6646 t_domain_loss: 0.5717 \n","[2/10] class_loss: 2.2537 s_domain_loss: 1.4760 t_domain_loss: 0.6259 \n","[3/10] class_loss: 1.8578 s_domain_loss: 1.4276 t_domain_loss: 0.6254 \n","[4/10] class_loss: 1.7657 s_domain_loss: 0.9109 t_domain_loss: 0.7013 \n","[5/10] class_loss: 1.8474 s_domain_loss: 0.5146 t_domain_loss: 0.9192 \n","[6/10] class_loss: 1.8442 s_domain_loss: 0.3196 t_domain_loss: 0.9546 \n","[7/10] class_loss: 1.8699 s_domain_loss: 0.2212 t_domain_loss: 1.8357 \n","[8/10] class_loss: 1.8470 s_domain_loss: 0.2137 t_domain_loss: 1.4946 \n","[9/10] class_loss: 1.8936 s_domain_loss: 0.2554 t_domain_loss: 1.0118 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[10/10] class_loss: 1.9033 s_domain_loss: 0.2977 t_domain_loss: 1.7552 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.03it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.2275390625\n","hyperprameters are: LR=0.007 and NUM_EPOCHS = 30\n","\n","Epoch 0001 / 0030\n","=================\n","[1/10] class_loss: 2.0417 s_domain_loss: 0.5381 t_domain_loss: 0.9218 \n","[2/10] class_loss: 1.2032 s_domain_loss: 1.5071 t_domain_loss: 0.2722 \n","[3/10] class_loss: 0.7454 s_domain_loss: 0.1023 t_domain_loss: 2.3800 \n","[4/10] class_loss: 0.4497 s_domain_loss: 1.9988 t_domain_loss: 0.1586 \n","[5/10] class_loss: 0.3450 s_domain_loss: 0.3021 t_domain_loss: 1.3382 \n","[6/10] class_loss: 0.4050 s_domain_loss: 1.0312 t_domain_loss: 0.4462 \n","[7/10] class_loss: 0.2421 s_domain_loss: 0.4211 t_domain_loss: 1.0476 \n","[8/10] class_loss: 0.3472 s_domain_loss: 1.3471 t_domain_loss: 0.3010 \n","[9/10] class_loss: 0.2236 s_domain_loss: 0.1479 t_domain_loss: 1.9491 \n","[10/10] class_loss: 0.1660 s_domain_loss: 2.0668 t_domain_loss: 0.1332 \n","\n","Epoch 0002 / 0030\n","=================\n","[1/10] class_loss: 0.1400 s_domain_loss: 0.2082 t_domain_loss: 1.5636 \n","[2/10] class_loss: 0.1840 s_domain_loss: 1.1871 t_domain_loss: 0.3239 \n","[3/10] class_loss: 0.1710 s_domain_loss: 0.3306 t_domain_loss: 1.1241 \n","[4/10] class_loss: 0.1225 s_domain_loss: 1.2792 t_domain_loss: 0.2876 \n","[5/10] class_loss: 0.1726 s_domain_loss: 0.1817 t_domain_loss: 1.5937 \n","[6/10] class_loss: 0.1523 s_domain_loss: 1.7794 t_domain_loss: 0.1590 \n","[7/10] class_loss: 0.1006 s_domain_loss: 0.1725 t_domain_loss: 1.6260 \n","[8/10] class_loss: 0.0962 s_domain_loss: 1.4743 t_domain_loss: 0.2167 \n","[9/10] class_loss: 0.0737 s_domain_loss: 0.2326 t_domain_loss: 1.3573 \n","[10/10] class_loss: 0.0645 s_domain_loss: 1.2311 t_domain_loss: 0.2523 \n","\n","Epoch 0003 / 0030\n","=================\n","[1/10] class_loss: 0.0839 s_domain_loss: 0.3092 t_domain_loss: 1.1195 \n","[2/10] class_loss: 0.0920 s_domain_loss: 0.8897 t_domain_loss: 0.3548 \n","[3/10] class_loss: 0.0814 s_domain_loss: 0.3990 t_domain_loss: 0.7691 \n","[4/10] class_loss: 0.0660 s_domain_loss: 0.7342 t_domain_loss: 0.4393 \n","[5/10] class_loss: 0.0382 s_domain_loss: 0.5487 t_domain_loss: 0.5614 \n","[6/10] class_loss: 0.0752 s_domain_loss: 0.3679 t_domain_loss: 0.7489 \n","[7/10] class_loss: 0.0777 s_domain_loss: 1.2539 t_domain_loss: 0.2027 \n","[8/10] class_loss: 0.0696 s_domain_loss: 0.1196 t_domain_loss: 1.7165 \n","[9/10] class_loss: 0.0628 s_domain_loss: 1.4613 t_domain_loss: 0.1488 \n","[10/10] class_loss: 0.0500 s_domain_loss: 0.3864 t_domain_loss: 0.6187 \n","\n","Epoch 0004 / 0030\n","=================\n","[1/10] class_loss: 0.0491 s_domain_loss: 0.3159 t_domain_loss: 0.7319 \n","[2/10] class_loss: 0.0431 s_domain_loss: 1.1658 t_domain_loss: 0.2064 \n","[3/10] class_loss: 0.0462 s_domain_loss: 0.1115 t_domain_loss: 1.1995 \n","[4/10] class_loss: 0.0386 s_domain_loss: 1.1836 t_domain_loss: 0.1564 \n","[5/10] class_loss: 0.0638 s_domain_loss: 0.3743 t_domain_loss: 0.5667 \n","[6/10] class_loss: 0.0685 s_domain_loss: 0.2493 t_domain_loss: 0.6665 \n","[7/10] class_loss: 0.0306 s_domain_loss: 1.2363 t_domain_loss: 0.1092 \n","[8/10] class_loss: 0.0652 s_domain_loss: 0.1709 t_domain_loss: 0.9424 \n","[9/10] class_loss: 0.1475 s_domain_loss: 0.4171 t_domain_loss: 0.3662 \n","[10/10] class_loss: 0.0809 s_domain_loss: 0.8175 t_domain_loss: 0.1105 \n","\n","Epoch 0005 / 0030\n","=================\n","[1/10] class_loss: 0.0570 s_domain_loss: 0.1014 t_domain_loss: 0.8261 \n","[2/10] class_loss: 0.0947 s_domain_loss: 0.5053 t_domain_loss: 0.3143 \n","[3/10] class_loss: 0.0636 s_domain_loss: 0.4748 t_domain_loss: 0.1878 \n","[4/10] class_loss: 0.0496 s_domain_loss: 0.4046 t_domain_loss: 0.5101 \n","[5/10] class_loss: 0.0580 s_domain_loss: 0.2858 t_domain_loss: 0.2909 \n","[6/10] class_loss: 0.0712 s_domain_loss: 0.6040 t_domain_loss: 0.1806 \n","[7/10] class_loss: 0.0513 s_domain_loss: 0.1225 t_domain_loss: 0.6792 \n","[8/10] class_loss: 0.0268 s_domain_loss: 0.3856 t_domain_loss: 0.1557 \n","[9/10] class_loss: 0.0416 s_domain_loss: 0.4056 t_domain_loss: 0.1422 \n","[10/10] class_loss: 0.0344 s_domain_loss: 0.1761 t_domain_loss: 0.2891 \n","\n","Epoch 0006 / 0030\n","=================\n","[1/10] class_loss: 0.0316 s_domain_loss: 0.2360 t_domain_loss: 0.3590 \n","[2/10] class_loss: 0.1105 s_domain_loss: 0.2985 t_domain_loss: 0.1450 \n","[3/10] class_loss: 0.0548 s_domain_loss: 0.4639 t_domain_loss: 0.1145 \n","[4/10] class_loss: 0.0333 s_domain_loss: 0.0446 t_domain_loss: 0.5218 \n","[5/10] class_loss: 0.1012 s_domain_loss: 0.3158 t_domain_loss: 0.2043 \n","[6/10] class_loss: 0.0559 s_domain_loss: 0.2692 t_domain_loss: 0.0705 \n","[7/10] class_loss: 0.0856 s_domain_loss: 0.5691 t_domain_loss: 0.0629 \n","[8/10] class_loss: 0.0677 s_domain_loss: 0.0222 t_domain_loss: 0.6025 \n","[9/10] class_loss: 0.0505 s_domain_loss: 0.1411 t_domain_loss: 0.2371 \n","[10/10] class_loss: 0.0331 s_domain_loss: 0.3194 t_domain_loss: 0.0381 \n","\n","Epoch 0007 / 0030\n","=================\n","[1/10] class_loss: 0.0348 s_domain_loss: 0.2877 t_domain_loss: 0.0490 \n","[2/10] class_loss: 0.0292 s_domain_loss: 0.0741 t_domain_loss: 0.1423 \n","[3/10] class_loss: 0.0791 s_domain_loss: 0.0422 t_domain_loss: 0.2261 \n","[4/10] class_loss: 0.1009 s_domain_loss: 0.0827 t_domain_loss: 0.1235 \n","[5/10] class_loss: 0.0591 s_domain_loss: 0.1945 t_domain_loss: 0.0404 \n","[6/10] class_loss: 0.0870 s_domain_loss: 0.3089 t_domain_loss: 0.0441 \n","[7/10] class_loss: 0.0712 s_domain_loss: 0.0607 t_domain_loss: 0.1825 \n","[8/10] class_loss: 0.1120 s_domain_loss: 0.1472 t_domain_loss: 0.2324 \n","[9/10] class_loss: 0.0455 s_domain_loss: 0.0189 t_domain_loss: 0.1094 \n","[10/10] class_loss: 0.0486 s_domain_loss: 0.1102 t_domain_loss: 0.0305 \n","\n","Epoch 0008 / 0030\n","=================\n","[1/10] class_loss: 0.0774 s_domain_loss: 0.1566 t_domain_loss: 0.0170 \n","[2/10] class_loss: 0.0460 s_domain_loss: 0.0590 t_domain_loss: 0.0244 \n","[3/10] class_loss: 0.0444 s_domain_loss: 0.0406 t_domain_loss: 0.0468 \n","[4/10] class_loss: 0.0378 s_domain_loss: 0.0180 t_domain_loss: 0.0961 \n","[5/10] class_loss: 0.0528 s_domain_loss: 0.0832 t_domain_loss: 0.0635 \n","[6/10] class_loss: 0.0425 s_domain_loss: 0.0790 t_domain_loss: 0.0450 \n","[7/10] class_loss: 0.0237 s_domain_loss: 0.0534 t_domain_loss: 0.0303 \n","[8/10] class_loss: 0.0389 s_domain_loss: 0.1124 t_domain_loss: 0.0196 \n","[9/10] class_loss: 0.0713 s_domain_loss: 0.0858 t_domain_loss: 0.0246 \n","[10/10] class_loss: 0.0373 s_domain_loss: 0.0401 t_domain_loss: 0.0239 \n","\n","Epoch 0009 / 0030\n","=================\n","[1/10] class_loss: 0.0231 s_domain_loss: 0.0311 t_domain_loss: 0.0845 \n","[2/10] class_loss: 0.0191 s_domain_loss: 0.0063 t_domain_loss: 0.0554 \n","[3/10] class_loss: 0.0276 s_domain_loss: 0.0204 t_domain_loss: 0.0363 \n","[4/10] class_loss: 0.0297 s_domain_loss: 0.0184 t_domain_loss: 0.0217 \n","[5/10] class_loss: 0.0359 s_domain_loss: 0.0495 t_domain_loss: 0.0139 \n","[6/10] class_loss: 0.0348 s_domain_loss: 0.0390 t_domain_loss: 0.0107 \n","[7/10] class_loss: 0.0381 s_domain_loss: 0.0143 t_domain_loss: 0.0116 \n","[8/10] class_loss: 0.0132 s_domain_loss: 0.0151 t_domain_loss: 0.0121 \n","[9/10] class_loss: 0.0222 s_domain_loss: 0.0203 t_domain_loss: 0.0202 \n","[10/10] class_loss: 0.0342 s_domain_loss: 0.0164 t_domain_loss: 0.0051 \n","\n","Epoch 0010 / 0030\n","=================\n","[1/10] class_loss: 0.0137 s_domain_loss: 0.0130 t_domain_loss: 0.0104 \n","[2/10] class_loss: 0.0258 s_domain_loss: 0.0175 t_domain_loss: 0.0088 \n","[3/10] class_loss: 0.0338 s_domain_loss: 0.0159 t_domain_loss: 0.0109 \n","[4/10] class_loss: 0.0222 s_domain_loss: 0.0276 t_domain_loss: 0.0113 \n","[5/10] class_loss: 0.0142 s_domain_loss: 0.0076 t_domain_loss: 0.0147 \n","[6/10] class_loss: 0.0155 s_domain_loss: 0.0311 t_domain_loss: 0.0171 \n","[7/10] class_loss: 0.0066 s_domain_loss: 0.0108 t_domain_loss: 0.0211 \n","[8/10] class_loss: 0.0120 s_domain_loss: 0.0116 t_domain_loss: 0.0198 \n","[9/10] class_loss: 0.0103 s_domain_loss: 0.0063 t_domain_loss: 0.0211 \n","[10/10] class_loss: 0.0089 s_domain_loss: 0.0263 t_domain_loss: 0.0088 \n","\n","Epoch 0011 / 0030\n","=================\n","[1/10] class_loss: 0.0064 s_domain_loss: 0.0156 t_domain_loss: 0.0177 \n","[2/10] class_loss: 0.0151 s_domain_loss: 0.0083 t_domain_loss: 0.0141 \n","[3/10] class_loss: 0.0139 s_domain_loss: 0.0025 t_domain_loss: 0.0128 \n","[4/10] class_loss: 0.0079 s_domain_loss: 0.0223 t_domain_loss: 0.0104 \n","[5/10] class_loss: 0.0087 s_domain_loss: 0.0013 t_domain_loss: 0.0100 \n","[6/10] class_loss: 0.0089 s_domain_loss: 0.0150 t_domain_loss: 0.0096 \n","[7/10] class_loss: 0.0098 s_domain_loss: 0.0049 t_domain_loss: 0.0088 \n","[8/10] class_loss: 0.0071 s_domain_loss: 0.0035 t_domain_loss: 0.0067 \n","[9/10] class_loss: 0.0098 s_domain_loss: 0.0070 t_domain_loss: 0.0066 \n","[10/10] class_loss: 0.0118 s_domain_loss: 0.0246 t_domain_loss: 0.0025 \n","\n","Epoch 0012 / 0030\n","=================\n","[1/10] class_loss: 0.0094 s_domain_loss: 0.0233 t_domain_loss: 0.0060 \n","[2/10] class_loss: 0.0038 s_domain_loss: 0.0129 t_domain_loss: 0.0058 \n","[3/10] class_loss: 0.0055 s_domain_loss: 0.0071 t_domain_loss: 0.0078 \n","[4/10] class_loss: 0.0168 s_domain_loss: 0.0063 t_domain_loss: 0.0076 \n","[5/10] class_loss: 0.0041 s_domain_loss: 0.0155 t_domain_loss: 0.0099 \n","[6/10] class_loss: 0.0070 s_domain_loss: 0.0339 t_domain_loss: 0.0118 \n","[7/10] class_loss: 0.0059 s_domain_loss: 0.0399 t_domain_loss: 0.0157 \n","[8/10] class_loss: 0.0075 s_domain_loss: 0.0012 t_domain_loss: 0.0190 \n","[9/10] class_loss: 0.0144 s_domain_loss: 0.0005 t_domain_loss: 0.0250 \n","[10/10] class_loss: 0.0230 s_domain_loss: 0.0100 t_domain_loss: 0.0150 \n","\n","Epoch 0013 / 0030\n","=================\n","[1/10] class_loss: 0.0290 s_domain_loss: 0.0957 t_domain_loss: 0.0169 \n","[2/10] class_loss: 0.0065 s_domain_loss: 0.0130 t_domain_loss: 0.0232 \n","[3/10] class_loss: 0.0134 s_domain_loss: 0.0013 t_domain_loss: 0.0333 \n","[4/10] class_loss: 0.0224 s_domain_loss: 0.0072 t_domain_loss: 0.0332 \n","[5/10] class_loss: 0.0396 s_domain_loss: 0.3936 t_domain_loss: 0.0489 \n","[6/10] class_loss: 0.0291 s_domain_loss: 0.1933 t_domain_loss: 0.0479 \n","[7/10] class_loss: 0.0829 s_domain_loss: 0.0495 t_domain_loss: 0.1655 \n","[8/10] class_loss: 0.0556 s_domain_loss: 0.0049 t_domain_loss: 0.1560 \n","[9/10] class_loss: 0.0631 s_domain_loss: 0.0266 t_domain_loss: 0.0791 \n","[10/10] class_loss: 0.0204 s_domain_loss: 0.0233 t_domain_loss: 0.0099 \n","\n","Epoch 0014 / 0030\n","=================\n","[1/10] class_loss: 0.0394 s_domain_loss: 0.3255 t_domain_loss: 0.0049 \n","[2/10] class_loss: 0.0766 s_domain_loss: 0.0368 t_domain_loss: 0.0095 \n","[3/10] class_loss: 0.0834 s_domain_loss: 0.0377 t_domain_loss: 0.1691 \n","[4/10] class_loss: 0.1047 s_domain_loss: 0.0971 t_domain_loss: 0.0226 \n","[5/10] class_loss: 0.1669 s_domain_loss: 1.1017 t_domain_loss: 0.0323 \n","[6/10] class_loss: 0.7904 s_domain_loss: 1.7069 t_domain_loss: 0.3872 \n","[7/10] class_loss: 0.4610 s_domain_loss: 0.1991 t_domain_loss: 2.2044 \n","[8/10] class_loss: 0.5779 s_domain_loss: 1.4258 t_domain_loss: 0.5481 \n","[9/10] class_loss: 0.8425 s_domain_loss: 2.1655 t_domain_loss: 0.2349 \n","[10/10] class_loss: 1.3552 s_domain_loss: 0.5741 t_domain_loss: 1.4815 \n","\n","Epoch 0015 / 0030\n","=================\n","[1/10] class_loss: 3.6578 s_domain_loss: 2.1689 t_domain_loss: 3.6713 \n","[2/10] class_loss: 4.2435 s_domain_loss: 1.3636 t_domain_loss: 0.6492 \n","[3/10] class_loss: 6.5534 s_domain_loss: 1.5538 t_domain_loss: 1.0521 \n","[4/10] class_loss: 12.3857 s_domain_loss: 1.1429 t_domain_loss: 1.2907 \n","[5/10] class_loss: 2.0261 s_domain_loss: 0.8397 t_domain_loss: 0.9944 \n","[6/10] class_loss: 9.9540 s_domain_loss: 1.5664 t_domain_loss: 1.2352 \n","[7/10] class_loss: 2.0305 s_domain_loss: 0.6442 t_domain_loss: 0.7446 \n","[8/10] class_loss: 2.0218 s_domain_loss: 0.6207 t_domain_loss: 1.7247 \n","[9/10] class_loss: 6225.3706 s_domain_loss: 1.8801 t_domain_loss: 1.5340 \n","[10/10] class_loss: 74802.5938 s_domain_loss: 1.4704 t_domain_loss: 0.6699 \n","\n","Epoch 0016 / 0030\n","=================\n","[1/10] class_loss: 4326780987650535849984.0000 s_domain_loss: 0.8664 t_domain_loss: 0.8367 \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0017 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0018 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0019 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0020 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0021 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0022 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0023 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0024 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0025 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0026 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0027 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0028 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0029 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0030 / 0030\n","=================\n","[1/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[10/10] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 10/10 [00:09<00:00,  1.00it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Cartoon: 0.18994140625\n","best hyperparemeters after validation on cartoon are : LR=0.007, NUM_EPOCHS= 20 having validation accuracy= 0.2275390625 and validation loss =1.7302061319351196\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"qxYT3PgINTjv","colab_type":"text"},"source":["###Validation on Sketch"]},{"cell_type":"code","metadata":{"id":"H_zr3wpBNJU8","colab_type":"code","outputId":"8ceb8a32-d27e-4ddb-acca-3318947def44","executionInfo":{"status":"ok","timestamp":1591827337445,"user_tz":-120,"elapsed":10930711,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["max_val_accuracy2=0\n","min_val_loss2=100\n","best_LR2=0\n","best_epoch_num2=0\n","for lrate in Learning_rates:\n","   for epochs in num_epochs:\n","\n","      print(\"hyperprameters are: LR={} and NUM_EPOCHS = {}\".format(lrate, epochs))\n","      alpha= 1\n","      net = DANNAlexnet(num_classes = 7)\n","      net = net.to(DEVICE)\n","\n","      class_loss = nn.CrossEntropyLoss() \n","      domain_loss = nn.CrossEntropyLoss()\n","\n","      parameters_to_optimize = net.parameters() \n","\n","      optimizer = optim.SGD(parameters_to_optimize, lr=lrate, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","\n","      scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n","\n","\n","      max_batches = max(len(train_dataloader), len(sketch_dataloader))\n","      min_batches = min(len(train_dataloader), len(sketch_dataloader))#\n","      net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","\n","      cudnn.benchmark #function to optimize runtime by finding the best configuration for your hw, useful when input size \n","      running_corrects = 0\n","      current_step = 0\n","      for epoch in range(epochs):\n","        print(f'\\nEpoch {epoch+1:04d} / {epochs:04d}', end='\\n=================\\n')\n","        scheduler.step() \n","        train_iterable = iter(train_dataloader)\n","        test_iterable = iter(sketch_dataloader)\n","        for batch in range(max_batches):\n","          net.train() # Sets module in training mode\n","          optimizer.zero_grad() # Zero-ing the gradients \n","          \n","            \n","          try:\n","            image_source, labels_source = next(train_iterable)\n","          except StopIteration:\n","            train_iterable = iter(train_dataloader)\n","            image_source, labels_source = next(train_iterable)\n","\n","          images_source, labels_source = next(train_iterable)\n","          labels_domain = torch.zeros(len(images_source), dtype=torch.long)    \n","          \n","          images_source = images_source.to(DEVICE)\n","          labels_source = labels_source.to(DEVICE)\n","          labels_domain = labels_domain.to(DEVICE)\n","          \n","          class_output = net(images_source)\n","          domain_output = net(images_source, alpha)\n","          \n","\n","\n","          loss_s_label = class_loss(class_output, labels_source)\n","          loss_s_domain = domain_loss(domain_output, labels_domain)\n","          \n","\n","        \n","          targets, _ = next(test_iterable)\n","          target_domain = torch.ones(len(targets), dtype=torch.long)\n","\n","      \n","          targets = targets.to(DEVICE)\n","          target_domain = target_domain.to(DEVICE)\n","\n","          target_output = net(targets, alpha)\n","\n","\n","          loss_t_domain = domain_loss(target_output,target_domain)\n","\n","\n","          loss = loss_s_label + loss_s_domain + loss_t_domain\n","          loss.backward() \n","\n","          optimizer.step() \n","\n","          current_step += 1\n","\n","          print(f'[{batch+1}/{max_batches}] '\n","                f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '\n","                f't_domain_loss: {loss_t_domain.item():.4f} '\n","                )  \n","        \n","\n","      params=valOnSketch()\n","      val_accuracy= params[0]\n","      val_loss=params[1]\n","      \n","      \n","      if val_loss<min_val_loss2:\n","        max_val_accuracy2=val_accuracy\n","        min_val_loss2=val_loss\n","        \n","        best_LR2= lrate\n","        best_epoch_num2= epochs\n","        \n","      \n","      if val_loss<min_val_loss2:\n","        if val_accuracy>max_val_accuracy2:\n","          max_val_accuracy2=val_accuracy\n","          min_val_loss2=val_loss\n","          \n","          best_LR2= lrate\n","          best_epoch_num2=epochs\n","      \n","      \n","      \n","            \n","\n","\n","print (\"best hyperparemeters after validation on sketch are : LR={}, NUM_EPOCHS= {} having validation accuracy= {} and validation loss ={}\".format(best_LR2, best_epoch_num2,max_val_accuracy2,min_val_loss2))     \n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["hyperprameters are: LR=0.005 and NUM_EPOCHS = 10\n","\n","Epoch 0001 / 0010\n","=================\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[1/16] class_loss: 2.1138 s_domain_loss: 0.7101 t_domain_loss: 0.7357 \n","[2/16] class_loss: 1.3060 s_domain_loss: 0.7085 t_domain_loss: 0.7089 \n","[3/16] class_loss: 0.9358 s_domain_loss: 0.6858 t_domain_loss: 0.7405 \n","[4/16] class_loss: 0.6901 s_domain_loss: 0.7407 t_domain_loss: 0.6688 \n","[5/16] class_loss: 0.3901 s_domain_loss: 0.6853 t_domain_loss: 0.7150 \n","[6/16] class_loss: 0.2917 s_domain_loss: 0.6859 t_domain_loss: 0.7034 \n","[7/16] class_loss: 0.2664 s_domain_loss: 0.6893 t_domain_loss: 0.6905 \n","[8/16] class_loss: 0.2520 s_domain_loss: 0.6597 t_domain_loss: 0.7116 \n","[9/16] class_loss: 0.2211 s_domain_loss: 0.6823 t_domain_loss: 0.6791 \n","[10/16] class_loss: 0.1428 s_domain_loss: 0.6787 t_domain_loss: 0.6930 \n","[11/16] class_loss: 0.2312 s_domain_loss: 0.6372 t_domain_loss: 0.7145 \n","[12/16] class_loss: 0.1514 s_domain_loss: 0.7411 t_domain_loss: 0.5900 \n","[13/16] class_loss: 0.2153 s_domain_loss: 0.5995 t_domain_loss: 0.7195 \n","[14/16] class_loss: 0.1353 s_domain_loss: 0.6633 t_domain_loss: 0.6514 \n","[15/16] class_loss: 0.1193 s_domain_loss: 0.6558 t_domain_loss: 0.6234 \n","[16/16] class_loss: 0.1545 s_domain_loss: 0.6150 t_domain_loss: 0.6762 \n","\n","Epoch 0002 / 0010\n","=================\n","[1/16] class_loss: 0.1899 s_domain_loss: 0.6358 t_domain_loss: 0.6290 \n","[2/16] class_loss: 0.1344 s_domain_loss: 0.6204 t_domain_loss: 0.6189 \n","[3/16] class_loss: 0.1570 s_domain_loss: 0.6166 t_domain_loss: 0.6214 \n","[4/16] class_loss: 0.0586 s_domain_loss: 0.6392 t_domain_loss: 0.5806 \n","[5/16] class_loss: 0.1024 s_domain_loss: 0.6748 t_domain_loss: 0.5854 \n","[6/16] class_loss: 0.0334 s_domain_loss: 0.5059 t_domain_loss: 0.6983 \n","[7/16] class_loss: 0.0764 s_domain_loss: 0.6662 t_domain_loss: 0.5008 \n","[8/16] class_loss: 0.0909 s_domain_loss: 0.5967 t_domain_loss: 0.5835 \n","[9/16] class_loss: 0.0389 s_domain_loss: 0.4836 t_domain_loss: 0.6858 \n","[10/16] class_loss: 0.0805 s_domain_loss: 0.7854 t_domain_loss: 0.4392 \n","[11/16] class_loss: 0.0943 s_domain_loss: 0.4305 t_domain_loss: 0.7157 \n","[12/16] class_loss: 0.0449 s_domain_loss: 0.5926 t_domain_loss: 0.5154 \n","[13/16] class_loss: 0.0523 s_domain_loss: 0.6277 t_domain_loss: 0.4467 \n","[14/16] class_loss: 0.0419 s_domain_loss: 0.4495 t_domain_loss: 0.6697 \n","[15/16] class_loss: 0.0931 s_domain_loss: 0.4920 t_domain_loss: 0.5052 \n","[16/16] class_loss: 0.0801 s_domain_loss: 0.6909 t_domain_loss: 0.3479 \n","\n","Epoch 0003 / 0010\n","=================\n","[1/16] class_loss: 0.0383 s_domain_loss: 0.3724 t_domain_loss: 0.6295 \n","[2/16] class_loss: 0.1171 s_domain_loss: 0.4309 t_domain_loss: 0.4703 \n","[3/16] class_loss: 0.0870 s_domain_loss: 0.8137 t_domain_loss: 0.2732 \n","[4/16] class_loss: 0.0592 s_domain_loss: 0.2527 t_domain_loss: 0.7719 \n","[5/16] class_loss: 0.0538 s_domain_loss: 0.5564 t_domain_loss: 0.3733 \n","[6/16] class_loss: 0.0590 s_domain_loss: 0.7273 t_domain_loss: 0.2389 \n","[7/16] class_loss: 0.0852 s_domain_loss: 0.2166 t_domain_loss: 0.6842 \n","[8/16] class_loss: 0.0630 s_domain_loss: 0.3885 t_domain_loss: 0.3873 \n","[9/16] class_loss: 0.0520 s_domain_loss: 0.5950 t_domain_loss: 0.2020 \n","[10/16] class_loss: 0.0706 s_domain_loss: 0.2954 t_domain_loss: 0.4536 \n","[11/16] class_loss: 0.0390 s_domain_loss: 0.3456 t_domain_loss: 0.4595 \n","[12/16] class_loss: 0.0774 s_domain_loss: 0.4603 t_domain_loss: 0.2812 \n","[13/16] class_loss: 0.0497 s_domain_loss: 0.3828 t_domain_loss: 0.2840 \n","[14/16] class_loss: 0.0615 s_domain_loss: 0.2268 t_domain_loss: 0.3692 \n","[15/16] class_loss: 0.0355 s_domain_loss: 0.2836 t_domain_loss: 0.2416 \n","[16/16] class_loss: 0.0504 s_domain_loss: 0.4839 t_domain_loss: 0.1534 \n","\n","Epoch 0004 / 0010\n","=================\n","[1/16] class_loss: 0.0517 s_domain_loss: 0.1501 t_domain_loss: 0.3588 \n","[2/16] class_loss: 0.0784 s_domain_loss: 0.1933 t_domain_loss: 0.2863 \n","[3/16] class_loss: 0.0379 s_domain_loss: 0.4192 t_domain_loss: 0.1407 \n","[4/16] class_loss: 0.0547 s_domain_loss: 0.2589 t_domain_loss: 0.2042 \n","[5/16] class_loss: 0.0671 s_domain_loss: 0.1264 t_domain_loss: 0.2963 \n","[6/16] class_loss: 0.1019 s_domain_loss: 0.2225 t_domain_loss: 0.1791 \n","[7/16] class_loss: 0.0684 s_domain_loss: 0.2069 t_domain_loss: 0.1057 \n","[8/16] class_loss: 0.0700 s_domain_loss: 0.2464 t_domain_loss: 0.0980 \n","[9/16] class_loss: 0.0714 s_domain_loss: 0.1117 t_domain_loss: 0.1520 \n","[10/16] class_loss: 0.0596 s_domain_loss: 0.1139 t_domain_loss: 0.1819 \n","[11/16] class_loss: 0.0629 s_domain_loss: 0.2410 t_domain_loss: 0.1220 \n","[12/16] class_loss: 0.0735 s_domain_loss: 0.0775 t_domain_loss: 0.1525 \n","[13/16] class_loss: 0.0713 s_domain_loss: 0.1414 t_domain_loss: 0.1115 \n","[14/16] class_loss: 0.0438 s_domain_loss: 0.2665 t_domain_loss: 0.0765 \n","[15/16] class_loss: 0.0613 s_domain_loss: 0.0820 t_domain_loss: 0.0902 \n","[16/16] class_loss: 0.0821 s_domain_loss: 0.3588 t_domain_loss: 0.0839 \n","\n","Epoch 0005 / 0010\n","=================\n","[1/16] class_loss: 0.0653 s_domain_loss: 0.0324 t_domain_loss: 0.2498 \n","[2/16] class_loss: 0.1410 s_domain_loss: 0.0668 t_domain_loss: 0.2171 \n","[3/16] class_loss: 0.0963 s_domain_loss: 0.2081 t_domain_loss: 0.0900 \n","[4/16] class_loss: 0.0601 s_domain_loss: 0.1628 t_domain_loss: 0.0490 \n","[5/16] class_loss: 0.2076 s_domain_loss: 0.4171 t_domain_loss: 0.0412 \n","[6/16] class_loss: 0.1153 s_domain_loss: 0.0635 t_domain_loss: 0.1180 \n","[7/16] class_loss: 0.0641 s_domain_loss: 0.0402 t_domain_loss: 0.2000 \n","[8/16] class_loss: 0.0570 s_domain_loss: 0.0485 t_domain_loss: 0.1280 \n","[9/16] class_loss: 0.0752 s_domain_loss: 0.4138 t_domain_loss: 0.0519 \n","[10/16] class_loss: 0.1971 s_domain_loss: 0.1639 t_domain_loss: 0.0465 \n","[11/16] class_loss: 0.2039 s_domain_loss: 0.6385 t_domain_loss: 0.0605 \n","[12/16] class_loss: 0.1474 s_domain_loss: 0.0418 t_domain_loss: 0.3809 \n","[13/16] class_loss: 0.4529 s_domain_loss: 0.1917 t_domain_loss: 0.3700 \n","[14/16] class_loss: 0.1391 s_domain_loss: 0.0516 t_domain_loss: 0.1363 \n","[15/16] class_loss: 0.1586 s_domain_loss: 0.1280 t_domain_loss: 0.0316 \n","[16/16] class_loss: 0.2495 s_domain_loss: 0.5471 t_domain_loss: 0.0116 \n","\n","Epoch 0006 / 0010\n","=================\n","[1/16] class_loss: 0.1280 s_domain_loss: 0.0794 t_domain_loss: 0.0381 \n","[2/16] class_loss: 0.2255 s_domain_loss: 0.2355 t_domain_loss: 0.0981 \n","[3/16] class_loss: 0.1233 s_domain_loss: 0.0235 t_domain_loss: 0.2861 \n","[4/16] class_loss: 0.1239 s_domain_loss: 0.0239 t_domain_loss: 0.1812 \n","[5/16] class_loss: 0.1594 s_domain_loss: 0.0302 t_domain_loss: 0.0718 \n","[6/16] class_loss: 0.2157 s_domain_loss: 0.1026 t_domain_loss: 0.0223 \n","[7/16] class_loss: 0.2051 s_domain_loss: 0.2364 t_domain_loss: 0.0099 \n","[8/16] class_loss: 0.1232 s_domain_loss: 0.2675 t_domain_loss: 0.0148 \n","[9/16] class_loss: 0.0849 s_domain_loss: 0.1861 t_domain_loss: 0.0495 \n","[10/16] class_loss: 0.1563 s_domain_loss: 0.0361 t_domain_loss: 0.2637 \n","[11/16] class_loss: 0.0915 s_domain_loss: 0.0109 t_domain_loss: 0.1429 \n","[12/16] class_loss: 0.1063 s_domain_loss: 0.0111 t_domain_loss: 0.0628 \n","[13/16] class_loss: 0.1062 s_domain_loss: 0.0511 t_domain_loss: 0.0299 \n","[14/16] class_loss: 0.0680 s_domain_loss: 0.0832 t_domain_loss: 0.0172 \n","[15/16] class_loss: 0.1061 s_domain_loss: 0.2440 t_domain_loss: 0.0079 \n","[16/16] class_loss: 0.0841 s_domain_loss: 0.0390 t_domain_loss: 0.0117 \n","\n","Epoch 0007 / 0010\n","=================\n","[1/16] class_loss: 0.0844 s_domain_loss: 0.0570 t_domain_loss: 0.0194 \n","[2/16] class_loss: 0.0758 s_domain_loss: 0.0771 t_domain_loss: 0.0302 \n","[3/16] class_loss: 0.0623 s_domain_loss: 0.0113 t_domain_loss: 0.0502 \n","[4/16] class_loss: 0.0438 s_domain_loss: 0.0032 t_domain_loss: 0.0561 \n","[5/16] class_loss: 0.0590 s_domain_loss: 0.0047 t_domain_loss: 0.0443 \n","[6/16] class_loss: 0.0487 s_domain_loss: 0.0364 t_domain_loss: 0.0432 \n","[7/16] class_loss: 0.0638 s_domain_loss: 0.0461 t_domain_loss: 0.0272 \n","[8/16] class_loss: 0.0782 s_domain_loss: 0.0765 t_domain_loss: 0.0200 \n","[9/16] class_loss: 0.0414 s_domain_loss: 0.0477 t_domain_loss: 0.0176 \n","[10/16] class_loss: 0.0584 s_domain_loss: 0.0496 t_domain_loss: 0.0634 \n","[11/16] class_loss: 0.0598 s_domain_loss: 0.0167 t_domain_loss: 0.0268 \n","[12/16] class_loss: 0.0666 s_domain_loss: 0.0273 t_domain_loss: 0.0148 \n","[13/16] class_loss: 0.0378 s_domain_loss: 0.0343 t_domain_loss: 0.0147 \n","[14/16] class_loss: 0.0310 s_domain_loss: 0.1497 t_domain_loss: 0.0165 \n","[15/16] class_loss: 0.0526 s_domain_loss: 0.0109 t_domain_loss: 0.0245 \n","[16/16] class_loss: 0.0402 s_domain_loss: 0.0064 t_domain_loss: 0.0348 \n","\n","Epoch 0008 / 0010\n","=================\n","[1/16] class_loss: 0.0395 s_domain_loss: 0.0086 t_domain_loss: 0.0593 \n","[2/16] class_loss: 0.0336 s_domain_loss: 0.0016 t_domain_loss: 0.0439 \n","[3/16] class_loss: 0.0418 s_domain_loss: 0.0057 t_domain_loss: 0.0275 \n","[4/16] class_loss: 0.0642 s_domain_loss: 0.0007 t_domain_loss: 0.0188 \n","[5/16] class_loss: 0.0338 s_domain_loss: 0.0235 t_domain_loss: 0.0116 \n","[6/16] class_loss: 0.0345 s_domain_loss: 0.1349 t_domain_loss: 0.0071 \n","[7/16] class_loss: 0.0297 s_domain_loss: 0.0420 t_domain_loss: 0.0090 \n","[8/16] class_loss: 0.0327 s_domain_loss: 0.0186 t_domain_loss: 0.0109 \n","[9/16] class_loss: 0.0371 s_domain_loss: 0.0124 t_domain_loss: 0.0128 \n","[10/16] class_loss: 0.0471 s_domain_loss: 0.1469 t_domain_loss: 0.0231 \n","[11/16] class_loss: 0.0263 s_domain_loss: 0.0017 t_domain_loss: 0.0345 \n","[12/16] class_loss: 0.0263 s_domain_loss: 0.0009 t_domain_loss: 0.0484 \n","[13/16] class_loss: 0.0616 s_domain_loss: 0.0020 t_domain_loss: 0.0404 \n","[14/16] class_loss: 0.0225 s_domain_loss: 0.0020 t_domain_loss: 0.0339 \n","[15/16] class_loss: 0.0285 s_domain_loss: 0.1304 t_domain_loss: 0.0262 \n","[16/16] class_loss: 0.0191 s_domain_loss: 0.0055 t_domain_loss: 0.0317 \n","\n","Epoch 0009 / 0010\n","=================\n","[1/16] class_loss: 0.0204 s_domain_loss: 0.0074 t_domain_loss: 0.0255 \n","[2/16] class_loss: 0.0483 s_domain_loss: 0.0029 t_domain_loss: 0.0220 \n","[3/16] class_loss: 0.0395 s_domain_loss: 0.0020 t_domain_loss: 0.0151 \n","[4/16] class_loss: 0.0317 s_domain_loss: 0.0228 t_domain_loss: 0.0120 \n","[5/16] class_loss: 0.0097 s_domain_loss: 0.0813 t_domain_loss: 0.0080 \n","[6/16] class_loss: 0.0253 s_domain_loss: 0.0063 t_domain_loss: 0.0073 \n","[7/16] class_loss: 0.0150 s_domain_loss: 0.0042 t_domain_loss: 0.0074 \n","[8/16] class_loss: 0.0624 s_domain_loss: 0.0018 t_domain_loss: 0.0091 \n","[9/16] class_loss: 0.0986 s_domain_loss: 0.0247 t_domain_loss: 0.0072 \n","[10/16] class_loss: 0.0448 s_domain_loss: 0.0078 t_domain_loss: 0.0118 \n","[11/16] class_loss: 0.0199 s_domain_loss: 0.0030 t_domain_loss: 0.0110 \n","[12/16] class_loss: 0.0184 s_domain_loss: 0.0012 t_domain_loss: 0.0058 \n","[13/16] class_loss: 0.0209 s_domain_loss: 0.0016 t_domain_loss: 0.0051 \n","[14/16] class_loss: 0.0400 s_domain_loss: 0.6763 t_domain_loss: 0.0041 \n","[15/16] class_loss: 0.1213 s_domain_loss: 0.1119 t_domain_loss: 0.0366 \n","[16/16] class_loss: 0.2823 s_domain_loss: 0.0769 t_domain_loss: 0.2261 \n","\n","Epoch 0010 / 0010\n","=================\n","[1/16] class_loss: 0.0410 s_domain_loss: 0.0417 t_domain_loss: 0.4478 \n","[2/16] class_loss: 0.0526 s_domain_loss: 0.0473 t_domain_loss: 0.1564 \n","[3/16] class_loss: 0.0643 s_domain_loss: 0.0058 t_domain_loss: 0.0289 \n","[4/16] class_loss: 0.2149 s_domain_loss: 0.2264 t_domain_loss: 0.0054 \n","[5/16] class_loss: 0.1944 s_domain_loss: 0.0168 t_domain_loss: 0.0026 \n","[6/16] class_loss: 0.1864 s_domain_loss: 0.0287 t_domain_loss: 0.0015 \n","[7/16] class_loss: 0.1368 s_domain_loss: 0.0641 t_domain_loss: 0.0008 \n","[8/16] class_loss: 0.1190 s_domain_loss: 0.4008 t_domain_loss: 0.0009 \n","[9/16] class_loss: 0.1102 s_domain_loss: 0.1324 t_domain_loss: 0.0022 \n","[10/16] class_loss: 0.1528 s_domain_loss: 0.0663 t_domain_loss: 0.0241 \n","[11/16] class_loss: 0.0908 s_domain_loss: 0.1100 t_domain_loss: 0.0470 \n","[12/16] class_loss: 0.0963 s_domain_loss: 0.0004 t_domain_loss: 0.1328 \n","[13/16] class_loss: 0.1088 s_domain_loss: 0.0022 t_domain_loss: 0.1361 \n","[14/16] class_loss: 0.1402 s_domain_loss: 0.0007 t_domain_loss: 0.1220 \n","[15/16] class_loss: 0.1000 s_domain_loss: 0.0133 t_domain_loss: 0.0478 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[16/16] class_loss: 0.0901 s_domain_loss: 0.0670 t_domain_loss: 0.0238 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:18<00:00,  1.14s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.5185546875\n","hyperprameters are: LR=0.005 and NUM_EPOCHS = 20\n","\n","Epoch 0001 / 0020\n","=================\n","[1/16] class_loss: 2.3361 s_domain_loss: 0.7932 t_domain_loss: 0.6510 \n","[2/16] class_loss: 1.3363 s_domain_loss: 0.5717 t_domain_loss: 0.8776 \n","[3/16] class_loss: 1.0295 s_domain_loss: 0.8380 t_domain_loss: 0.5946 \n","[4/16] class_loss: 0.6195 s_domain_loss: 0.6897 t_domain_loss: 0.7020 \n","[5/16] class_loss: 0.4519 s_domain_loss: 0.5807 t_domain_loss: 0.8266 \n","[6/16] class_loss: 0.3280 s_domain_loss: 0.8501 t_domain_loss: 0.5565 \n","[7/16] class_loss: 0.2608 s_domain_loss: 0.5442 t_domain_loss: 0.8531 \n","[8/16] class_loss: 0.2858 s_domain_loss: 0.7390 t_domain_loss: 0.6383 \n","[9/16] class_loss: 0.2469 s_domain_loss: 0.7364 t_domain_loss: 0.6259 \n","[10/16] class_loss: 0.1717 s_domain_loss: 0.5556 t_domain_loss: 0.8028 \n","[11/16] class_loss: 0.2004 s_domain_loss: 0.7581 t_domain_loss: 0.5958 \n","[12/16] class_loss: 0.2213 s_domain_loss: 0.6592 t_domain_loss: 0.6643 \n","[13/16] class_loss: 0.1605 s_domain_loss: 0.6079 t_domain_loss: 0.7178 \n","[14/16] class_loss: 0.2248 s_domain_loss: 0.7208 t_domain_loss: 0.5851 \n","[15/16] class_loss: 0.1834 s_domain_loss: 0.5995 t_domain_loss: 0.6944 \n","[16/16] class_loss: 0.1256 s_domain_loss: 0.6499 t_domain_loss: 0.6394 \n","\n","Epoch 0002 / 0020\n","=================\n","[1/16] class_loss: 0.0939 s_domain_loss: 0.6410 t_domain_loss: 0.6165 \n","[2/16] class_loss: 0.1242 s_domain_loss: 0.5912 t_domain_loss: 0.6325 \n","[3/16] class_loss: 0.1164 s_domain_loss: 0.6725 t_domain_loss: 0.5927 \n","[4/16] class_loss: 0.1183 s_domain_loss: 0.5498 t_domain_loss: 0.6507 \n","[5/16] class_loss: 0.1035 s_domain_loss: 0.7036 t_domain_loss: 0.5368 \n","[6/16] class_loss: 0.0769 s_domain_loss: 0.5295 t_domain_loss: 0.6724 \n","[7/16] class_loss: 0.0713 s_domain_loss: 0.6248 t_domain_loss: 0.5516 \n","[8/16] class_loss: 0.0545 s_domain_loss: 0.6010 t_domain_loss: 0.5579 \n","[9/16] class_loss: 0.0748 s_domain_loss: 0.5215 t_domain_loss: 0.6494 \n","[10/16] class_loss: 0.0674 s_domain_loss: 0.6488 t_domain_loss: 0.5261 \n","[11/16] class_loss: 0.0583 s_domain_loss: 0.5049 t_domain_loss: 0.6269 \n","[12/16] class_loss: 0.0590 s_domain_loss: 0.6145 t_domain_loss: 0.5240 \n","[13/16] class_loss: 0.0478 s_domain_loss: 0.5510 t_domain_loss: 0.5563 \n","[14/16] class_loss: 0.0620 s_domain_loss: 0.6200 t_domain_loss: 0.5246 \n","[15/16] class_loss: 0.0328 s_domain_loss: 0.4763 t_domain_loss: 0.5974 \n","[16/16] class_loss: 0.0546 s_domain_loss: 0.6140 t_domain_loss: 0.4325 \n","\n","Epoch 0003 / 0020\n","=================\n","[1/16] class_loss: 0.0498 s_domain_loss: 0.5350 t_domain_loss: 0.5215 \n","[2/16] class_loss: 0.0286 s_domain_loss: 0.4086 t_domain_loss: 0.6140 \n","[3/16] class_loss: 0.0617 s_domain_loss: 0.6679 t_domain_loss: 0.3517 \n","[4/16] class_loss: 0.0289 s_domain_loss: 0.3888 t_domain_loss: 0.5247 \n","[5/16] class_loss: 0.0608 s_domain_loss: 0.5159 t_domain_loss: 0.4817 \n","[6/16] class_loss: 0.0423 s_domain_loss: 0.4372 t_domain_loss: 0.4338 \n","[7/16] class_loss: 0.0556 s_domain_loss: 0.4967 t_domain_loss: 0.3721 \n","[8/16] class_loss: 0.0660 s_domain_loss: 0.3890 t_domain_loss: 0.4420 \n","[9/16] class_loss: 0.0415 s_domain_loss: 0.4156 t_domain_loss: 0.4016 \n","[10/16] class_loss: 0.0398 s_domain_loss: 0.4192 t_domain_loss: 0.3954 \n","[11/16] class_loss: 0.0325 s_domain_loss: 0.3091 t_domain_loss: 0.4000 \n","[12/16] class_loss: 0.0361 s_domain_loss: 0.5639 t_domain_loss: 0.3046 \n","[13/16] class_loss: 0.0475 s_domain_loss: 0.3466 t_domain_loss: 0.4569 \n","[14/16] class_loss: 0.0401 s_domain_loss: 0.2656 t_domain_loss: 0.4327 \n","[15/16] class_loss: 0.0384 s_domain_loss: 0.4618 t_domain_loss: 0.2123 \n","[16/16] class_loss: 0.0256 s_domain_loss: 0.3907 t_domain_loss: 0.2306 \n","\n","Epoch 0004 / 0020\n","=================\n","[1/16] class_loss: 0.0419 s_domain_loss: 0.2004 t_domain_loss: 0.4553 \n","[2/16] class_loss: 0.0606 s_domain_loss: 0.4024 t_domain_loss: 0.2601 \n","[3/16] class_loss: 0.0412 s_domain_loss: 0.3650 t_domain_loss: 0.2194 \n","[4/16] class_loss: 0.0590 s_domain_loss: 0.2912 t_domain_loss: 0.3051 \n","[5/16] class_loss: 0.0465 s_domain_loss: 0.2651 t_domain_loss: 0.3152 \n","[6/16] class_loss: 0.0633 s_domain_loss: 0.2621 t_domain_loss: 0.2075 \n","[7/16] class_loss: 0.0539 s_domain_loss: 0.2923 t_domain_loss: 0.1466 \n","[8/16] class_loss: 0.0538 s_domain_loss: 0.1859 t_domain_loss: 0.1790 \n","[9/16] class_loss: 0.0503 s_domain_loss: 0.3564 t_domain_loss: 0.2054 \n","[10/16] class_loss: 0.0364 s_domain_loss: 0.0954 t_domain_loss: 0.3664 \n","[11/16] class_loss: 0.0443 s_domain_loss: 0.1306 t_domain_loss: 0.1856 \n","[12/16] class_loss: 0.0595 s_domain_loss: 0.3364 t_domain_loss: 0.0758 \n","[13/16] class_loss: 0.0699 s_domain_loss: 0.2095 t_domain_loss: 0.0907 \n","[14/16] class_loss: 0.0486 s_domain_loss: 0.1336 t_domain_loss: 0.1529 \n","[15/16] class_loss: 0.0536 s_domain_loss: 0.0868 t_domain_loss: 0.2197 \n","[16/16] class_loss: 0.0524 s_domain_loss: 0.1294 t_domain_loss: 0.1340 \n","\n","Epoch 0005 / 0020\n","=================\n","[1/16] class_loss: 0.0371 s_domain_loss: 0.1061 t_domain_loss: 0.1084 \n","[2/16] class_loss: 0.0537 s_domain_loss: 0.2900 t_domain_loss: 0.0651 \n","[3/16] class_loss: 0.0735 s_domain_loss: 0.0777 t_domain_loss: 0.1010 \n","[4/16] class_loss: 0.0509 s_domain_loss: 0.0720 t_domain_loss: 0.1191 \n","[5/16] class_loss: 0.0470 s_domain_loss: 0.0969 t_domain_loss: 0.1029 \n","[6/16] class_loss: 0.0580 s_domain_loss: 0.0668 t_domain_loss: 0.0758 \n","[7/16] class_loss: 0.0638 s_domain_loss: 0.0890 t_domain_loss: 0.0547 \n","[8/16] class_loss: 0.0340 s_domain_loss: 0.2242 t_domain_loss: 0.0454 \n","[9/16] class_loss: 0.0433 s_domain_loss: 0.1518 t_domain_loss: 0.0605 \n","[10/16] class_loss: 0.0546 s_domain_loss: 0.0165 t_domain_loss: 0.1191 \n","[11/16] class_loss: 0.0420 s_domain_loss: 0.1905 t_domain_loss: 0.1237 \n","[12/16] class_loss: 0.0451 s_domain_loss: 0.0213 t_domain_loss: 0.1750 \n","[13/16] class_loss: 0.0465 s_domain_loss: 0.0378 t_domain_loss: 0.1012 \n","[14/16] class_loss: 0.0449 s_domain_loss: 0.4396 t_domain_loss: 0.0418 \n","[15/16] class_loss: 0.1455 s_domain_loss: 0.3247 t_domain_loss: 0.0499 \n","[16/16] class_loss: 0.2476 s_domain_loss: 0.9896 t_domain_loss: 0.1258 \n","\n","Epoch 0006 / 0020\n","=================\n","[1/16] class_loss: 0.0912 s_domain_loss: 0.0292 t_domain_loss: 1.2902 \n","[2/16] class_loss: 0.6931 s_domain_loss: 1.5590 t_domain_loss: 0.7109 \n","[3/16] class_loss: 0.1889 s_domain_loss: 0.1412 t_domain_loss: 0.0765 \n","[4/16] class_loss: 0.7199 s_domain_loss: 4.1356 t_domain_loss: 0.0131 \n","[5/16] class_loss: 0.4082 s_domain_loss: 0.9725 t_domain_loss: 0.4913 \n","[6/16] class_loss: 0.5266 s_domain_loss: 0.0258 t_domain_loss: 3.6636 \n","[7/16] class_loss: 0.3682 s_domain_loss: 0.1777 t_domain_loss: 1.9889 \n","[8/16] class_loss: 0.3817 s_domain_loss: 2.2305 t_domain_loss: 0.0221 \n","[9/16] class_loss: 0.5680 s_domain_loss: 3.2054 t_domain_loss: 0.0114 \n","[10/16] class_loss: 0.3904 s_domain_loss: 0.4592 t_domain_loss: 0.1842 \n","[11/16] class_loss: 0.8083 s_domain_loss: 0.1792 t_domain_loss: 1.4197 \n","[12/16] class_loss: 0.5677 s_domain_loss: 0.4021 t_domain_loss: 1.0161 \n","[13/16] class_loss: 0.2391 s_domain_loss: 0.4713 t_domain_loss: 0.1237 \n","[14/16] class_loss: 0.3202 s_domain_loss: 1.2285 t_domain_loss: 0.0298 \n","[15/16] class_loss: 0.2962 s_domain_loss: 0.2505 t_domain_loss: 0.1624 \n","[16/16] class_loss: 0.3047 s_domain_loss: 0.2187 t_domain_loss: 0.6280 \n","\n","Epoch 0007 / 0020\n","=================\n","[1/16] class_loss: 0.3625 s_domain_loss: 0.1517 t_domain_loss: 0.3508 \n","[2/16] class_loss: 0.4428 s_domain_loss: 0.4823 t_domain_loss: 0.0795 \n","[3/16] class_loss: 0.3276 s_domain_loss: 0.3922 t_domain_loss: 0.0420 \n","[4/16] class_loss: 0.2762 s_domain_loss: 0.3588 t_domain_loss: 0.0689 \n","[5/16] class_loss: 0.2526 s_domain_loss: 0.0098 t_domain_loss: 0.1799 \n","[6/16] class_loss: 0.2133 s_domain_loss: 0.0134 t_domain_loss: 0.1594 \n","[7/16] class_loss: 0.2733 s_domain_loss: 0.0306 t_domain_loss: 0.1069 \n","[8/16] class_loss: 0.2302 s_domain_loss: 0.6422 t_domain_loss: 0.0468 \n","[9/16] class_loss: 0.2224 s_domain_loss: 0.0707 t_domain_loss: 0.1040 \n","[10/16] class_loss: 0.2801 s_domain_loss: 0.4985 t_domain_loss: 0.1577 \n","[11/16] class_loss: 0.2355 s_domain_loss: 0.0175 t_domain_loss: 0.2430 \n","[12/16] class_loss: 0.1927 s_domain_loss: 0.0495 t_domain_loss: 0.1966 \n","[13/16] class_loss: 0.1917 s_domain_loss: 0.0821 t_domain_loss: 0.0702 \n","[14/16] class_loss: 0.2855 s_domain_loss: 0.1249 t_domain_loss: 0.0193 \n","[15/16] class_loss: 0.2710 s_domain_loss: 0.4149 t_domain_loss: 0.0068 \n","[16/16] class_loss: 0.2234 s_domain_loss: 0.4615 t_domain_loss: 0.0146 \n","\n","Epoch 0008 / 0020\n","=================\n","[1/16] class_loss: 0.2164 s_domain_loss: 0.1147 t_domain_loss: 0.0543 \n","[2/16] class_loss: 0.2308 s_domain_loss: 0.2452 t_domain_loss: 0.2128 \n","[3/16] class_loss: 0.2206 s_domain_loss: 0.0053 t_domain_loss: 0.4512 \n","[4/16] class_loss: 0.1556 s_domain_loss: 0.0032 t_domain_loss: 0.1917 \n","[5/16] class_loss: 0.1905 s_domain_loss: 0.0412 t_domain_loss: 0.0420 \n","[6/16] class_loss: 0.1606 s_domain_loss: 0.1743 t_domain_loss: 0.0077 \n","[7/16] class_loss: 0.2282 s_domain_loss: 0.0100 t_domain_loss: 0.0029 \n","[8/16] class_loss: 0.2763 s_domain_loss: 0.2197 t_domain_loss: 0.0024 \n","[9/16] class_loss: 0.1743 s_domain_loss: 1.0265 t_domain_loss: 0.0019 \n","[10/16] class_loss: 0.2238 s_domain_loss: 0.2085 t_domain_loss: 0.0530 \n","[11/16] class_loss: 0.4004 s_domain_loss: 0.2205 t_domain_loss: 0.3796 \n","[12/16] class_loss: 0.2340 s_domain_loss: 0.0078 t_domain_loss: 0.8614 \n","[13/16] class_loss: 0.3419 s_domain_loss: 0.0274 t_domain_loss: 0.4823 \n","[14/16] class_loss: 0.3050 s_domain_loss: 0.0436 t_domain_loss: 0.0344 \n","[15/16] class_loss: 0.3126 s_domain_loss: 0.0577 t_domain_loss: 0.0029 \n","[16/16] class_loss: 0.3126 s_domain_loss: 0.1070 t_domain_loss: 0.0010 \n","\n","Epoch 0009 / 0020\n","=================\n","[1/16] class_loss: 0.3183 s_domain_loss: 0.1696 t_domain_loss: 0.0005 \n","[2/16] class_loss: 0.3102 s_domain_loss: 1.2032 t_domain_loss: 0.0003 \n","[3/16] class_loss: 0.3084 s_domain_loss: 1.4269 t_domain_loss: 0.0042 \n","[4/16] class_loss: 0.3484 s_domain_loss: 0.0012 t_domain_loss: 0.0709 \n","[5/16] class_loss: 0.3523 s_domain_loss: 0.0836 t_domain_loss: 0.6219 \n","[6/16] class_loss: 0.3867 s_domain_loss: 0.9085 t_domain_loss: 0.9866 \n","[7/16] class_loss: 0.2545 s_domain_loss: 0.0004 t_domain_loss: 1.1760 \n","[8/16] class_loss: 0.1984 s_domain_loss: 0.0001 t_domain_loss: 0.1280 \n","[9/16] class_loss: 0.2015 s_domain_loss: 1.2648 t_domain_loss: 0.0101 \n","[10/16] class_loss: 0.2803 s_domain_loss: 0.0221 t_domain_loss: 0.0163 \n","[11/16] class_loss: 0.4140 s_domain_loss: 2.3162 t_domain_loss: 0.0065 \n","[12/16] class_loss: 0.3080 s_domain_loss: 0.1147 t_domain_loss: 0.1148 \n","[13/16] class_loss: 0.6025 s_domain_loss: 0.5297 t_domain_loss: 0.6834 \n","[14/16] class_loss: 0.4967 s_domain_loss: 0.0025 t_domain_loss: 1.1426 \n","[15/16] class_loss: 0.4577 s_domain_loss: 0.0393 t_domain_loss: 0.4357 \n","[16/16] class_loss: 0.4589 s_domain_loss: 3.6608 t_domain_loss: 0.0220 \n","\n","Epoch 0010 / 0020\n","=================\n","[1/16] class_loss: 0.5320 s_domain_loss: 0.1038 t_domain_loss: 0.1807 \n","[2/16] class_loss: 1.0230 s_domain_loss: 2.3937 t_domain_loss: 0.6980 \n","[3/16] class_loss: 0.6242 s_domain_loss: 0.2013 t_domain_loss: 0.8644 \n","[4/16] class_loss: 1.0636 s_domain_loss: 0.2236 t_domain_loss: 0.4993 \n","[5/16] class_loss: 1.2346 s_domain_loss: 0.9378 t_domain_loss: 0.1541 \n","[6/16] class_loss: 0.7367 s_domain_loss: 0.6149 t_domain_loss: 0.0895 \n","[7/16] class_loss: 0.5800 s_domain_loss: 0.7071 t_domain_loss: 0.0654 \n","[8/16] class_loss: 0.5743 s_domain_loss: 0.5392 t_domain_loss: 0.0296 \n","[9/16] class_loss: 0.4037 s_domain_loss: 0.2420 t_domain_loss: 0.0238 \n","[10/16] class_loss: 0.3612 s_domain_loss: 0.4177 t_domain_loss: 0.0326 \n","[11/16] class_loss: 0.2902 s_domain_loss: 0.1103 t_domain_loss: 0.0296 \n","[12/16] class_loss: 0.4464 s_domain_loss: 0.0128 t_domain_loss: 0.0344 \n","[13/16] class_loss: 0.3741 s_domain_loss: 0.0223 t_domain_loss: 0.0470 \n","[14/16] class_loss: 0.3316 s_domain_loss: 0.2511 t_domain_loss: 0.0522 \n","[15/16] class_loss: 0.3866 s_domain_loss: 0.0106 t_domain_loss: 0.0972 \n","[16/16] class_loss: 0.4115 s_domain_loss: 0.2501 t_domain_loss: 0.1043 \n","\n","Epoch 0011 / 0020\n","=================\n","[1/16] class_loss: 0.3033 s_domain_loss: 0.0038 t_domain_loss: 0.1453 \n","[2/16] class_loss: 0.2720 s_domain_loss: 0.0051 t_domain_loss: 0.1420 \n","[3/16] class_loss: 0.2296 s_domain_loss: 0.0018 t_domain_loss: 0.1005 \n","[4/16] class_loss: 0.3487 s_domain_loss: 0.0278 t_domain_loss: 0.0269 \n","[5/16] class_loss: 0.2633 s_domain_loss: 0.0114 t_domain_loss: 0.0144 \n","[6/16] class_loss: 0.2981 s_domain_loss: 0.0066 t_domain_loss: 0.0062 \n","[7/16] class_loss: 0.2885 s_domain_loss: 0.0840 t_domain_loss: 0.0036 \n","[8/16] class_loss: 0.1927 s_domain_loss: 0.0400 t_domain_loss: 0.0018 \n","[9/16] class_loss: 0.2694 s_domain_loss: 0.0607 t_domain_loss: 0.0022 \n","[10/16] class_loss: 0.2839 s_domain_loss: 0.3168 t_domain_loss: 0.0097 \n","[11/16] class_loss: 0.2411 s_domain_loss: 0.9436 t_domain_loss: 0.0059 \n","[12/16] class_loss: 0.1977 s_domain_loss: 0.0025 t_domain_loss: 0.0548 \n","[13/16] class_loss: 0.2577 s_domain_loss: 0.0000 t_domain_loss: 0.2111 \n","[14/16] class_loss: 0.2883 s_domain_loss: 0.6194 t_domain_loss: 0.3404 \n","[15/16] class_loss: 0.3002 s_domain_loss: 0.0005 t_domain_loss: 0.6863 \n","[16/16] class_loss: 0.2291 s_domain_loss: 0.0003 t_domain_loss: 0.2457 \n","\n","Epoch 0012 / 0020\n","=================\n","[1/16] class_loss: 0.2267 s_domain_loss: 0.0011 t_domain_loss: 0.0823 \n","[2/16] class_loss: 0.2567 s_domain_loss: 0.0099 t_domain_loss: 0.0098 \n","[3/16] class_loss: 0.2736 s_domain_loss: 0.2095 t_domain_loss: 0.0036 \n","[4/16] class_loss: 0.1611 s_domain_loss: 0.0026 t_domain_loss: 0.0090 \n","[5/16] class_loss: 0.2036 s_domain_loss: 0.0396 t_domain_loss: 0.0131 \n","[6/16] class_loss: 0.2695 s_domain_loss: 0.0862 t_domain_loss: 0.0018 \n","[7/16] class_loss: 0.2618 s_domain_loss: 1.0621 t_domain_loss: 0.0013 \n","[8/16] class_loss: 0.2628 s_domain_loss: 0.0262 t_domain_loss: 0.0070 \n","[9/16] class_loss: 0.2879 s_domain_loss: 0.0353 t_domain_loss: 0.0276 \n","[10/16] class_loss: 0.2844 s_domain_loss: 0.0135 t_domain_loss: 0.1065 \n","[11/16] class_loss: 0.3242 s_domain_loss: 0.3048 t_domain_loss: 0.0771 \n","[12/16] class_loss: 0.2342 s_domain_loss: 0.0006 t_domain_loss: 0.4160 \n","[13/16] class_loss: 0.2723 s_domain_loss: 0.0020 t_domain_loss: 0.1721 \n","[14/16] class_loss: 0.2415 s_domain_loss: 0.0027 t_domain_loss: 0.0738 \n","[15/16] class_loss: 0.2576 s_domain_loss: 0.0000 t_domain_loss: 0.0705 \n","[16/16] class_loss: 0.3405 s_domain_loss: 0.1134 t_domain_loss: 0.0122 \n","\n","Epoch 0013 / 0020\n","=================\n","[1/16] class_loss: 0.3332 s_domain_loss: 0.1107 t_domain_loss: 0.0187 \n","[2/16] class_loss: 0.2112 s_domain_loss: 0.1132 t_domain_loss: 0.0053 \n","[3/16] class_loss: 0.3085 s_domain_loss: 5.1231 t_domain_loss: 0.0041 \n","[4/16] class_loss: 2.3414 s_domain_loss: 4.9447 t_domain_loss: 0.2296 \n","[5/16] class_loss: 3.6875 s_domain_loss: 1.3456 t_domain_loss: 11.9795 \n","[6/16] class_loss: 1.7626 s_domain_loss: 0.0515 t_domain_loss: 7.2030 \n","[7/16] class_loss: 3.1327 s_domain_loss: 0.1381 t_domain_loss: 4.3250 \n","[8/16] class_loss: 7.8053 s_domain_loss: 4.2277 t_domain_loss: 0.1181 \n","[9/16] class_loss: 2.8750 s_domain_loss: 5.7848 t_domain_loss: 0.0419 \n","[10/16] class_loss: 5.0228 s_domain_loss: 7.0352 t_domain_loss: 4.3162 \n","[11/16] class_loss: 5.0031 s_domain_loss: 0.3592 t_domain_loss: 3.2604 \n","[12/16] class_loss: 2.1640 s_domain_loss: 0.3331 t_domain_loss: 3.6584 \n","[13/16] class_loss: 3.8207 s_domain_loss: 1.5376 t_domain_loss: 1.0020 \n","[14/16] class_loss: 9.3352 s_domain_loss: 3.7631 t_domain_loss: 0.1715 \n","[15/16] class_loss: 2.4267 s_domain_loss: 1.9433 t_domain_loss: 1.2929 \n","[16/16] class_loss: 2.0409 s_domain_loss: 0.0487 t_domain_loss: 0.9589 \n","\n","Epoch 0014 / 0020\n","=================\n","[1/16] class_loss: 1.9815 s_domain_loss: 0.0012 t_domain_loss: 7.4204 \n","[2/16] class_loss: 2.1362 s_domain_loss: 0.0025 t_domain_loss: 7.6740 \n","[3/16] class_loss: 2.0652 s_domain_loss: 0.0020 t_domain_loss: 10.0319 \n","[4/16] class_loss: 666.6803 s_domain_loss: 0.4003 t_domain_loss: 2.1100 \n","[5/16] class_loss: 609.8730 s_domain_loss: 10.9982 t_domain_loss: 0.0662 \n","[6/16] class_loss: 89177152.0000 s_domain_loss: 15.1744 t_domain_loss: 0.0053 \n","[7/16] class_loss: 11826009763221927785752791351296.0000 s_domain_loss: 3.6878 t_domain_loss: 0.0106 \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0015 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0016 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0017 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0018 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0019 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0020 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:18<00:00,  1.13s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.376953125\n","hyperprameters are: LR=0.005 and NUM_EPOCHS = 30\n","\n","Epoch 0001 / 0030\n","=================\n","[1/16] class_loss: 2.2275 s_domain_loss: 0.8284 t_domain_loss: 0.6149 \n","[2/16] class_loss: 1.3970 s_domain_loss: 0.4769 t_domain_loss: 1.0114 \n","[3/16] class_loss: 0.8644 s_domain_loss: 0.9307 t_domain_loss: 0.5303 \n","[4/16] class_loss: 0.6856 s_domain_loss: 0.6586 t_domain_loss: 0.7449 \n","[5/16] class_loss: 0.4285 s_domain_loss: 0.5627 t_domain_loss: 0.8593 \n","[6/16] class_loss: 0.3424 s_domain_loss: 0.9392 t_domain_loss: 0.5017 \n","[7/16] class_loss: 0.2655 s_domain_loss: 0.5011 t_domain_loss: 0.9149 \n","[8/16] class_loss: 0.2714 s_domain_loss: 0.7390 t_domain_loss: 0.6308 \n","[9/16] class_loss: 0.2181 s_domain_loss: 0.7565 t_domain_loss: 0.6082 \n","[10/16] class_loss: 0.2585 s_domain_loss: 0.5115 t_domain_loss: 0.8672 \n","[11/16] class_loss: 0.1868 s_domain_loss: 0.8301 t_domain_loss: 0.5379 \n","[12/16] class_loss: 0.2046 s_domain_loss: 0.6435 t_domain_loss: 0.6920 \n","[13/16] class_loss: 0.1687 s_domain_loss: 0.5523 t_domain_loss: 0.7676 \n","[14/16] class_loss: 0.1109 s_domain_loss: 0.8172 t_domain_loss: 0.5096 \n","[15/16] class_loss: 0.1337 s_domain_loss: 0.5443 t_domain_loss: 0.7738 \n","[16/16] class_loss: 0.1050 s_domain_loss: 0.6059 t_domain_loss: 0.6532 \n","\n","Epoch 0002 / 0030\n","=================\n","[1/16] class_loss: 0.1337 s_domain_loss: 0.7662 t_domain_loss: 0.5057 \n","[2/16] class_loss: 0.1191 s_domain_loss: 0.4869 t_domain_loss: 0.8006 \n","[3/16] class_loss: 0.1004 s_domain_loss: 0.6615 t_domain_loss: 0.5549 \n","[4/16] class_loss: 0.1211 s_domain_loss: 0.7167 t_domain_loss: 0.5079 \n","[5/16] class_loss: 0.1547 s_domain_loss: 0.4563 t_domain_loss: 0.7600 \n","[6/16] class_loss: 0.0601 s_domain_loss: 0.7741 t_domain_loss: 0.4374 \n","[7/16] class_loss: 0.1162 s_domain_loss: 0.5377 t_domain_loss: 0.6440 \n","[8/16] class_loss: 0.0827 s_domain_loss: 0.4748 t_domain_loss: 0.6654 \n","[9/16] class_loss: 0.0508 s_domain_loss: 0.7066 t_domain_loss: 0.4162 \n","[10/16] class_loss: 0.0823 s_domain_loss: 0.5203 t_domain_loss: 0.6104 \n","[11/16] class_loss: 0.0370 s_domain_loss: 0.3868 t_domain_loss: 0.7066 \n","[12/16] class_loss: 0.0930 s_domain_loss: 1.0015 t_domain_loss: 0.3106 \n","[13/16] class_loss: 0.0519 s_domain_loss: 0.3167 t_domain_loss: 0.8143 \n","[14/16] class_loss: 0.0665 s_domain_loss: 0.5301 t_domain_loss: 0.4958 \n","[15/16] class_loss: 0.0597 s_domain_loss: 0.7554 t_domain_loss: 0.3324 \n","[16/16] class_loss: 0.0361 s_domain_loss: 0.3393 t_domain_loss: 0.7223 \n","\n","Epoch 0003 / 0030\n","=================\n","[1/16] class_loss: 0.0950 s_domain_loss: 0.5275 t_domain_loss: 0.4219 \n","[2/16] class_loss: 0.0464 s_domain_loss: 0.6694 t_domain_loss: 0.3148 \n","[3/16] class_loss: 0.0612 s_domain_loss: 0.3475 t_domain_loss: 0.6696 \n","[4/16] class_loss: 0.0518 s_domain_loss: 0.4127 t_domain_loss: 0.4825 \n","[5/16] class_loss: 0.0920 s_domain_loss: 0.7245 t_domain_loss: 0.2351 \n","[6/16] class_loss: 0.0539 s_domain_loss: 0.3438 t_domain_loss: 0.5175 \n","[7/16] class_loss: 0.0549 s_domain_loss: 0.2676 t_domain_loss: 0.5299 \n","[8/16] class_loss: 0.0533 s_domain_loss: 0.7497 t_domain_loss: 0.2018 \n","[9/16] class_loss: 0.0528 s_domain_loss: 0.3445 t_domain_loss: 0.4289 \n","[10/16] class_loss: 0.0574 s_domain_loss: 0.1767 t_domain_loss: 0.5913 \n","[11/16] class_loss: 0.0720 s_domain_loss: 0.6198 t_domain_loss: 0.1910 \n","[12/16] class_loss: 0.0837 s_domain_loss: 0.3916 t_domain_loss: 0.2997 \n","[13/16] class_loss: 0.1007 s_domain_loss: 0.2608 t_domain_loss: 0.5015 \n","[14/16] class_loss: 0.0308 s_domain_loss: 0.3486 t_domain_loss: 0.3011 \n","[15/16] class_loss: 0.0713 s_domain_loss: 0.6238 t_domain_loss: 0.1730 \n","[16/16] class_loss: 0.0746 s_domain_loss: 0.2463 t_domain_loss: 0.3869 \n","\n","Epoch 0004 / 0030\n","=================\n","[1/16] class_loss: 0.0455 s_domain_loss: 0.1497 t_domain_loss: 0.5041 \n","[2/16] class_loss: 0.0529 s_domain_loss: 0.4202 t_domain_loss: 0.1525 \n","[3/16] class_loss: 0.0574 s_domain_loss: 0.5905 t_domain_loss: 0.1247 \n","[4/16] class_loss: 0.0633 s_domain_loss: 0.0876 t_domain_loss: 0.4884 \n","[5/16] class_loss: 0.0787 s_domain_loss: 0.1857 t_domain_loss: 0.3084 \n","[6/16] class_loss: 0.0739 s_domain_loss: 0.5136 t_domain_loss: 0.0920 \n","[7/16] class_loss: 0.0673 s_domain_loss: 0.2178 t_domain_loss: 0.1425 \n","[8/16] class_loss: 0.0562 s_domain_loss: 0.1673 t_domain_loss: 0.2506 \n","[9/16] class_loss: 0.0666 s_domain_loss: 0.0722 t_domain_loss: 0.2393 \n","[10/16] class_loss: 0.0600 s_domain_loss: 0.1608 t_domain_loss: 0.1051 \n","[11/16] class_loss: 0.0628 s_domain_loss: 0.2190 t_domain_loss: 0.0568 \n","[12/16] class_loss: 0.0768 s_domain_loss: 0.3651 t_domain_loss: 0.0689 \n","[13/16] class_loss: 0.0894 s_domain_loss: 0.0854 t_domain_loss: 0.2415 \n","[14/16] class_loss: 0.0416 s_domain_loss: 0.0582 t_domain_loss: 0.3011 \n","[15/16] class_loss: 0.0620 s_domain_loss: 0.1539 t_domain_loss: 0.1404 \n","[16/16] class_loss: 0.0827 s_domain_loss: 0.1511 t_domain_loss: 0.0466 \n","\n","Epoch 0005 / 0030\n","=================\n","[1/16] class_loss: 0.0626 s_domain_loss: 0.1975 t_domain_loss: 0.0366 \n","[2/16] class_loss: 0.0528 s_domain_loss: 0.1730 t_domain_loss: 0.0538 \n","[3/16] class_loss: 0.0648 s_domain_loss: 0.1494 t_domain_loss: 0.1196 \n","[4/16] class_loss: 0.0754 s_domain_loss: 0.0292 t_domain_loss: 0.2167 \n","[5/16] class_loss: 0.0836 s_domain_loss: 0.0506 t_domain_loss: 0.1789 \n","[6/16] class_loss: 0.1253 s_domain_loss: 0.0535 t_domain_loss: 0.0666 \n","[7/16] class_loss: 0.0662 s_domain_loss: 0.1227 t_domain_loss: 0.0318 \n","[8/16] class_loss: 0.0412 s_domain_loss: 0.1979 t_domain_loss: 0.0161 \n","[9/16] class_loss: 0.0814 s_domain_loss: 0.2163 t_domain_loss: 0.0181 \n","[10/16] class_loss: 0.0811 s_domain_loss: 0.0299 t_domain_loss: 0.0551 \n","[11/16] class_loss: 0.0401 s_domain_loss: 0.0219 t_domain_loss: 0.1073 \n","[12/16] class_loss: 0.0573 s_domain_loss: 0.0383 t_domain_loss: 0.1402 \n","[13/16] class_loss: 0.0353 s_domain_loss: 0.0948 t_domain_loss: 0.0840 \n","[14/16] class_loss: 0.0696 s_domain_loss: 0.0359 t_domain_loss: 0.0437 \n","[15/16] class_loss: 0.0785 s_domain_loss: 0.2403 t_domain_loss: 0.0258 \n","[16/16] class_loss: 0.0284 s_domain_loss: 0.0464 t_domain_loss: 0.0307 \n","\n","Epoch 0006 / 0030\n","=================\n","[1/16] class_loss: 0.0377 s_domain_loss: 0.0690 t_domain_loss: 0.0508 \n","[2/16] class_loss: 0.0854 s_domain_loss: 0.1242 t_domain_loss: 0.0758 \n","[3/16] class_loss: 0.0594 s_domain_loss: 0.0177 t_domain_loss: 0.0906 \n","[4/16] class_loss: 0.0553 s_domain_loss: 0.0407 t_domain_loss: 0.0639 \n","[5/16] class_loss: 0.0228 s_domain_loss: 0.0506 t_domain_loss: 0.0386 \n","[6/16] class_loss: 0.0590 s_domain_loss: 0.1099 t_domain_loss: 0.0245 \n","[7/16] class_loss: 0.0270 s_domain_loss: 0.0394 t_domain_loss: 0.0234 \n","[8/16] class_loss: 0.0564 s_domain_loss: 0.0587 t_domain_loss: 0.0272 \n","[9/16] class_loss: 0.0412 s_domain_loss: 0.0112 t_domain_loss: 0.0323 \n","[10/16] class_loss: 0.0404 s_domain_loss: 0.0880 t_domain_loss: 0.0404 \n","[11/16] class_loss: 0.0667 s_domain_loss: 0.0885 t_domain_loss: 0.0405 \n","[12/16] class_loss: 0.0374 s_domain_loss: 0.0212 t_domain_loss: 0.0660 \n","[13/16] class_loss: 0.0362 s_domain_loss: 0.0172 t_domain_loss: 0.0729 \n","[14/16] class_loss: 0.0553 s_domain_loss: 0.0463 t_domain_loss: 0.0549 \n","[15/16] class_loss: 0.0220 s_domain_loss: 0.0141 t_domain_loss: 0.0454 \n","[16/16] class_loss: 0.0433 s_domain_loss: 0.1223 t_domain_loss: 0.0195 \n","\n","Epoch 0007 / 0030\n","=================\n","[1/16] class_loss: 0.0283 s_domain_loss: 0.0081 t_domain_loss: 0.0239 \n","[2/16] class_loss: 0.0448 s_domain_loss: 0.0380 t_domain_loss: 0.0218 \n","[3/16] class_loss: 0.0781 s_domain_loss: 0.0297 t_domain_loss: 0.0202 \n","[4/16] class_loss: 0.0263 s_domain_loss: 0.0359 t_domain_loss: 0.0172 \n","[5/16] class_loss: 0.0124 s_domain_loss: 0.0622 t_domain_loss: 0.0186 \n","[6/16] class_loss: 0.0264 s_domain_loss: 0.2519 t_domain_loss: 0.0237 \n","[7/16] class_loss: 0.1088 s_domain_loss: 0.1798 t_domain_loss: 0.0506 \n","[8/16] class_loss: 0.0589 s_domain_loss: 0.0610 t_domain_loss: 0.1397 \n","[9/16] class_loss: 0.0593 s_domain_loss: 0.0091 t_domain_loss: 0.1853 \n","[10/16] class_loss: 0.0348 s_domain_loss: 0.0019 t_domain_loss: 0.1048 \n","[11/16] class_loss: 0.0339 s_domain_loss: 0.0215 t_domain_loss: 0.0331 \n","[12/16] class_loss: 0.0739 s_domain_loss: 0.0710 t_domain_loss: 0.0120 \n","[13/16] class_loss: 0.0709 s_domain_loss: 0.1306 t_domain_loss: 0.0060 \n","[14/16] class_loss: 0.0204 s_domain_loss: 0.2415 t_domain_loss: 0.0057 \n","[15/16] class_loss: 0.0338 s_domain_loss: 0.0205 t_domain_loss: 0.0134 \n","[16/16] class_loss: 0.0484 s_domain_loss: 0.0583 t_domain_loss: 0.0232 \n","\n","Epoch 0008 / 0030\n","=================\n","[1/16] class_loss: 0.0882 s_domain_loss: 0.0057 t_domain_loss: 0.0577 \n","[2/16] class_loss: 0.0436 s_domain_loss: 0.0655 t_domain_loss: 0.0972 \n","[3/16] class_loss: 0.0519 s_domain_loss: 0.0086 t_domain_loss: 0.0821 \n","[4/16] class_loss: 0.0258 s_domain_loss: 0.0182 t_domain_loss: 0.0378 \n","[5/16] class_loss: 0.0359 s_domain_loss: 0.0428 t_domain_loss: 0.0228 \n","[6/16] class_loss: 0.0323 s_domain_loss: 0.0058 t_domain_loss: 0.0137 \n","[7/16] class_loss: 0.0331 s_domain_loss: 0.0238 t_domain_loss: 0.0085 \n","[8/16] class_loss: 0.0368 s_domain_loss: 0.0054 t_domain_loss: 0.0065 \n","[9/16] class_loss: 0.0214 s_domain_loss: 0.0175 t_domain_loss: 0.0044 \n","[10/16] class_loss: 0.0350 s_domain_loss: 0.0235 t_domain_loss: 0.0040 \n","[11/16] class_loss: 0.0408 s_domain_loss: 0.0486 t_domain_loss: 0.0030 \n","[12/16] class_loss: 0.0344 s_domain_loss: 0.0208 t_domain_loss: 0.0043 \n","[13/16] class_loss: 0.0261 s_domain_loss: 0.0475 t_domain_loss: 0.0048 \n","[14/16] class_loss: 0.0197 s_domain_loss: 0.0122 t_domain_loss: 0.0064 \n","[15/16] class_loss: 0.0217 s_domain_loss: 0.0265 t_domain_loss: 0.0092 \n","[16/16] class_loss: 0.0269 s_domain_loss: 0.0137 t_domain_loss: 0.0108 \n","\n","Epoch 0009 / 0030\n","=================\n","[1/16] class_loss: 0.0238 s_domain_loss: 0.0823 t_domain_loss: 0.0252 \n","[2/16] class_loss: 0.0158 s_domain_loss: 0.0028 t_domain_loss: 0.0343 \n","[3/16] class_loss: 0.0140 s_domain_loss: 0.0052 t_domain_loss: 0.0493 \n","[4/16] class_loss: 0.0139 s_domain_loss: 0.0036 t_domain_loss: 0.0326 \n","[5/16] class_loss: 0.0399 s_domain_loss: 0.0053 t_domain_loss: 0.0274 \n","[6/16] class_loss: 0.0447 s_domain_loss: 0.0419 t_domain_loss: 0.0180 \n","[7/16] class_loss: 0.0173 s_domain_loss: 0.0109 t_domain_loss: 0.0148 \n","[8/16] class_loss: 0.0098 s_domain_loss: 0.0044 t_domain_loss: 0.0128 \n","[9/16] class_loss: 0.0168 s_domain_loss: 0.0021 t_domain_loss: 0.0106 \n","[10/16] class_loss: 0.0266 s_domain_loss: 0.0505 t_domain_loss: 0.0086 \n","[11/16] class_loss: 0.0142 s_domain_loss: 0.0024 t_domain_loss: 0.0074 \n","[12/16] class_loss: 0.0137 s_domain_loss: 0.0058 t_domain_loss: 0.0078 \n","[13/16] class_loss: 0.0134 s_domain_loss: 0.0156 t_domain_loss: 0.0072 \n","[14/16] class_loss: 0.0170 s_domain_loss: 0.0031 t_domain_loss: 0.0068 \n","[15/16] class_loss: 0.0153 s_domain_loss: 0.0023 t_domain_loss: 0.0070 \n","[16/16] class_loss: 0.0215 s_domain_loss: 0.0029 t_domain_loss: 0.0050 \n","\n","Epoch 0010 / 0030\n","=================\n","[1/16] class_loss: 0.0197 s_domain_loss: 0.0033 t_domain_loss: 0.0055 \n","[2/16] class_loss: 0.0065 s_domain_loss: 0.0231 t_domain_loss: 0.0055 \n","[3/16] class_loss: 0.0054 s_domain_loss: 0.0049 t_domain_loss: 0.0056 \n","[4/16] class_loss: 0.0093 s_domain_loss: 0.0064 t_domain_loss: 0.0048 \n","[5/16] class_loss: 0.0077 s_domain_loss: 0.0047 t_domain_loss: 0.0050 \n","[6/16] class_loss: 0.0084 s_domain_loss: 0.0051 t_domain_loss: 0.0047 \n","[7/16] class_loss: 0.0057 s_domain_loss: 0.0112 t_domain_loss: 0.0046 \n","[8/16] class_loss: 0.0069 s_domain_loss: 0.0214 t_domain_loss: 0.0057 \n","[9/16] class_loss: 0.0069 s_domain_loss: 0.0021 t_domain_loss: 0.0057 \n","[10/16] class_loss: 0.0038 s_domain_loss: 0.0160 t_domain_loss: 0.0063 \n","[11/16] class_loss: 0.0106 s_domain_loss: 0.0060 t_domain_loss: 0.0054 \n","[12/16] class_loss: 0.0035 s_domain_loss: 0.0042 t_domain_loss: 0.0060 \n","[13/16] class_loss: 0.0040 s_domain_loss: 0.0108 t_domain_loss: 0.0065 \n","[14/16] class_loss: 0.0049 s_domain_loss: 0.0118 t_domain_loss: 0.0067 \n","[15/16] class_loss: 0.0030 s_domain_loss: 0.0056 t_domain_loss: 0.0081 \n","[16/16] class_loss: 0.0077 s_domain_loss: 0.0011 t_domain_loss: 0.0058 \n","\n","Epoch 0011 / 0030\n","=================\n","[1/16] class_loss: 0.0103 s_domain_loss: 0.0009 t_domain_loss: 0.0081 \n","[2/16] class_loss: 0.0084 s_domain_loss: 0.0093 t_domain_loss: 0.0073 \n","[3/16] class_loss: 0.0047 s_domain_loss: 0.0013 t_domain_loss: 0.0069 \n","[4/16] class_loss: 0.0041 s_domain_loss: 0.0056 t_domain_loss: 0.0063 \n","[5/16] class_loss: 0.0031 s_domain_loss: 0.0042 t_domain_loss: 0.0053 \n","[6/16] class_loss: 0.0091 s_domain_loss: 0.0008 t_domain_loss: 0.0054 \n","[7/16] class_loss: 0.0023 s_domain_loss: 0.0035 t_domain_loss: 0.0046 \n","[8/16] class_loss: 0.0063 s_domain_loss: 0.0039 t_domain_loss: 0.0046 \n","[9/16] class_loss: 0.0043 s_domain_loss: 0.0016 t_domain_loss: 0.0040 \n","[10/16] class_loss: 0.0041 s_domain_loss: 0.0034 t_domain_loss: 0.0040 \n","[11/16] class_loss: 0.0022 s_domain_loss: 0.0016 t_domain_loss: 0.0032 \n","[12/16] class_loss: 0.0029 s_domain_loss: 0.0183 t_domain_loss: 0.0033 \n","[13/16] class_loss: 0.0026 s_domain_loss: 0.0285 t_domain_loss: 0.0031 \n","[14/16] class_loss: 0.0076 s_domain_loss: 0.0007 t_domain_loss: 0.0034 \n","[15/16] class_loss: 0.0023 s_domain_loss: 0.0093 t_domain_loss: 0.0041 \n","[16/16] class_loss: 0.0023 s_domain_loss: 0.0016 t_domain_loss: 0.0033 \n","\n","Epoch 0012 / 0030\n","=================\n","[1/16] class_loss: 0.0025 s_domain_loss: 0.0012 t_domain_loss: 0.0045 \n","[2/16] class_loss: 0.0032 s_domain_loss: 0.0023 t_domain_loss: 0.0047 \n","[3/16] class_loss: 0.0019 s_domain_loss: 0.0044 t_domain_loss: 0.0046 \n","[4/16] class_loss: 0.0026 s_domain_loss: 0.0006 t_domain_loss: 0.0047 \n","[5/16] class_loss: 0.0012 s_domain_loss: 0.0030 t_domain_loss: 0.0045 \n","[6/16] class_loss: 0.0065 s_domain_loss: 0.0022 t_domain_loss: 0.0048 \n","[7/16] class_loss: 0.0014 s_domain_loss: 0.0064 t_domain_loss: 0.0044 \n","[8/16] class_loss: 0.0029 s_domain_loss: 0.0099 t_domain_loss: 0.0045 \n","[9/16] class_loss: 0.0057 s_domain_loss: 0.0002 t_domain_loss: 0.0044 \n","[10/16] class_loss: 0.0035 s_domain_loss: 0.0009 t_domain_loss: 0.0047 \n","[11/16] class_loss: 0.0054 s_domain_loss: 0.0071 t_domain_loss: 0.0040 \n","[12/16] class_loss: 0.0024 s_domain_loss: 0.0038 t_domain_loss: 0.0044 \n","[13/16] class_loss: 0.0020 s_domain_loss: 0.0005 t_domain_loss: 0.0040 \n","[14/16] class_loss: 0.0065 s_domain_loss: 0.0032 t_domain_loss: 0.0037 \n","[15/16] class_loss: 0.0023 s_domain_loss: 0.0008 t_domain_loss: 0.0040 \n","[16/16] class_loss: 0.0046 s_domain_loss: 0.0006 t_domain_loss: 0.0027 \n","\n","Epoch 0013 / 0030\n","=================\n","[1/16] class_loss: 0.0020 s_domain_loss: 0.0020 t_domain_loss: 0.0032 \n","[2/16] class_loss: 0.0024 s_domain_loss: 0.0026 t_domain_loss: 0.0030 \n","[3/16] class_loss: 0.0061 s_domain_loss: 0.0036 t_domain_loss: 0.0027 \n","[4/16] class_loss: 0.0031 s_domain_loss: 0.0061 t_domain_loss: 0.0026 \n","[5/16] class_loss: 0.0016 s_domain_loss: 0.0006 t_domain_loss: 0.0024 \n","[6/16] class_loss: 0.0017 s_domain_loss: 0.0011 t_domain_loss: 0.0025 \n","[7/16] class_loss: 0.0023 s_domain_loss: 0.0078 t_domain_loss: 0.0022 \n","[8/16] class_loss: 0.0009 s_domain_loss: 0.0041 t_domain_loss: 0.0023 \n","[9/16] class_loss: 0.0053 s_domain_loss: 0.0076 t_domain_loss: 0.0022 \n","[10/16] class_loss: 0.0019 s_domain_loss: 0.0021 t_domain_loss: 0.0025 \n","[11/16] class_loss: 0.0045 s_domain_loss: 0.0006 t_domain_loss: 0.0022 \n","[12/16] class_loss: 0.0021 s_domain_loss: 0.0034 t_domain_loss: 0.0025 \n","[13/16] class_loss: 0.0022 s_domain_loss: 0.0100 t_domain_loss: 0.0023 \n","[14/16] class_loss: 0.0033 s_domain_loss: 0.0021 t_domain_loss: 0.0024 \n","[15/16] class_loss: 0.0016 s_domain_loss: 0.0009 t_domain_loss: 0.0028 \n","[16/16] class_loss: 0.0024 s_domain_loss: 0.0009 t_domain_loss: 0.0020 \n","\n","Epoch 0014 / 0030\n","=================\n","[1/16] class_loss: 0.0022 s_domain_loss: 0.0014 t_domain_loss: 0.0027 \n","[2/16] class_loss: 0.0035 s_domain_loss: 0.0044 t_domain_loss: 0.0027 \n","[3/16] class_loss: 0.0033 s_domain_loss: 0.0025 t_domain_loss: 0.0026 \n","[4/16] class_loss: 0.0018 s_domain_loss: 0.0024 t_domain_loss: 0.0025 \n","[5/16] class_loss: 0.0040 s_domain_loss: 0.0144 t_domain_loss: 0.0025 \n","[6/16] class_loss: 0.0031 s_domain_loss: 0.0004 t_domain_loss: 0.0029 \n","[7/16] class_loss: 0.0032 s_domain_loss: 0.0015 t_domain_loss: 0.0028 \n","[8/16] class_loss: 0.0040 s_domain_loss: 0.0015 t_domain_loss: 0.0029 \n","[9/16] class_loss: 0.0031 s_domain_loss: 0.0003 t_domain_loss: 0.0029 \n","[10/16] class_loss: 0.0014 s_domain_loss: 0.0006 t_domain_loss: 0.0031 \n","[11/16] class_loss: 0.0024 s_domain_loss: 0.0056 t_domain_loss: 0.0029 \n","[12/16] class_loss: 0.0017 s_domain_loss: 0.0007 t_domain_loss: 0.0032 \n","[13/16] class_loss: 0.0011 s_domain_loss: 0.0011 t_domain_loss: 0.0029 \n","[14/16] class_loss: 0.0020 s_domain_loss: 0.0021 t_domain_loss: 0.0028 \n","[15/16] class_loss: 0.0014 s_domain_loss: 0.0020 t_domain_loss: 0.0031 \n","[16/16] class_loss: 0.0021 s_domain_loss: 0.0016 t_domain_loss: 0.0020 \n","\n","Epoch 0015 / 0030\n","=================\n","[1/16] class_loss: 0.0024 s_domain_loss: 0.0047 t_domain_loss: 0.0027 \n","[2/16] class_loss: 0.0015 s_domain_loss: 0.0019 t_domain_loss: 0.0026 \n","[3/16] class_loss: 0.0026 s_domain_loss: 0.0017 t_domain_loss: 0.0024 \n","[4/16] class_loss: 0.0021 s_domain_loss: 0.0038 t_domain_loss: 0.0023 \n","[5/16] class_loss: 0.0024 s_domain_loss: 0.0012 t_domain_loss: 0.0022 \n","[6/16] class_loss: 0.0030 s_domain_loss: 0.0025 t_domain_loss: 0.0024 \n","[7/16] class_loss: 0.0039 s_domain_loss: 0.0005 t_domain_loss: 0.0022 \n","[8/16] class_loss: 0.0017 s_domain_loss: 0.0009 t_domain_loss: 0.0022 \n","[9/16] class_loss: 0.0018 s_domain_loss: 0.0233 t_domain_loss: 0.0021 \n","[10/16] class_loss: 0.0014 s_domain_loss: 0.0031 t_domain_loss: 0.0024 \n","[11/16] class_loss: 0.0034 s_domain_loss: 0.0009 t_domain_loss: 0.0023 \n","[12/16] class_loss: 0.0042 s_domain_loss: 0.0008 t_domain_loss: 0.0026 \n","[13/16] class_loss: 0.0021 s_domain_loss: 0.0028 t_domain_loss: 0.0025 \n","[14/16] class_loss: 0.0022 s_domain_loss: 0.0005 t_domain_loss: 0.0026 \n","[15/16] class_loss: 0.0033 s_domain_loss: 0.0237 t_domain_loss: 0.0030 \n","[16/16] class_loss: 0.0019 s_domain_loss: 0.0005 t_domain_loss: 0.0023 \n","\n","Epoch 0016 / 0030\n","=================\n","[1/16] class_loss: 0.0015 s_domain_loss: 0.0007 t_domain_loss: 0.0035 \n","[2/16] class_loss: 0.0029 s_domain_loss: 0.0035 t_domain_loss: 0.0037 \n","[3/16] class_loss: 0.0043 s_domain_loss: 0.0114 t_domain_loss: 0.0037 \n","[4/16] class_loss: 0.0022 s_domain_loss: 0.0010 t_domain_loss: 0.0041 \n","[5/16] class_loss: 0.0018 s_domain_loss: 0.0003 t_domain_loss: 0.0044 \n","[6/16] class_loss: 0.0041 s_domain_loss: 0.0050 t_domain_loss: 0.0048 \n","[7/16] class_loss: 0.0032 s_domain_loss: 0.0077 t_domain_loss: 0.0046 \n","[8/16] class_loss: 0.0034 s_domain_loss: 0.0018 t_domain_loss: 0.0050 \n","[9/16] class_loss: 0.0015 s_domain_loss: 0.0003 t_domain_loss: 0.0049 \n","[10/16] class_loss: 0.0027 s_domain_loss: 0.0035 t_domain_loss: 0.0050 \n","[11/16] class_loss: 0.0011 s_domain_loss: 0.0019 t_domain_loss: 0.0047 \n","[12/16] class_loss: 0.0032 s_domain_loss: 0.0010 t_domain_loss: 0.0049 \n","[13/16] class_loss: 0.0025 s_domain_loss: 0.0008 t_domain_loss: 0.0043 \n","[14/16] class_loss: 0.0015 s_domain_loss: 0.0007 t_domain_loss: 0.0040 \n","[15/16] class_loss: 0.0015 s_domain_loss: 0.0011 t_domain_loss: 0.0041 \n","[16/16] class_loss: 0.0012 s_domain_loss: 0.0012 t_domain_loss: 0.0026 \n","\n","Epoch 0017 / 0030\n","=================\n","[1/16] class_loss: 0.0031 s_domain_loss: 0.0018 t_domain_loss: 0.0031 \n","[2/16] class_loss: 0.0028 s_domain_loss: 0.0080 t_domain_loss: 0.0029 \n","[3/16] class_loss: 0.0014 s_domain_loss: 0.0072 t_domain_loss: 0.0025 \n","[4/16] class_loss: 0.0036 s_domain_loss: 0.0013 t_domain_loss: 0.0023 \n","[5/16] class_loss: 0.0017 s_domain_loss: 0.0019 t_domain_loss: 0.0022 \n","[6/16] class_loss: 0.0014 s_domain_loss: 0.0004 t_domain_loss: 0.0023 \n","[7/16] class_loss: 0.0027 s_domain_loss: 0.0033 t_domain_loss: 0.0021 \n","[8/16] class_loss: 0.0005 s_domain_loss: 0.0003 t_domain_loss: 0.0020 \n","[9/16] class_loss: 0.0027 s_domain_loss: 0.0016 t_domain_loss: 0.0019 \n","[10/16] class_loss: 0.0016 s_domain_loss: 0.0006 t_domain_loss: 0.0021 \n","[11/16] class_loss: 0.0016 s_domain_loss: 0.0022 t_domain_loss: 0.0018 \n","[12/16] class_loss: 0.0017 s_domain_loss: 0.0053 t_domain_loss: 0.0019 \n","[13/16] class_loss: 0.0024 s_domain_loss: 0.0016 t_domain_loss: 0.0017 \n","[14/16] class_loss: 0.0019 s_domain_loss: 0.0030 t_domain_loss: 0.0016 \n","[15/16] class_loss: 0.0021 s_domain_loss: 0.0018 t_domain_loss: 0.0019 \n","[16/16] class_loss: 0.0011 s_domain_loss: 0.0040 t_domain_loss: 0.0012 \n","\n","Epoch 0018 / 0030\n","=================\n","[1/16] class_loss: 0.0049 s_domain_loss: 0.0003 t_domain_loss: 0.0017 \n","[2/16] class_loss: 0.0023 s_domain_loss: 0.0016 t_domain_loss: 0.0016 \n","[3/16] class_loss: 0.0016 s_domain_loss: 0.0007 t_domain_loss: 0.0015 \n","[4/16] class_loss: 0.0021 s_domain_loss: 0.0004 t_domain_loss: 0.0015 \n","[5/16] class_loss: 0.0041 s_domain_loss: 0.0006 t_domain_loss: 0.0014 \n","[6/16] class_loss: 0.0026 s_domain_loss: 0.0010 t_domain_loss: 0.0016 \n","[7/16] class_loss: 0.0036 s_domain_loss: 0.0014 t_domain_loss: 0.0014 \n","[8/16] class_loss: 0.0013 s_domain_loss: 0.0012 t_domain_loss: 0.0014 \n","[9/16] class_loss: 0.0010 s_domain_loss: 0.0007 t_domain_loss: 0.0013 \n","[10/16] class_loss: 0.0014 s_domain_loss: 0.0035 t_domain_loss: 0.0015 \n","[11/16] class_loss: 0.0010 s_domain_loss: 0.0030 t_domain_loss: 0.0013 \n","[12/16] class_loss: 0.0018 s_domain_loss: 0.0013 t_domain_loss: 0.0014 \n","[13/16] class_loss: 0.0018 s_domain_loss: 0.0052 t_domain_loss: 0.0013 \n","[14/16] class_loss: 0.0007 s_domain_loss: 0.0038 t_domain_loss: 0.0013 \n","[15/16] class_loss: 0.0023 s_domain_loss: 0.0037 t_domain_loss: 0.0016 \n","[16/16] class_loss: 0.0008 s_domain_loss: 0.0012 t_domain_loss: 0.0011 \n","\n","Epoch 0019 / 0030\n","=================\n","[1/16] class_loss: 0.0008 s_domain_loss: 0.0009 t_domain_loss: 0.0015 \n","[2/16] class_loss: 0.0011 s_domain_loss: 0.0005 t_domain_loss: 0.0015 \n","[3/16] class_loss: 0.0060 s_domain_loss: 0.0305 t_domain_loss: 0.0015 \n","[4/16] class_loss: 0.0022 s_domain_loss: 0.0017 t_domain_loss: 0.0017 \n","[5/16] class_loss: 0.0012 s_domain_loss: 0.0001 t_domain_loss: 0.0019 \n","[6/16] class_loss: 0.0007 s_domain_loss: 0.0006 t_domain_loss: 0.0024 \n","[7/16] class_loss: 0.0020 s_domain_loss: 0.0020 t_domain_loss: 0.0024 \n","[8/16] class_loss: 0.0025 s_domain_loss: 0.0004 t_domain_loss: 0.0026 \n","[9/16] class_loss: 0.0024 s_domain_loss: 0.0013 t_domain_loss: 0.0028 \n","[10/16] class_loss: 0.0010 s_domain_loss: 0.0012 t_domain_loss: 0.0031 \n","[11/16] class_loss: 0.0019 s_domain_loss: 0.0010 t_domain_loss: 0.0030 \n","[12/16] class_loss: 0.0048 s_domain_loss: 0.0006 t_domain_loss: 0.0034 \n","[13/16] class_loss: 0.0024 s_domain_loss: 0.0005 t_domain_loss: 0.0032 \n","[14/16] class_loss: 0.0027 s_domain_loss: 0.0002 t_domain_loss: 0.0030 \n","[15/16] class_loss: 0.0015 s_domain_loss: 0.0016 t_domain_loss: 0.0034 \n","[16/16] class_loss: 0.0028 s_domain_loss: 0.0004 t_domain_loss: 0.0021 \n","\n","Epoch 0020 / 0030\n","=================\n","[1/16] class_loss: 0.0008 s_domain_loss: 0.1487 t_domain_loss: 0.0028 \n","[2/16] class_loss: 0.0039 s_domain_loss: 0.0020 t_domain_loss: 0.0028 \n","[3/16] class_loss: 0.0012 s_domain_loss: 0.0286 t_domain_loss: 0.0028 \n","[4/16] class_loss: 0.0014 s_domain_loss: 0.0007 t_domain_loss: 0.0029 \n","[5/16] class_loss: 0.0018 s_domain_loss: 0.0006 t_domain_loss: 0.0029 \n","[6/16] class_loss: 0.0038 s_domain_loss: 0.0004 t_domain_loss: 0.0034 \n","[7/16] class_loss: 0.0035 s_domain_loss: 0.0002 t_domain_loss: 0.0032 \n","[8/16] class_loss: 0.0052 s_domain_loss: 0.0020 t_domain_loss: 0.0032 \n","[9/16] class_loss: 0.0033 s_domain_loss: 0.0002 t_domain_loss: 0.0033 \n","[10/16] class_loss: 0.0028 s_domain_loss: 0.0002 t_domain_loss: 0.0037 \n","[11/16] class_loss: 0.0012 s_domain_loss: 0.0011 t_domain_loss: 0.0035 \n","[12/16] class_loss: 0.0020 s_domain_loss: 0.0056 t_domain_loss: 0.0038 \n","[13/16] class_loss: 0.0027 s_domain_loss: 0.0032 t_domain_loss: 0.0038 \n","[14/16] class_loss: 0.0028 s_domain_loss: 0.0007 t_domain_loss: 0.0036 \n","[15/16] class_loss: 0.0057 s_domain_loss: 0.0003 t_domain_loss: 0.0044 \n","[16/16] class_loss: 0.0025 s_domain_loss: 0.0011 t_domain_loss: 0.0029 \n","\n","Epoch 0021 / 0030\n","=================\n","[1/16] class_loss: 0.0026 s_domain_loss: 0.0025 t_domain_loss: 0.0041 \n","[2/16] class_loss: 0.0017 s_domain_loss: 0.0006 t_domain_loss: 0.0039 \n","[3/16] class_loss: 0.0010 s_domain_loss: 0.0011 t_domain_loss: 0.0037 \n","[4/16] class_loss: 0.0043 s_domain_loss: 0.0004 t_domain_loss: 0.0037 \n","[5/16] class_loss: 0.0014 s_domain_loss: 0.0011 t_domain_loss: 0.0035 \n","[6/16] class_loss: 0.0018 s_domain_loss: 0.0010 t_domain_loss: 0.0038 \n","[7/16] class_loss: 0.0028 s_domain_loss: 0.0038 t_domain_loss: 0.0036 \n","[8/16] class_loss: 0.0011 s_domain_loss: 0.0005 t_domain_loss: 0.0034 \n","[9/16] class_loss: 0.0027 s_domain_loss: 0.0016 t_domain_loss: 0.0034 \n","[10/16] class_loss: 0.0015 s_domain_loss: 0.0002 t_domain_loss: 0.0037 \n","[11/16] class_loss: 0.0023 s_domain_loss: 0.0033 t_domain_loss: 0.0035 \n","[12/16] class_loss: 0.0026 s_domain_loss: 0.0004 t_domain_loss: 0.0037 \n","[13/16] class_loss: 0.0009 s_domain_loss: 0.0047 t_domain_loss: 0.0036 \n","[14/16] class_loss: 0.0017 s_domain_loss: 0.0003 t_domain_loss: 0.0034 \n","[15/16] class_loss: 0.0018 s_domain_loss: 0.0015 t_domain_loss: 0.0040 \n","[16/16] class_loss: 0.0020 s_domain_loss: 0.0007 t_domain_loss: 0.0026 \n","\n","Epoch 0022 / 0030\n","=================\n","[1/16] class_loss: 0.0011 s_domain_loss: 0.0142 t_domain_loss: 0.0036 \n","[2/16] class_loss: 0.0012 s_domain_loss: 0.0005 t_domain_loss: 0.0034 \n","[3/16] class_loss: 0.0014 s_domain_loss: 0.0003 t_domain_loss: 0.0032 \n","[4/16] class_loss: 0.0014 s_domain_loss: 0.0006 t_domain_loss: 0.0032 \n","[5/16] class_loss: 0.0013 s_domain_loss: 0.0026 t_domain_loss: 0.0031 \n","[6/16] class_loss: 0.0014 s_domain_loss: 0.0006 t_domain_loss: 0.0034 \n","[7/16] class_loss: 0.0018 s_domain_loss: 0.0009 t_domain_loss: 0.0031 \n","[8/16] class_loss: 0.0024 s_domain_loss: 0.0037 t_domain_loss: 0.0030 \n","[9/16] class_loss: 0.0013 s_domain_loss: 0.0003 t_domain_loss: 0.0030 \n","[10/16] class_loss: 0.0020 s_domain_loss: 0.0047 t_domain_loss: 0.0033 \n","[11/16] class_loss: 0.0013 s_domain_loss: 0.0002 t_domain_loss: 0.0030 \n","[12/16] class_loss: 0.0009 s_domain_loss: 0.0002 t_domain_loss: 0.0032 \n","[13/16] class_loss: 0.0023 s_domain_loss: 0.0003 t_domain_loss: 0.0031 \n","[14/16] class_loss: 0.0004 s_domain_loss: 0.0002 t_domain_loss: 0.0030 \n","[15/16] class_loss: 0.0007 s_domain_loss: 0.0006 t_domain_loss: 0.0035 \n","[16/16] class_loss: 0.0010 s_domain_loss: 0.0002 t_domain_loss: 0.0023 \n","\n","Epoch 0023 / 0030\n","=================\n","[1/16] class_loss: 0.0010 s_domain_loss: 0.0004 t_domain_loss: 0.0031 \n","[2/16] class_loss: 0.0011 s_domain_loss: 0.0016 t_domain_loss: 0.0030 \n","[3/16] class_loss: 0.0025 s_domain_loss: 0.0005 t_domain_loss: 0.0028 \n","[4/16] class_loss: 0.0015 s_domain_loss: 0.0007 t_domain_loss: 0.0027 \n","[5/16] class_loss: 0.0008 s_domain_loss: 0.0010 t_domain_loss: 0.0027 \n","[6/16] class_loss: 0.0011 s_domain_loss: 0.0002 t_domain_loss: 0.0029 \n","[7/16] class_loss: 0.0009 s_domain_loss: 0.0007 t_domain_loss: 0.0026 \n","[8/16] class_loss: 0.0008 s_domain_loss: 0.0027 t_domain_loss: 0.0026 \n","[9/16] class_loss: 0.0010 s_domain_loss: 0.0008 t_domain_loss: 0.0025 \n","[10/16] class_loss: 0.0015 s_domain_loss: 0.0007 t_domain_loss: 0.0028 \n","[11/16] class_loss: 0.0010 s_domain_loss: 0.0009 t_domain_loss: 0.0026 \n","[12/16] class_loss: 0.0017 s_domain_loss: 0.0092 t_domain_loss: 0.0027 \n","[13/16] class_loss: 0.0009 s_domain_loss: 0.0012 t_domain_loss: 0.0026 \n","[14/16] class_loss: 0.0020 s_domain_loss: 0.0004 t_domain_loss: 0.0025 \n","[15/16] class_loss: 0.0013 s_domain_loss: 0.0009 t_domain_loss: 0.0029 \n","[16/16] class_loss: 0.0013 s_domain_loss: 0.0062 t_domain_loss: 0.0019 \n","\n","Epoch 0024 / 0030\n","=================\n","[1/16] class_loss: 0.0016 s_domain_loss: 0.0011 t_domain_loss: 0.0027 \n","[2/16] class_loss: 0.0013 s_domain_loss: 0.0002 t_domain_loss: 0.0026 \n","[3/16] class_loss: 0.0020 s_domain_loss: 0.0022 t_domain_loss: 0.0024 \n","[4/16] class_loss: 0.0014 s_domain_loss: 0.0013 t_domain_loss: 0.0024 \n","[5/16] class_loss: 0.0012 s_domain_loss: 0.0037 t_domain_loss: 0.0023 \n","[6/16] class_loss: 0.0006 s_domain_loss: 0.0012 t_domain_loss: 0.0025 \n","[7/16] class_loss: 0.0011 s_domain_loss: 0.0010 t_domain_loss: 0.0023 \n","[8/16] class_loss: 0.0007 s_domain_loss: 0.0122 t_domain_loss: 0.0023 \n","[9/16] class_loss: 0.0018 s_domain_loss: 0.0016 t_domain_loss: 0.0023 \n","[10/16] class_loss: 0.0005 s_domain_loss: 0.0019 t_domain_loss: 0.0025 \n","[11/16] class_loss: 0.0006 s_domain_loss: 0.0007 t_domain_loss: 0.0024 \n","[12/16] class_loss: 0.0011 s_domain_loss: 0.0025 t_domain_loss: 0.0025 \n","[13/16] class_loss: 0.0028 s_domain_loss: 0.0017 t_domain_loss: 0.0024 \n","[14/16] class_loss: 0.0011 s_domain_loss: 0.0005 t_domain_loss: 0.0024 \n","[15/16] class_loss: 0.0014 s_domain_loss: 0.0004 t_domain_loss: 0.0028 \n","[16/16] class_loss: 0.0012 s_domain_loss: 0.0004 t_domain_loss: 0.0018 \n","\n","Epoch 0025 / 0030\n","=================\n","[1/16] class_loss: 0.0013 s_domain_loss: 0.0007 t_domain_loss: 0.0025 \n","[2/16] class_loss: 0.0007 s_domain_loss: 0.0013 t_domain_loss: 0.0024 \n","[3/16] class_loss: 0.0019 s_domain_loss: 0.0001 t_domain_loss: 0.0023 \n","[4/16] class_loss: 0.0012 s_domain_loss: 0.0023 t_domain_loss: 0.0022 \n","[5/16] class_loss: 0.0006 s_domain_loss: 0.0026 t_domain_loss: 0.0022 \n","[6/16] class_loss: 0.0005 s_domain_loss: 0.0016 t_domain_loss: 0.0024 \n","[7/16] class_loss: 0.0008 s_domain_loss: 0.0010 t_domain_loss: 0.0022 \n","[8/16] class_loss: 0.0016 s_domain_loss: 0.0020 t_domain_loss: 0.0022 \n","[9/16] class_loss: 0.0008 s_domain_loss: 0.0004 t_domain_loss: 0.0022 \n","[10/16] class_loss: 0.0012 s_domain_loss: 0.0023 t_domain_loss: 0.0024 \n","[11/16] class_loss: 0.0013 s_domain_loss: 0.0011 t_domain_loss: 0.0022 \n","[12/16] class_loss: 0.0008 s_domain_loss: 0.0009 t_domain_loss: 0.0023 \n","[13/16] class_loss: 0.0010 s_domain_loss: 0.0018 t_domain_loss: 0.0022 \n","[14/16] class_loss: 0.0011 s_domain_loss: 0.0009 t_domain_loss: 0.0022 \n","[15/16] class_loss: 0.0006 s_domain_loss: 0.0003 t_domain_loss: 0.0025 \n","[16/16] class_loss: 0.0010 s_domain_loss: 0.0037 t_domain_loss: 0.0016 \n","\n","Epoch 0026 / 0030\n","=================\n","[1/16] class_loss: 0.0022 s_domain_loss: 0.0058 t_domain_loss: 0.0023 \n","[2/16] class_loss: 0.0010 s_domain_loss: 0.0011 t_domain_loss: 0.0022 \n","[3/16] class_loss: 0.0008 s_domain_loss: 0.0026 t_domain_loss: 0.0021 \n","[4/16] class_loss: 0.0010 s_domain_loss: 0.0146 t_domain_loss: 0.0020 \n","[5/16] class_loss: 0.0009 s_domain_loss: 0.0010 t_domain_loss: 0.0020 \n","[6/16] class_loss: 0.0010 s_domain_loss: 0.0010 t_domain_loss: 0.0022 \n","[7/16] class_loss: 0.0005 s_domain_loss: 0.0037 t_domain_loss: 0.0021 \n","[8/16] class_loss: 0.0010 s_domain_loss: 0.0008 t_domain_loss: 0.0021 \n","[9/16] class_loss: 0.0010 s_domain_loss: 0.0006 t_domain_loss: 0.0021 \n","[10/16] class_loss: 0.0017 s_domain_loss: 0.0013 t_domain_loss: 0.0023 \n","[11/16] class_loss: 0.0011 s_domain_loss: 0.0017 t_domain_loss: 0.0021 \n","[12/16] class_loss: 0.0007 s_domain_loss: 0.0007 t_domain_loss: 0.0023 \n","[13/16] class_loss: 0.0013 s_domain_loss: 0.0005 t_domain_loss: 0.0022 \n","[14/16] class_loss: 0.0027 s_domain_loss: 0.0008 t_domain_loss: 0.0021 \n","[15/16] class_loss: 0.0017 s_domain_loss: 0.0010 t_domain_loss: 0.0025 \n","[16/16] class_loss: 0.0007 s_domain_loss: 0.0008 t_domain_loss: 0.0016 \n","\n","Epoch 0027 / 0030\n","=================\n","[1/16] class_loss: 0.0008 s_domain_loss: 0.0006 t_domain_loss: 0.0022 \n","[2/16] class_loss: 0.0011 s_domain_loss: 0.0012 t_domain_loss: 0.0022 \n","[3/16] class_loss: 0.0010 s_domain_loss: 0.0006 t_domain_loss: 0.0020 \n","[4/16] class_loss: 0.0014 s_domain_loss: 0.0012 t_domain_loss: 0.0020 \n","[5/16] class_loss: 0.0008 s_domain_loss: 0.0008 t_domain_loss: 0.0020 \n","[6/16] class_loss: 0.0014 s_domain_loss: 0.0003 t_domain_loss: 0.0022 \n","[7/16] class_loss: 0.0009 s_domain_loss: 0.0004 t_domain_loss: 0.0020 \n","[8/16] class_loss: 0.0028 s_domain_loss: 0.0006 t_domain_loss: 0.0020 \n","[9/16] class_loss: 0.0010 s_domain_loss: 0.0011 t_domain_loss: 0.0019 \n","[10/16] class_loss: 0.0008 s_domain_loss: 0.0013 t_domain_loss: 0.0021 \n","[11/16] class_loss: 0.0029 s_domain_loss: 0.0033 t_domain_loss: 0.0020 \n","[12/16] class_loss: 0.0006 s_domain_loss: 0.0006 t_domain_loss: 0.0021 \n","[13/16] class_loss: 0.0009 s_domain_loss: 0.0033 t_domain_loss: 0.0020 \n","[14/16] class_loss: 0.0069 s_domain_loss: 0.0015 t_domain_loss: 0.0019 \n","[15/16] class_loss: 0.0009 s_domain_loss: 0.0018 t_domain_loss: 0.0022 \n","[16/16] class_loss: 0.0007 s_domain_loss: 0.0014 t_domain_loss: 0.0015 \n","\n","Epoch 0028 / 0030\n","=================\n","[1/16] class_loss: 0.0021 s_domain_loss: 0.0004 t_domain_loss: 0.0021 \n","[2/16] class_loss: 0.0006 s_domain_loss: 0.0007 t_domain_loss: 0.0020 \n","[3/16] class_loss: 0.0013 s_domain_loss: 0.0005 t_domain_loss: 0.0019 \n","[4/16] class_loss: 0.0007 s_domain_loss: 0.0008 t_domain_loss: 0.0018 \n","[5/16] class_loss: 0.0022 s_domain_loss: 0.0278 t_domain_loss: 0.0018 \n","[6/16] class_loss: 0.0006 s_domain_loss: 0.0004 t_domain_loss: 0.0020 \n","[7/16] class_loss: 0.0011 s_domain_loss: 0.0003 t_domain_loss: 0.0019 \n","[8/16] class_loss: 0.0016 s_domain_loss: 0.0007 t_domain_loss: 0.0019 \n","[9/16] class_loss: 0.0010 s_domain_loss: 0.0011 t_domain_loss: 0.0018 \n","[10/16] class_loss: 0.0013 s_domain_loss: 0.0011 t_domain_loss: 0.0021 \n","[11/16] class_loss: 0.0013 s_domain_loss: 0.0003 t_domain_loss: 0.0019 \n","[12/16] class_loss: 0.0020 s_domain_loss: 0.0013 t_domain_loss: 0.0020 \n","[13/16] class_loss: 0.0009 s_domain_loss: 0.0023 t_domain_loss: 0.0020 \n","[14/16] class_loss: 0.0022 s_domain_loss: 0.0069 t_domain_loss: 0.0019 \n","[15/16] class_loss: 0.0010 s_domain_loss: 0.0025 t_domain_loss: 0.0022 \n","[16/16] class_loss: 0.0014 s_domain_loss: 0.0445 t_domain_loss: 0.0015 \n","\n","Epoch 0029 / 0030\n","=================\n","[1/16] class_loss: 0.0007 s_domain_loss: 0.0011 t_domain_loss: 0.0021 \n","[2/16] class_loss: 0.0007 s_domain_loss: 0.0009 t_domain_loss: 0.0021 \n","[3/16] class_loss: 0.0014 s_domain_loss: 0.0009 t_domain_loss: 0.0020 \n","[4/16] class_loss: 0.0009 s_domain_loss: 0.0010 t_domain_loss: 0.0020 \n","[5/16] class_loss: 0.0019 s_domain_loss: 0.0005 t_domain_loss: 0.0020 \n","[6/16] class_loss: 0.0007 s_domain_loss: 0.0012 t_domain_loss: 0.0022 \n","[7/16] class_loss: 0.0010 s_domain_loss: 0.0003 t_domain_loss: 0.0021 \n","[8/16] class_loss: 0.0006 s_domain_loss: 0.0006 t_domain_loss: 0.0021 \n","[9/16] class_loss: 0.0010 s_domain_loss: 0.0006 t_domain_loss: 0.0021 \n","[10/16] class_loss: 0.0004 s_domain_loss: 0.0013 t_domain_loss: 0.0023 \n","[11/16] class_loss: 0.0012 s_domain_loss: 0.0008 t_domain_loss: 0.0022 \n","[12/16] class_loss: 0.0028 s_domain_loss: 0.0041 t_domain_loss: 0.0024 \n","[13/16] class_loss: 0.0011 s_domain_loss: 0.0013 t_domain_loss: 0.0023 \n","[14/16] class_loss: 0.0007 s_domain_loss: 0.0010 t_domain_loss: 0.0022 \n","[15/16] class_loss: 0.0005 s_domain_loss: 0.0020 t_domain_loss: 0.0026 \n","[16/16] class_loss: 0.0012 s_domain_loss: 0.0067 t_domain_loss: 0.0017 \n","\n","Epoch 0030 / 0030\n","=================\n","[1/16] class_loss: 0.0010 s_domain_loss: 0.0015 t_domain_loss: 0.0024 \n","[2/16] class_loss: 0.0006 s_domain_loss: 0.0062 t_domain_loss: 0.0024 \n","[3/16] class_loss: 0.0010 s_domain_loss: 0.0019 t_domain_loss: 0.0022 \n","[4/16] class_loss: 0.0008 s_domain_loss: 0.0040 t_domain_loss: 0.0021 \n","[5/16] class_loss: 0.0017 s_domain_loss: 0.0015 t_domain_loss: 0.0022 \n","[6/16] class_loss: 0.0020 s_domain_loss: 0.0007 t_domain_loss: 0.0024 \n","[7/16] class_loss: 0.0008 s_domain_loss: 0.0040 t_domain_loss: 0.0022 \n","[8/16] class_loss: 0.0005 s_domain_loss: 0.0048 t_domain_loss: 0.0022 \n","[9/16] class_loss: 0.0014 s_domain_loss: 0.0071 t_domain_loss: 0.0022 \n","[10/16] class_loss: 0.0007 s_domain_loss: 0.0204 t_domain_loss: 0.0024 \n","[11/16] class_loss: 0.0014 s_domain_loss: 0.0040 t_domain_loss: 0.0023 \n","[12/16] class_loss: 0.0006 s_domain_loss: 0.0015 t_domain_loss: 0.0025 \n","[13/16] class_loss: 0.0008 s_domain_loss: 0.0004 t_domain_loss: 0.0024 \n","[14/16] class_loss: 0.0005 s_domain_loss: 0.0034 t_domain_loss: 0.0023 \n","[15/16] class_loss: 0.0010 s_domain_loss: 0.0006 t_domain_loss: 0.0027 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[16/16] class_loss: 0.0017 s_domain_loss: 0.0042 t_domain_loss: 0.0018 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:16<00:00,  1.04s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.5849609375\n","hyperprameters are: LR=0.006 and NUM_EPOCHS = 10\n","\n","Epoch 0001 / 0010\n","=================\n","[1/16] class_loss: 1.8808 s_domain_loss: 0.9282 t_domain_loss: 0.5473 \n","[2/16] class_loss: 1.1474 s_domain_loss: 0.3078 t_domain_loss: 1.4093 \n","[3/16] class_loss: 0.6832 s_domain_loss: 1.6222 t_domain_loss: 0.2408 \n","[4/16] class_loss: 0.4231 s_domain_loss: 0.3089 t_domain_loss: 1.3573 \n","[5/16] class_loss: 0.4060 s_domain_loss: 0.9729 t_domain_loss: 0.4854 \n","[6/16] class_loss: 0.2399 s_domain_loss: 0.6668 t_domain_loss: 0.7067 \n","[7/16] class_loss: 0.2089 s_domain_loss: 0.4588 t_domain_loss: 0.9785 \n","[8/16] class_loss: 0.1836 s_domain_loss: 1.2882 t_domain_loss: 0.3135 \n","[9/16] class_loss: 0.2216 s_domain_loss: 0.2460 t_domain_loss: 1.4642 \n","[10/16] class_loss: 0.2783 s_domain_loss: 1.2891 t_domain_loss: 0.3055 \n","[11/16] class_loss: 0.1772 s_domain_loss: 0.3991 t_domain_loss: 1.0291 \n","[12/16] class_loss: 0.2090 s_domain_loss: 0.8028 t_domain_loss: 0.5244 \n","[13/16] class_loss: 0.2434 s_domain_loss: 0.6344 t_domain_loss: 0.6670 \n","[14/16] class_loss: 0.1582 s_domain_loss: 0.5530 t_domain_loss: 0.7472 \n","[15/16] class_loss: 0.1604 s_domain_loss: 0.8495 t_domain_loss: 0.4919 \n","[16/16] class_loss: 0.1134 s_domain_loss: 0.4138 t_domain_loss: 0.9127 \n","\n","Epoch 0002 / 0010\n","=================\n","[1/16] class_loss: 0.0938 s_domain_loss: 0.9472 t_domain_loss: 0.3765 \n","[2/16] class_loss: 0.1360 s_domain_loss: 0.4002 t_domain_loss: 0.8925 \n","[3/16] class_loss: 0.1493 s_domain_loss: 0.8228 t_domain_loss: 0.4497 \n","[4/16] class_loss: 0.0759 s_domain_loss: 0.4710 t_domain_loss: 0.7302 \n","[5/16] class_loss: 0.0978 s_domain_loss: 0.7474 t_domain_loss: 0.4734 \n","[6/16] class_loss: 0.1388 s_domain_loss: 0.4645 t_domain_loss: 0.7382 \n","[7/16] class_loss: 0.0852 s_domain_loss: 0.7114 t_domain_loss: 0.4336 \n","[8/16] class_loss: 0.0824 s_domain_loss: 0.4677 t_domain_loss: 0.6514 \n","[9/16] class_loss: 0.0763 s_domain_loss: 0.6151 t_domain_loss: 0.4872 \n","[10/16] class_loss: 0.0589 s_domain_loss: 0.4977 t_domain_loss: 0.6066 \n","[11/16] class_loss: 0.0628 s_domain_loss: 0.4976 t_domain_loss: 0.5526 \n","[12/16] class_loss: 0.0805 s_domain_loss: 0.6563 t_domain_loss: 0.4272 \n","[13/16] class_loss: 0.0579 s_domain_loss: 0.3891 t_domain_loss: 0.6421 \n","[14/16] class_loss: 0.0480 s_domain_loss: 0.6762 t_domain_loss: 0.3677 \n","[15/16] class_loss: 0.0886 s_domain_loss: 0.3502 t_domain_loss: 0.6001 \n","[16/16] class_loss: 0.0602 s_domain_loss: 0.5858 t_domain_loss: 0.3415 \n","\n","Epoch 0003 / 0010\n","=================\n","[1/16] class_loss: 0.0420 s_domain_loss: 0.4389 t_domain_loss: 0.4902 \n","[2/16] class_loss: 0.0594 s_domain_loss: 0.4004 t_domain_loss: 0.4943 \n","[3/16] class_loss: 0.0637 s_domain_loss: 0.5626 t_domain_loss: 0.3223 \n","[4/16] class_loss: 0.0438 s_domain_loss: 0.3632 t_domain_loss: 0.4979 \n","[5/16] class_loss: 0.0439 s_domain_loss: 0.3926 t_domain_loss: 0.3640 \n","[6/16] class_loss: 0.0491 s_domain_loss: 0.5473 t_domain_loss: 0.2734 \n","[7/16] class_loss: 0.0307 s_domain_loss: 0.2323 t_domain_loss: 0.5727 \n","[8/16] class_loss: 0.0512 s_domain_loss: 0.4186 t_domain_loss: 0.2507 \n","[9/16] class_loss: 0.0488 s_domain_loss: 0.4429 t_domain_loss: 0.2108 \n","[10/16] class_loss: 0.0493 s_domain_loss: 0.1400 t_domain_loss: 0.4710 \n","[11/16] class_loss: 0.0632 s_domain_loss: 0.3608 t_domain_loss: 0.2176 \n","[12/16] class_loss: 0.0721 s_domain_loss: 0.4144 t_domain_loss: 0.2046 \n","[13/16] class_loss: 0.0557 s_domain_loss: 0.1188 t_domain_loss: 0.3986 \n","[14/16] class_loss: 0.0587 s_domain_loss: 0.4449 t_domain_loss: 0.1817 \n","[15/16] class_loss: 0.0651 s_domain_loss: 0.2505 t_domain_loss: 0.2336 \n","[16/16] class_loss: 0.0485 s_domain_loss: 0.2086 t_domain_loss: 0.3079 \n","\n","Epoch 0004 / 0010\n","=================\n","[1/16] class_loss: 0.0550 s_domain_loss: 0.2434 t_domain_loss: 0.2159 \n","[2/16] class_loss: 0.0656 s_domain_loss: 0.3598 t_domain_loss: 0.1288 \n","[3/16] class_loss: 0.0891 s_domain_loss: 0.0764 t_domain_loss: 0.2254 \n","[4/16] class_loss: 0.0443 s_domain_loss: 0.1510 t_domain_loss: 0.1471 \n","[5/16] class_loss: 0.0282 s_domain_loss: 0.3171 t_domain_loss: 0.0963 \n","[6/16] class_loss: 0.0780 s_domain_loss: 0.1925 t_domain_loss: 0.1220 \n","[7/16] class_loss: 0.1273 s_domain_loss: 0.1376 t_domain_loss: 0.1634 \n","[8/16] class_loss: 0.0874 s_domain_loss: 0.4884 t_domain_loss: 0.1974 \n","[9/16] class_loss: 0.0836 s_domain_loss: 0.0313 t_domain_loss: 0.5312 \n","[10/16] class_loss: 0.3237 s_domain_loss: 0.7287 t_domain_loss: 0.1432 \n","[11/16] class_loss: 0.1572 s_domain_loss: 0.3906 t_domain_loss: 0.0699 \n","[12/16] class_loss: 0.1691 s_domain_loss: 0.9491 t_domain_loss: 0.1683 \n","[13/16] class_loss: 0.1586 s_domain_loss: 0.0150 t_domain_loss: 1.2035 \n","[14/16] class_loss: 0.1168 s_domain_loss: 0.2749 t_domain_loss: 0.2473 \n","[15/16] class_loss: 0.2246 s_domain_loss: 1.3843 t_domain_loss: 0.0247 \n","[16/16] class_loss: 0.1636 s_domain_loss: 1.7977 t_domain_loss: 0.0734 \n","\n","Epoch 0005 / 0010\n","=================\n","[1/16] class_loss: 0.2441 s_domain_loss: 0.1313 t_domain_loss: 0.8542 \n","[2/16] class_loss: 0.3083 s_domain_loss: 0.2631 t_domain_loss: 0.6177 \n","[3/16] class_loss: 0.2611 s_domain_loss: 0.5141 t_domain_loss: 0.0894 \n","[4/16] class_loss: 0.2890 s_domain_loss: 0.6408 t_domain_loss: 0.1215 \n","[5/16] class_loss: 0.3680 s_domain_loss: 0.2195 t_domain_loss: 0.3147 \n","[6/16] class_loss: 0.4211 s_domain_loss: 0.0710 t_domain_loss: 0.4871 \n","[7/16] class_loss: 0.3515 s_domain_loss: 0.0821 t_domain_loss: 0.1280 \n","[8/16] class_loss: 0.2899 s_domain_loss: 0.5989 t_domain_loss: 0.0318 \n","[9/16] class_loss: 0.2669 s_domain_loss: 0.6152 t_domain_loss: 0.0627 \n","[10/16] class_loss: 0.3043 s_domain_loss: 0.3904 t_domain_loss: 0.2882 \n","[11/16] class_loss: 0.4354 s_domain_loss: 0.0489 t_domain_loss: 1.1437 \n","[12/16] class_loss: 0.2766 s_domain_loss: 0.0504 t_domain_loss: 0.2584 \n","[13/16] class_loss: 0.2816 s_domain_loss: 0.2811 t_domain_loss: 0.0137 \n","[14/16] class_loss: 0.1984 s_domain_loss: 0.4431 t_domain_loss: 0.0023 \n","[15/16] class_loss: 0.2337 s_domain_loss: 0.5492 t_domain_loss: 0.0039 \n","[16/16] class_loss: 0.1545 s_domain_loss: 0.0802 t_domain_loss: 0.0462 \n","\n","Epoch 0006 / 0010\n","=================\n","[1/16] class_loss: 0.2513 s_domain_loss: 0.0617 t_domain_loss: 0.3829 \n","[2/16] class_loss: 0.1552 s_domain_loss: 0.0091 t_domain_loss: 0.3839 \n","[3/16] class_loss: 0.2170 s_domain_loss: 0.0949 t_domain_loss: 0.1012 \n","[4/16] class_loss: 0.1648 s_domain_loss: 0.0522 t_domain_loss: 0.0381 \n","[5/16] class_loss: 0.1160 s_domain_loss: 0.0823 t_domain_loss: 0.0187 \n","[6/16] class_loss: 0.1581 s_domain_loss: 0.0161 t_domain_loss: 0.0129 \n","[7/16] class_loss: 0.1022 s_domain_loss: 0.0561 t_domain_loss: 0.0044 \n","[8/16] class_loss: 0.0951 s_domain_loss: 0.7083 t_domain_loss: 0.0013 \n","[9/16] class_loss: 0.4074 s_domain_loss: 1.4791 t_domain_loss: 0.0284 \n","[10/16] class_loss: 0.2687 s_domain_loss: 0.1549 t_domain_loss: 0.7535 \n","[11/16] class_loss: 0.7945 s_domain_loss: 0.2247 t_domain_loss: 2.5894 \n","[12/16] class_loss: 1.9977 s_domain_loss: 1.3706 t_domain_loss: 0.7957 \n","[13/16] class_loss: 1.2737 s_domain_loss: 1.2425 t_domain_loss: 0.6109 \n","[14/16] class_loss: 2.1572 s_domain_loss: 0.8089 t_domain_loss: 1.2362 \n","[15/16] class_loss: 1.5271 s_domain_loss: 1.0766 t_domain_loss: 0.9515 \n","[16/16] class_loss: 1.6127 s_domain_loss: 1.2503 t_domain_loss: 0.6965 \n","\n","Epoch 0007 / 0010\n","=================\n","[1/16] class_loss: 1.5688 s_domain_loss: 1.0429 t_domain_loss: 0.8755 \n","[2/16] class_loss: 1.5009 s_domain_loss: 0.7328 t_domain_loss: 1.0802 \n","[3/16] class_loss: 1.4847 s_domain_loss: 0.9340 t_domain_loss: 0.7622 \n","[4/16] class_loss: 1.2351 s_domain_loss: 0.8729 t_domain_loss: 0.7308 \n","[5/16] class_loss: 1.3055 s_domain_loss: 0.6213 t_domain_loss: 1.0475 \n","[6/16] class_loss: 1.3762 s_domain_loss: 1.0229 t_domain_loss: 0.5981 \n","[7/16] class_loss: 1.2881 s_domain_loss: 0.7451 t_domain_loss: 0.9717 \n","[8/16] class_loss: 1.1944 s_domain_loss: 0.9507 t_domain_loss: 0.7373 \n","[9/16] class_loss: 1.3312 s_domain_loss: 0.9179 t_domain_loss: 0.6044 \n","[10/16] class_loss: 1.5487 s_domain_loss: 1.0554 t_domain_loss: 0.7510 \n","[11/16] class_loss: 1.7801 s_domain_loss: 0.9203 t_domain_loss: 0.8827 \n","[12/16] class_loss: 1.3456 s_domain_loss: 0.6657 t_domain_loss: 1.2426 \n","[13/16] class_loss: 1.4183 s_domain_loss: 1.7987 t_domain_loss: 0.9181 \n","[14/16] class_loss: 1.5898 s_domain_loss: 1.5222 t_domain_loss: 0.3294 \n","[15/16] class_loss: 1.7163 s_domain_loss: 0.7157 t_domain_loss: 1.2251 \n","[16/16] class_loss: 2.0193 s_domain_loss: 1.2820 t_domain_loss: 1.1836 \n","\n","Epoch 0008 / 0010\n","=================\n","[1/16] class_loss: 2.0318 s_domain_loss: 1.0721 t_domain_loss: 1.3052 \n","[2/16] class_loss: 2.0272 s_domain_loss: 1.0955 t_domain_loss: 2.1819 \n","[3/16] class_loss: 4.3606 s_domain_loss: 1.5151 t_domain_loss: 1.8650 \n","[4/16] class_loss: 2.8138 s_domain_loss: 1.3302 t_domain_loss: 0.9061 \n","[5/16] class_loss: 2.6287 s_domain_loss: 1.4935 t_domain_loss: 1.0569 \n","[6/16] class_loss: 2.0109 s_domain_loss: 1.3945 t_domain_loss: 0.7946 \n","[7/16] class_loss: 19.9328 s_domain_loss: 1.5097 t_domain_loss: 0.9113 \n","[8/16] class_loss: 1.9610 s_domain_loss: 0.6239 t_domain_loss: 0.8735 \n","[9/16] class_loss: 6.4799 s_domain_loss: 0.5045 t_domain_loss: 3.2375 \n","[10/16] class_loss: 2.9241 s_domain_loss: 1.5635 t_domain_loss: 1.2958 \n","[11/16] class_loss: 2.1597 s_domain_loss: 0.5973 t_domain_loss: 0.7992 \n","[12/16] class_loss: 2.0257 s_domain_loss: 0.6054 t_domain_loss: 0.7893 \n","[13/16] class_loss: 2.2388 s_domain_loss: 0.6136 t_domain_loss: 0.7796 \n","[14/16] class_loss: 2.2722 s_domain_loss: 0.6216 t_domain_loss: 0.7702 \n","[15/16] class_loss: 2.1236 s_domain_loss: 0.6296 t_domain_loss: 0.7610 \n","[16/16] class_loss: 2.2917 s_domain_loss: 0.6563 t_domain_loss: 0.7522 \n","\n","Epoch 0009 / 0010\n","=================\n","[1/16] class_loss: 2.2155 s_domain_loss: 0.6455 t_domain_loss: 0.7403 \n","[2/16] class_loss: 3433.6809 s_domain_loss: 13.6421 t_domain_loss: 1.0561 \n","[3/16] class_loss: 653.4143 s_domain_loss: 10.1901 t_domain_loss: 0.0016 \n","[4/16] class_loss: 5101833728.0000 s_domain_loss: 0.9953 t_domain_loss: 0.7203 \n","[5/16] class_loss: nan s_domain_loss: 0.6218 t_domain_loss: 0.7700 \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0010 / 0010\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:15<00:00,  1.04it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.376953125\n","hyperprameters are: LR=0.006 and NUM_EPOCHS = 20\n","\n","Epoch 0001 / 0020\n","=================\n","[1/16] class_loss: 1.9978 s_domain_loss: 0.5641 t_domain_loss: 0.8899 \n","[2/16] class_loss: 1.0830 s_domain_loss: 1.2114 t_domain_loss: 0.3854 \n","[3/16] class_loss: 0.8118 s_domain_loss: 0.2649 t_domain_loss: 1.4993 \n","[4/16] class_loss: 0.4664 s_domain_loss: 1.4305 t_domain_loss: 0.2848 \n","[5/16] class_loss: 0.3699 s_domain_loss: 0.3594 t_domain_loss: 1.2126 \n","[6/16] class_loss: 0.2782 s_domain_loss: 0.9373 t_domain_loss: 0.5030 \n","[7/16] class_loss: 0.2635 s_domain_loss: 0.6299 t_domain_loss: 0.7434 \n","[8/16] class_loss: 0.2407 s_domain_loss: 0.5839 t_domain_loss: 0.7924 \n","[9/16] class_loss: 0.1840 s_domain_loss: 0.9483 t_domain_loss: 0.4805 \n","[10/16] class_loss: 0.1635 s_domain_loss: 0.3483 t_domain_loss: 1.1526 \n","[11/16] class_loss: 0.2695 s_domain_loss: 1.2944 t_domain_loss: 0.2961 \n","[12/16] class_loss: 0.1968 s_domain_loss: 0.2909 t_domain_loss: 1.2903 \n","[13/16] class_loss: 0.1961 s_domain_loss: 1.0959 t_domain_loss: 0.3576 \n","[14/16] class_loss: 0.1298 s_domain_loss: 0.4493 t_domain_loss: 0.8672 \n","[15/16] class_loss: 0.0894 s_domain_loss: 0.7530 t_domain_loss: 0.5520 \n","[16/16] class_loss: 0.0974 s_domain_loss: 0.6175 t_domain_loss: 0.6391 \n","\n","Epoch 0002 / 0020\n","=================\n","[1/16] class_loss: 0.0941 s_domain_loss: 0.5455 t_domain_loss: 0.7258 \n","[2/16] class_loss: 0.0715 s_domain_loss: 0.7884 t_domain_loss: 0.4863 \n","[3/16] class_loss: 0.0679 s_domain_loss: 0.4350 t_domain_loss: 0.8253 \n","[4/16] class_loss: 0.0733 s_domain_loss: 0.8402 t_domain_loss: 0.3964 \n","[5/16] class_loss: 0.0734 s_domain_loss: 0.5016 t_domain_loss: 0.7687 \n","[6/16] class_loss: 0.0873 s_domain_loss: 0.6268 t_domain_loss: 0.5772 \n","[7/16] class_loss: 0.0811 s_domain_loss: 0.6687 t_domain_loss: 0.4920 \n","[8/16] class_loss: 0.0475 s_domain_loss: 0.4307 t_domain_loss: 0.7179 \n","[9/16] class_loss: 0.0557 s_domain_loss: 0.7729 t_domain_loss: 0.3811 \n","[10/16] class_loss: 0.1105 s_domain_loss: 0.3688 t_domain_loss: 0.7589 \n","[11/16] class_loss: 0.0516 s_domain_loss: 0.6071 t_domain_loss: 0.4287 \n","[12/16] class_loss: 0.1056 s_domain_loss: 0.5775 t_domain_loss: 0.4676 \n","[13/16] class_loss: 0.0728 s_domain_loss: 0.3886 t_domain_loss: 0.6691 \n","[14/16] class_loss: 0.0393 s_domain_loss: 0.7389 t_domain_loss: 0.3137 \n","[15/16] class_loss: 0.0508 s_domain_loss: 0.4299 t_domain_loss: 0.6780 \n","[16/16] class_loss: 0.0530 s_domain_loss: 0.4542 t_domain_loss: 0.5232 \n","\n","Epoch 0003 / 0020\n","=================\n","[1/16] class_loss: 0.0423 s_domain_loss: 0.6677 t_domain_loss: 0.2895 \n","[2/16] class_loss: 0.0449 s_domain_loss: 0.3292 t_domain_loss: 0.6467 \n","[3/16] class_loss: 0.0496 s_domain_loss: 0.4493 t_domain_loss: 0.3985 \n","[4/16] class_loss: 0.0502 s_domain_loss: 0.5875 t_domain_loss: 0.3115 \n","[5/16] class_loss: 0.0538 s_domain_loss: 0.2412 t_domain_loss: 0.6510 \n","[6/16] class_loss: 0.0455 s_domain_loss: 0.6011 t_domain_loss: 0.2383 \n","[7/16] class_loss: 0.0295 s_domain_loss: 0.3310 t_domain_loss: 0.3589 \n","[8/16] class_loss: 0.0453 s_domain_loss: 0.2224 t_domain_loss: 0.4077 \n","[9/16] class_loss: 0.0492 s_domain_loss: 0.6302 t_domain_loss: 0.1852 \n","[10/16] class_loss: 0.0515 s_domain_loss: 0.1914 t_domain_loss: 0.5671 \n","[11/16] class_loss: 0.0291 s_domain_loss: 0.4070 t_domain_loss: 0.3070 \n","[12/16] class_loss: 0.0664 s_domain_loss: 0.4275 t_domain_loss: 0.2481 \n","[13/16] class_loss: 0.0438 s_domain_loss: 0.2416 t_domain_loss: 0.3193 \n","[14/16] class_loss: 0.0459 s_domain_loss: 0.5151 t_domain_loss: 0.2604 \n","[15/16] class_loss: 0.0626 s_domain_loss: 0.1201 t_domain_loss: 0.4635 \n","[16/16] class_loss: 0.0915 s_domain_loss: 0.4137 t_domain_loss: 0.1424 \n","\n","Epoch 0004 / 0020\n","=================\n","[1/16] class_loss: 0.0288 s_domain_loss: 0.3067 t_domain_loss: 0.1397 \n","[2/16] class_loss: 0.0538 s_domain_loss: 0.2075 t_domain_loss: 0.2735 \n","[3/16] class_loss: 0.0539 s_domain_loss: 0.1124 t_domain_loss: 0.3489 \n","[4/16] class_loss: 0.0414 s_domain_loss: 0.2692 t_domain_loss: 0.1290 \n","[5/16] class_loss: 0.0623 s_domain_loss: 0.4044 t_domain_loss: 0.0793 \n","[6/16] class_loss: 0.0566 s_domain_loss: 0.0990 t_domain_loss: 0.1905 \n","[7/16] class_loss: 0.0799 s_domain_loss: 0.1065 t_domain_loss: 0.2248 \n","[8/16] class_loss: 0.0703 s_domain_loss: 0.1317 t_domain_loss: 0.1304 \n","[9/16] class_loss: 0.0442 s_domain_loss: 0.1536 t_domain_loss: 0.0850 \n","[10/16] class_loss: 0.1025 s_domain_loss: 0.1648 t_domain_loss: 0.0781 \n","[11/16] class_loss: 0.0393 s_domain_loss: 0.1412 t_domain_loss: 0.0907 \n","[12/16] class_loss: 0.1075 s_domain_loss: 0.0767 t_domain_loss: 0.1349 \n","[13/16] class_loss: 0.0405 s_domain_loss: 0.0813 t_domain_loss: 0.1338 \n","[14/16] class_loss: 0.0651 s_domain_loss: 0.1731 t_domain_loss: 0.0803 \n","[15/16] class_loss: 0.0723 s_domain_loss: 0.1708 t_domain_loss: 0.0684 \n","[16/16] class_loss: 0.1153 s_domain_loss: 0.0398 t_domain_loss: 0.0844 \n","\n","Epoch 0005 / 0020\n","=================\n","[1/16] class_loss: 0.0786 s_domain_loss: 0.0206 t_domain_loss: 0.1088 \n","[2/16] class_loss: 0.0906 s_domain_loss: 0.2394 t_domain_loss: 0.0526 \n","[3/16] class_loss: 0.0702 s_domain_loss: 0.0909 t_domain_loss: 0.0786 \n","[4/16] class_loss: 0.1122 s_domain_loss: 0.2838 t_domain_loss: 0.0945 \n","[5/16] class_loss: 0.1041 s_domain_loss: 0.3581 t_domain_loss: 0.1754 \n","[6/16] class_loss: 0.0681 s_domain_loss: 0.0071 t_domain_loss: 0.4233 \n","[7/16] class_loss: 0.0480 s_domain_loss: 0.0246 t_domain_loss: 0.1054 \n","[8/16] class_loss: 0.0736 s_domain_loss: 0.1941 t_domain_loss: 0.0188 \n","[9/16] class_loss: 0.1182 s_domain_loss: 0.2344 t_domain_loss: 0.0098 \n","[10/16] class_loss: 0.0498 s_domain_loss: 0.2099 t_domain_loss: 0.0211 \n","[11/16] class_loss: 0.1352 s_domain_loss: 0.0862 t_domain_loss: 0.0626 \n","[12/16] class_loss: 0.0830 s_domain_loss: 0.0065 t_domain_loss: 0.1957 \n","[13/16] class_loss: 0.0436 s_domain_loss: 0.0089 t_domain_loss: 0.1931 \n","[14/16] class_loss: 0.0796 s_domain_loss: 0.0147 t_domain_loss: 0.0720 \n","[15/16] class_loss: 0.0942 s_domain_loss: 0.0520 t_domain_loss: 0.0181 \n","[16/16] class_loss: 0.0527 s_domain_loss: 0.0360 t_domain_loss: 0.0048 \n","\n","Epoch 0006 / 0020\n","=================\n","[1/16] class_loss: 0.0634 s_domain_loss: 0.1377 t_domain_loss: 0.0025 \n","[2/16] class_loss: 0.0350 s_domain_loss: 0.0960 t_domain_loss: 0.0020 \n","[3/16] class_loss: 0.0538 s_domain_loss: 0.6257 t_domain_loss: 0.0027 \n","[4/16] class_loss: 0.0544 s_domain_loss: 0.0089 t_domain_loss: 0.0374 \n","[5/16] class_loss: 0.0493 s_domain_loss: 0.0019 t_domain_loss: 0.3202 \n","[6/16] class_loss: 0.1033 s_domain_loss: 0.0007 t_domain_loss: 0.2709 \n","[7/16] class_loss: 0.0645 s_domain_loss: 0.0515 t_domain_loss: 0.0753 \n","[8/16] class_loss: 0.0384 s_domain_loss: 0.1239 t_domain_loss: 0.0143 \n","[9/16] class_loss: 0.0681 s_domain_loss: 0.0284 t_domain_loss: 0.0055 \n","[10/16] class_loss: 0.0791 s_domain_loss: 0.2903 t_domain_loss: 0.0027 \n","[11/16] class_loss: 0.0646 s_domain_loss: 0.0408 t_domain_loss: 0.0024 \n","[12/16] class_loss: 0.0594 s_domain_loss: 0.0083 t_domain_loss: 0.0037 \n","[13/16] class_loss: 0.0336 s_domain_loss: 0.1815 t_domain_loss: 0.0033 \n","[14/16] class_loss: 0.0519 s_domain_loss: 0.0021 t_domain_loss: 0.0128 \n","[15/16] class_loss: 0.0393 s_domain_loss: 0.0167 t_domain_loss: 0.0420 \n","[16/16] class_loss: 0.0541 s_domain_loss: 0.3393 t_domain_loss: 0.0334 \n","\n","Epoch 0007 / 0020\n","=================\n","[1/16] class_loss: 0.0728 s_domain_loss: 0.0282 t_domain_loss: 0.1664 \n","[2/16] class_loss: 0.3356 s_domain_loss: 1.7801 t_domain_loss: 0.3594 \n","[3/16] class_loss: 0.5991 s_domain_loss: 0.5737 t_domain_loss: 0.9286 \n","[4/16] class_loss: 0.5167 s_domain_loss: 0.8580 t_domain_loss: 0.7962 \n","[5/16] class_loss: 0.7719 s_domain_loss: 2.1608 t_domain_loss: 0.3727 \n","[6/16] class_loss: 0.9083 s_domain_loss: 2.4191 t_domain_loss: 2.0558 \n","[7/16] class_loss: 2.3879 s_domain_loss: 0.8589 t_domain_loss: 1.0564 \n","[8/16] class_loss: 1.7263 s_domain_loss: 1.1930 t_domain_loss: 0.5714 \n","[9/16] class_loss: 1.5422 s_domain_loss: 0.8923 t_domain_loss: 0.8058 \n","[10/16] class_loss: 1.4268 s_domain_loss: 0.6852 t_domain_loss: 1.1549 \n","[11/16] class_loss: 1.4097 s_domain_loss: 1.3137 t_domain_loss: 0.4680 \n","[12/16] class_loss: 1.4641 s_domain_loss: 0.7174 t_domain_loss: 0.9147 \n","[13/16] class_loss: 1.2354 s_domain_loss: 0.8226 t_domain_loss: 0.9020 \n","[14/16] class_loss: 1.5421 s_domain_loss: 1.0897 t_domain_loss: 0.7111 \n","[15/16] class_loss: 1.2390 s_domain_loss: 0.8778 t_domain_loss: 0.7291 \n","[16/16] class_loss: 1.7941 s_domain_loss: 0.6651 t_domain_loss: 0.8326 \n","\n","Epoch 0008 / 0020\n","=================\n","[1/16] class_loss: 6.4384 s_domain_loss: 0.9692 t_domain_loss: 0.7549 \n","[2/16] class_loss: 13.5536 s_domain_loss: 0.8238 t_domain_loss: 1.2839 \n","[3/16] class_loss: 2.9016 s_domain_loss: 1.0004 t_domain_loss: 0.8378 \n","[4/16] class_loss: 2.1336 s_domain_loss: 1.2120 t_domain_loss: 0.6811 \n","[5/16] class_loss: 2.1140 s_domain_loss: 0.8306 t_domain_loss: 1.3462 \n","[6/16] class_loss: 41.8975 s_domain_loss: 1.0445 t_domain_loss: 1.3420 \n","[7/16] class_loss: 4962.8096 s_domain_loss: 4.3097 t_domain_loss: 3.4235 \n","[8/16] class_loss: 26842.1973 s_domain_loss: 1.8083 t_domain_loss: 0.4693 \n","[9/16] class_loss: 291137646493696.0000 s_domain_loss: 0.4864 t_domain_loss: 1.7923 \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0009 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0010 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0011 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0012 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0013 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0014 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0015 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0016 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0017 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0018 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0019 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0020 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:15<00:00,  1.05it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.376953125\n","hyperprameters are: LR=0.006 and NUM_EPOCHS = 30\n","\n","Epoch 0001 / 0030\n","=================\n","[1/16] class_loss: 2.1102 s_domain_loss: 0.6419 t_domain_loss: 0.8268 \n","[2/16] class_loss: 1.1490 s_domain_loss: 0.9144 t_domain_loss: 0.5577 \n","[3/16] class_loss: 0.8005 s_domain_loss: 0.4688 t_domain_loss: 1.0269 \n","[4/16] class_loss: 0.6316 s_domain_loss: 1.1298 t_domain_loss: 0.4122 \n","[5/16] class_loss: 0.3691 s_domain_loss: 0.3569 t_domain_loss: 1.2375 \n","[6/16] class_loss: 0.2825 s_domain_loss: 1.2201 t_domain_loss: 0.3741 \n","[7/16] class_loss: 0.2351 s_domain_loss: 0.3588 t_domain_loss: 1.2072 \n","[8/16] class_loss: 0.2929 s_domain_loss: 1.0686 t_domain_loss: 0.4225 \n","[9/16] class_loss: 0.2067 s_domain_loss: 0.4517 t_domain_loss: 0.9698 \n","[10/16] class_loss: 0.2822 s_domain_loss: 0.8845 t_domain_loss: 0.5145 \n","[11/16] class_loss: 0.2424 s_domain_loss: 0.5236 t_domain_loss: 0.8374 \n","[12/16] class_loss: 0.1681 s_domain_loss: 0.8997 t_domain_loss: 0.4995 \n","[13/16] class_loss: 0.1187 s_domain_loss: 0.4245 t_domain_loss: 0.9916 \n","[14/16] class_loss: 0.2197 s_domain_loss: 1.0215 t_domain_loss: 0.4040 \n","[15/16] class_loss: 0.1917 s_domain_loss: 0.3853 t_domain_loss: 1.0306 \n","[16/16] class_loss: 0.1042 s_domain_loss: 1.0715 t_domain_loss: 0.3615 \n","\n","Epoch 0002 / 0030\n","=================\n","[1/16] class_loss: 0.1189 s_domain_loss: 0.3409 t_domain_loss: 1.0623 \n","[2/16] class_loss: 0.1316 s_domain_loss: 0.9773 t_domain_loss: 0.3860 \n","[3/16] class_loss: 0.0914 s_domain_loss: 0.4128 t_domain_loss: 0.8550 \n","[4/16] class_loss: 0.1002 s_domain_loss: 0.7754 t_domain_loss: 0.4517 \n","[5/16] class_loss: 0.1176 s_domain_loss: 0.5013 t_domain_loss: 0.7054 \n","[6/16] class_loss: 0.1017 s_domain_loss: 0.6702 t_domain_loss: 0.5077 \n","[7/16] class_loss: 0.0697 s_domain_loss: 0.4964 t_domain_loss: 0.6587 \n","[8/16] class_loss: 0.0873 s_domain_loss: 0.7346 t_domain_loss: 0.4267 \n","[9/16] class_loss: 0.1029 s_domain_loss: 0.4478 t_domain_loss: 0.7746 \n","[10/16] class_loss: 0.0744 s_domain_loss: 0.5843 t_domain_loss: 0.5083 \n","[11/16] class_loss: 0.0662 s_domain_loss: 0.5949 t_domain_loss: 0.4731 \n","[12/16] class_loss: 0.0798 s_domain_loss: 0.5104 t_domain_loss: 0.6326 \n","[13/16] class_loss: 0.0563 s_domain_loss: 0.5093 t_domain_loss: 0.5138 \n","[14/16] class_loss: 0.0861 s_domain_loss: 0.6970 t_domain_loss: 0.3773 \n","[15/16] class_loss: 0.0938 s_domain_loss: 0.3049 t_domain_loss: 0.7928 \n","[16/16] class_loss: 0.0455 s_domain_loss: 0.7147 t_domain_loss: 0.2991 \n","\n","Epoch 0003 / 0030\n","=================\n","[1/16] class_loss: 0.0805 s_domain_loss: 0.4576 t_domain_loss: 0.4681 \n","[2/16] class_loss: 0.0760 s_domain_loss: 0.3210 t_domain_loss: 0.6521 \n","[3/16] class_loss: 0.0752 s_domain_loss: 0.6987 t_domain_loss: 0.2520 \n","[4/16] class_loss: 0.1031 s_domain_loss: 0.3525 t_domain_loss: 0.5093 \n","[5/16] class_loss: 0.0409 s_domain_loss: 0.3444 t_domain_loss: 0.4864 \n","[6/16] class_loss: 0.0379 s_domain_loss: 0.5573 t_domain_loss: 0.2349 \n","[7/16] class_loss: 0.0642 s_domain_loss: 0.4374 t_domain_loss: 0.4320 \n","[8/16] class_loss: 0.0491 s_domain_loss: 0.2369 t_domain_loss: 0.6165 \n","[9/16] class_loss: 0.0595 s_domain_loss: 0.6296 t_domain_loss: 0.1655 \n","[10/16] class_loss: 0.0717 s_domain_loss: 0.4341 t_domain_loss: 0.2409 \n","[11/16] class_loss: 0.0453 s_domain_loss: 0.1588 t_domain_loss: 0.6439 \n","[12/16] class_loss: 0.0580 s_domain_loss: 0.4491 t_domain_loss: 0.2117 \n","[13/16] class_loss: 0.0776 s_domain_loss: 0.3208 t_domain_loss: 0.1707 \n","[14/16] class_loss: 0.0537 s_domain_loss: 0.2096 t_domain_loss: 0.2604 \n","[15/16] class_loss: 0.0456 s_domain_loss: 0.2689 t_domain_loss: 0.2299 \n","[16/16] class_loss: 0.0637 s_domain_loss: 0.1798 t_domain_loss: 0.1898 \n","\n","Epoch 0004 / 0030\n","=================\n","[1/16] class_loss: 0.0738 s_domain_loss: 0.6145 t_domain_loss: 0.1317 \n","[2/16] class_loss: 0.0615 s_domain_loss: 0.0574 t_domain_loss: 0.5299 \n","[3/16] class_loss: 0.0607 s_domain_loss: 0.1842 t_domain_loss: 0.2177 \n","[4/16] class_loss: 0.0729 s_domain_loss: 0.4878 t_domain_loss: 0.0603 \n","[5/16] class_loss: 0.0821 s_domain_loss: 0.2907 t_domain_loss: 0.0733 \n","[6/16] class_loss: 0.2329 s_domain_loss: 0.8032 t_domain_loss: 0.2122 \n","[7/16] class_loss: 0.0617 s_domain_loss: 0.0163 t_domain_loss: 1.5567 \n","[8/16] class_loss: 0.3916 s_domain_loss: 0.8150 t_domain_loss: 0.1730 \n","[9/16] class_loss: 0.2537 s_domain_loss: 0.6645 t_domain_loss: 0.0470 \n","[10/16] class_loss: 0.1890 s_domain_loss: 0.3688 t_domain_loss: 0.0831 \n","[11/16] class_loss: 0.1644 s_domain_loss: 0.1686 t_domain_loss: 0.3082 \n","[12/16] class_loss: 0.1338 s_domain_loss: 0.0312 t_domain_loss: 0.4137 \n","[13/16] class_loss: 0.1306 s_domain_loss: 0.2761 t_domain_loss: 0.0825 \n","[14/16] class_loss: 0.1844 s_domain_loss: 1.1007 t_domain_loss: 0.0302 \n","[15/16] class_loss: 0.3661 s_domain_loss: 0.1418 t_domain_loss: 0.2396 \n","[16/16] class_loss: 0.2310 s_domain_loss: 0.2498 t_domain_loss: 0.6757 \n","\n","Epoch 0005 / 0030\n","=================\n","[1/16] class_loss: 0.2679 s_domain_loss: 0.1310 t_domain_loss: 0.2470 \n","[2/16] class_loss: 0.1614 s_domain_loss: 0.3133 t_domain_loss: 0.0323 \n","[3/16] class_loss: 0.2844 s_domain_loss: 0.3509 t_domain_loss: 0.0143 \n","[4/16] class_loss: 0.2252 s_domain_loss: 0.2771 t_domain_loss: 0.0281 \n","[5/16] class_loss: 0.1544 s_domain_loss: 0.0650 t_domain_loss: 0.1573 \n","[6/16] class_loss: 0.1161 s_domain_loss: 0.0116 t_domain_loss: 0.2939 \n","[7/16] class_loss: 0.1258 s_domain_loss: 0.0535 t_domain_loss: 0.1875 \n","[8/16] class_loss: 0.1737 s_domain_loss: 0.0737 t_domain_loss: 0.0432 \n","[9/16] class_loss: 0.0802 s_domain_loss: 0.3228 t_domain_loss: 0.0125 \n","[10/16] class_loss: 0.0872 s_domain_loss: 0.1621 t_domain_loss: 0.0623 \n","[11/16] class_loss: 0.1097 s_domain_loss: 0.3562 t_domain_loss: 0.0777 \n","[12/16] class_loss: 0.1351 s_domain_loss: 0.0118 t_domain_loss: 0.1471 \n","[13/16] class_loss: 0.1723 s_domain_loss: 0.0483 t_domain_loss: 0.1868 \n","[14/16] class_loss: 0.1857 s_domain_loss: 0.2394 t_domain_loss: 0.1132 \n","[15/16] class_loss: 0.1929 s_domain_loss: 0.1510 t_domain_loss: 0.1140 \n","[16/16] class_loss: 0.1194 s_domain_loss: 0.0459 t_domain_loss: 0.1239 \n","\n","Epoch 0006 / 0030\n","=================\n","[1/16] class_loss: 0.1526 s_domain_loss: 0.1871 t_domain_loss: 0.0458 \n","[2/16] class_loss: 0.1272 s_domain_loss: 0.0945 t_domain_loss: 0.0541 \n","[3/16] class_loss: 0.0766 s_domain_loss: 0.0911 t_domain_loss: 0.0579 \n","[4/16] class_loss: 0.1139 s_domain_loss: 0.0521 t_domain_loss: 0.0436 \n","[5/16] class_loss: 0.1461 s_domain_loss: 0.0743 t_domain_loss: 0.0401 \n","[6/16] class_loss: 0.1614 s_domain_loss: 0.1061 t_domain_loss: 0.0389 \n","[7/16] class_loss: 0.1597 s_domain_loss: 0.0580 t_domain_loss: 0.0389 \n","[8/16] class_loss: 0.1433 s_domain_loss: 0.0631 t_domain_loss: 0.0333 \n","[9/16] class_loss: 0.1403 s_domain_loss: 0.0502 t_domain_loss: 0.0363 \n","[10/16] class_loss: 0.1048 s_domain_loss: 0.0313 t_domain_loss: 0.0483 \n","[11/16] class_loss: 0.0993 s_domain_loss: 0.0576 t_domain_loss: 0.0418 \n","[12/16] class_loss: 0.0912 s_domain_loss: 0.0208 t_domain_loss: 0.0418 \n","[13/16] class_loss: 0.1050 s_domain_loss: 0.0093 t_domain_loss: 0.0185 \n","[14/16] class_loss: 0.0859 s_domain_loss: 0.0212 t_domain_loss: 0.0121 \n","[15/16] class_loss: 0.0709 s_domain_loss: 0.0685 t_domain_loss: 0.0097 \n","[16/16] class_loss: 0.0664 s_domain_loss: 0.1152 t_domain_loss: 0.0238 \n","\n","Epoch 0007 / 0030\n","=================\n","[1/16] class_loss: 0.0603 s_domain_loss: 0.0174 t_domain_loss: 0.0254 \n","[2/16] class_loss: 0.0583 s_domain_loss: 0.0429 t_domain_loss: 0.0306 \n","[3/16] class_loss: 0.0354 s_domain_loss: 0.0321 t_domain_loss: 0.0397 \n","[4/16] class_loss: 0.0901 s_domain_loss: 0.0089 t_domain_loss: 0.0333 \n","[5/16] class_loss: 0.0543 s_domain_loss: 0.0024 t_domain_loss: 0.0280 \n","[6/16] class_loss: 0.0395 s_domain_loss: 0.0167 t_domain_loss: 0.0187 \n","[7/16] class_loss: 0.0580 s_domain_loss: 0.0832 t_domain_loss: 0.0162 \n","[8/16] class_loss: 0.0454 s_domain_loss: 0.0077 t_domain_loss: 0.0216 \n","[9/16] class_loss: 0.0298 s_domain_loss: 0.0062 t_domain_loss: 0.0158 \n","[10/16] class_loss: 0.0300 s_domain_loss: 0.1729 t_domain_loss: 0.0152 \n","[11/16] class_loss: 0.0682 s_domain_loss: 0.0253 t_domain_loss: 0.0240 \n","[12/16] class_loss: 0.0957 s_domain_loss: 0.0212 t_domain_loss: 0.0707 \n","[13/16] class_loss: 0.0332 s_domain_loss: 0.0039 t_domain_loss: 0.0530 \n","[14/16] class_loss: 0.0385 s_domain_loss: 0.0176 t_domain_loss: 0.0436 \n","[15/16] class_loss: 0.0491 s_domain_loss: 0.0019 t_domain_loss: 0.0323 \n","[16/16] class_loss: 0.0245 s_domain_loss: 0.0012 t_domain_loss: 0.0219 \n","\n","Epoch 0008 / 0030\n","=================\n","[1/16] class_loss: 0.0519 s_domain_loss: 0.0036 t_domain_loss: 0.0101 \n","[2/16] class_loss: 0.0567 s_domain_loss: 0.0013 t_domain_loss: 0.0048 \n","[3/16] class_loss: 0.0258 s_domain_loss: 0.0009 t_domain_loss: 0.0028 \n","[4/16] class_loss: 0.0197 s_domain_loss: 0.0335 t_domain_loss: 0.0017 \n","[5/16] class_loss: 0.0449 s_domain_loss: 0.0286 t_domain_loss: 0.0013 \n","[6/16] class_loss: 0.0255 s_domain_loss: 0.0269 t_domain_loss: 0.0012 \n","[7/16] class_loss: 0.0230 s_domain_loss: 0.0288 t_domain_loss: 0.0009 \n","[8/16] class_loss: 0.0330 s_domain_loss: 0.0049 t_domain_loss: 0.0013 \n","[9/16] class_loss: 0.0148 s_domain_loss: 0.0539 t_domain_loss: 0.0012 \n","[10/16] class_loss: 0.0226 s_domain_loss: 0.0052 t_domain_loss: 0.0032 \n","[11/16] class_loss: 0.0222 s_domain_loss: 0.0012 t_domain_loss: 0.0031 \n","[12/16] class_loss: 0.0143 s_domain_loss: 0.0067 t_domain_loss: 0.0052 \n","[13/16] class_loss: 0.0190 s_domain_loss: 0.0099 t_domain_loss: 0.0087 \n","[14/16] class_loss: 0.0122 s_domain_loss: 0.0083 t_domain_loss: 0.0096 \n","[15/16] class_loss: 0.0128 s_domain_loss: 0.0008 t_domain_loss: 0.0121 \n","[16/16] class_loss: 0.0270 s_domain_loss: 0.0164 t_domain_loss: 0.0131 \n","\n","Epoch 0009 / 0030\n","=================\n","[1/16] class_loss: 0.0187 s_domain_loss: 0.0054 t_domain_loss: 0.0171 \n","[2/16] class_loss: 0.0155 s_domain_loss: 0.0065 t_domain_loss: 0.0152 \n","[3/16] class_loss: 0.0128 s_domain_loss: 0.0009 t_domain_loss: 0.0154 \n","[4/16] class_loss: 0.0063 s_domain_loss: 0.0088 t_domain_loss: 0.0114 \n","[5/16] class_loss: 0.0097 s_domain_loss: 0.0048 t_domain_loss: 0.0091 \n","[6/16] class_loss: 0.0117 s_domain_loss: 0.0019 t_domain_loss: 0.0055 \n","[7/16] class_loss: 0.0106 s_domain_loss: 0.0003 t_domain_loss: 0.0050 \n","[8/16] class_loss: 0.0088 s_domain_loss: 0.0060 t_domain_loss: 0.0045 \n","[9/16] class_loss: 0.0098 s_domain_loss: 0.0095 t_domain_loss: 0.0032 \n","[10/16] class_loss: 0.0157 s_domain_loss: 0.0051 t_domain_loss: 0.0039 \n","[11/16] class_loss: 0.0105 s_domain_loss: 0.0159 t_domain_loss: 0.0021 \n","[12/16] class_loss: 0.0091 s_domain_loss: 0.0004 t_domain_loss: 0.0023 \n","[13/16] class_loss: 0.0147 s_domain_loss: 0.0057 t_domain_loss: 0.0025 \n","[14/16] class_loss: 0.0065 s_domain_loss: 0.0006 t_domain_loss: 0.0029 \n","[15/16] class_loss: 0.0056 s_domain_loss: 0.0007 t_domain_loss: 0.0024 \n","[16/16] class_loss: 0.0145 s_domain_loss: 0.0112 t_domain_loss: 0.0025 \n","\n","Epoch 0010 / 0030\n","=================\n","[1/16] class_loss: 0.0048 s_domain_loss: 0.0074 t_domain_loss: 0.0027 \n","[2/16] class_loss: 0.0078 s_domain_loss: 0.0006 t_domain_loss: 0.0031 \n","[3/16] class_loss: 0.0064 s_domain_loss: 0.0088 t_domain_loss: 0.0029 \n","[4/16] class_loss: 0.0206 s_domain_loss: 0.0015 t_domain_loss: 0.0030 \n","[5/16] class_loss: 0.0044 s_domain_loss: 0.0754 t_domain_loss: 0.0030 \n","[6/16] class_loss: 0.0028 s_domain_loss: 0.0001 t_domain_loss: 0.0039 \n","[7/16] class_loss: 0.0054 s_domain_loss: 0.0032 t_domain_loss: 0.0053 \n","[8/16] class_loss: 0.0026 s_domain_loss: 0.0003 t_domain_loss: 0.0084 \n","[9/16] class_loss: 0.0028 s_domain_loss: 0.0037 t_domain_loss: 0.0099 \n","[10/16] class_loss: 0.0028 s_domain_loss: 0.0009 t_domain_loss: 0.0134 \n","[11/16] class_loss: 0.0039 s_domain_loss: 0.0086 t_domain_loss: 0.0105 \n","[12/16] class_loss: 0.0051 s_domain_loss: 0.0032 t_domain_loss: 0.0120 \n","[13/16] class_loss: 0.0065 s_domain_loss: 0.0003 t_domain_loss: 0.0127 \n","[14/16] class_loss: 0.0026 s_domain_loss: 0.0012 t_domain_loss: 0.0114 \n","[15/16] class_loss: 0.0081 s_domain_loss: 0.0011 t_domain_loss: 0.0082 \n","[16/16] class_loss: 0.0048 s_domain_loss: 0.0003 t_domain_loss: 0.0068 \n","\n","Epoch 0011 / 0030\n","=================\n","[1/16] class_loss: 0.0063 s_domain_loss: 0.0031 t_domain_loss: 0.0055 \n","[2/16] class_loss: 0.0064 s_domain_loss: 0.0089 t_domain_loss: 0.0043 \n","[3/16] class_loss: 0.0048 s_domain_loss: 0.0018 t_domain_loss: 0.0031 \n","[4/16] class_loss: 0.0055 s_domain_loss: 0.0055 t_domain_loss: 0.0030 \n","[5/16] class_loss: 0.0049 s_domain_loss: 0.0014 t_domain_loss: 0.0024 \n","[6/16] class_loss: 0.0101 s_domain_loss: 0.0171 t_domain_loss: 0.0020 \n","[7/16] class_loss: 0.0022 s_domain_loss: 0.0014 t_domain_loss: 0.0016 \n","[8/16] class_loss: 0.0034 s_domain_loss: 0.0029 t_domain_loss: 0.0016 \n","[9/16] class_loss: 0.0031 s_domain_loss: 0.0040 t_domain_loss: 0.0015 \n","[10/16] class_loss: 0.0033 s_domain_loss: 0.0032 t_domain_loss: 0.0022 \n","[11/16] class_loss: 0.0054 s_domain_loss: 0.0007 t_domain_loss: 0.0014 \n","[12/16] class_loss: 0.0031 s_domain_loss: 0.0059 t_domain_loss: 0.0013 \n","[13/16] class_loss: 0.0041 s_domain_loss: 0.0009 t_domain_loss: 0.0016 \n","[14/16] class_loss: 0.0027 s_domain_loss: 0.0004 t_domain_loss: 0.0016 \n","[15/16] class_loss: 0.0062 s_domain_loss: 0.0032 t_domain_loss: 0.0016 \n","[16/16] class_loss: 0.0035 s_domain_loss: 0.0010 t_domain_loss: 0.0014 \n","\n","Epoch 0012 / 0030\n","=================\n","[1/16] class_loss: 0.0042 s_domain_loss: 0.0091 t_domain_loss: 0.0017 \n","[2/16] class_loss: 0.0024 s_domain_loss: 0.0012 t_domain_loss: 0.0018 \n","[3/16] class_loss: 0.0036 s_domain_loss: 0.0019 t_domain_loss: 0.0017 \n","[4/16] class_loss: 0.0020 s_domain_loss: 0.0043 t_domain_loss: 0.0022 \n","[5/16] class_loss: 0.0029 s_domain_loss: 0.0009 t_domain_loss: 0.0020 \n","[6/16] class_loss: 0.0035 s_domain_loss: 0.0011 t_domain_loss: 0.0019 \n","[7/16] class_loss: 0.0027 s_domain_loss: 0.0012 t_domain_loss: 0.0018 \n","[8/16] class_loss: 0.0026 s_domain_loss: 0.0006 t_domain_loss: 0.0018 \n","[9/16] class_loss: 0.0019 s_domain_loss: 0.0030 t_domain_loss: 0.0018 \n","[10/16] class_loss: 0.0016 s_domain_loss: 0.0008 t_domain_loss: 0.0025 \n","[11/16] class_loss: 0.0039 s_domain_loss: 0.0026 t_domain_loss: 0.0016 \n","[12/16] class_loss: 0.0013 s_domain_loss: 0.0005 t_domain_loss: 0.0017 \n","[13/16] class_loss: 0.0023 s_domain_loss: 0.0006 t_domain_loss: 0.0019 \n","[14/16] class_loss: 0.0037 s_domain_loss: 0.0006 t_domain_loss: 0.0019 \n","[15/16] class_loss: 0.0017 s_domain_loss: 0.0015 t_domain_loss: 0.0018 \n","[16/16] class_loss: 0.0031 s_domain_loss: 0.0025 t_domain_loss: 0.0015 \n","\n","Epoch 0013 / 0030\n","=================\n","[1/16] class_loss: 0.0079 s_domain_loss: 0.0009 t_domain_loss: 0.0018 \n","[2/16] class_loss: 0.0021 s_domain_loss: 0.0077 t_domain_loss: 0.0017 \n","[3/16] class_loss: 0.0014 s_domain_loss: 0.0007 t_domain_loss: 0.0017 \n","[4/16] class_loss: 0.0017 s_domain_loss: 0.0002 t_domain_loss: 0.0020 \n","[5/16] class_loss: 0.0020 s_domain_loss: 0.0004 t_domain_loss: 0.0018 \n","[6/16] class_loss: 0.0040 s_domain_loss: 0.0039 t_domain_loss: 0.0016 \n","[7/16] class_loss: 0.0034 s_domain_loss: 0.0007 t_domain_loss: 0.0014 \n","[8/16] class_loss: 0.0035 s_domain_loss: 0.0034 t_domain_loss: 0.0015 \n","[9/16] class_loss: 0.0016 s_domain_loss: 0.0043 t_domain_loss: 0.0015 \n","[10/16] class_loss: 0.0012 s_domain_loss: 0.0004 t_domain_loss: 0.0020 \n","[11/16] class_loss: 0.0030 s_domain_loss: 0.0072 t_domain_loss: 0.0014 \n","[12/16] class_loss: 0.0039 s_domain_loss: 0.0005 t_domain_loss: 0.0015 \n","[13/16] class_loss: 0.0006 s_domain_loss: 0.0009 t_domain_loss: 0.0017 \n","[14/16] class_loss: 0.0018 s_domain_loss: 0.0001 t_domain_loss: 0.0017 \n","[15/16] class_loss: 0.0017 s_domain_loss: 0.0012 t_domain_loss: 0.0017 \n","[16/16] class_loss: 0.0019 s_domain_loss: 0.0005 t_domain_loss: 0.0014 \n","\n","Epoch 0014 / 0030\n","=================\n","[1/16] class_loss: 0.0012 s_domain_loss: 0.0018 t_domain_loss: 0.0018 \n","[2/16] class_loss: 0.0018 s_domain_loss: 0.0030 t_domain_loss: 0.0018 \n","[3/16] class_loss: 0.0016 s_domain_loss: 0.0005 t_domain_loss: 0.0017 \n","[4/16] class_loss: 0.0017 s_domain_loss: 0.0013 t_domain_loss: 0.0020 \n","[5/16] class_loss: 0.0016 s_domain_loss: 0.0017 t_domain_loss: 0.0018 \n","[6/16] class_loss: 0.0019 s_domain_loss: 0.0003 t_domain_loss: 0.0016 \n","[7/16] class_loss: 0.0024 s_domain_loss: 0.0027 t_domain_loss: 0.0014 \n","[8/16] class_loss: 0.0008 s_domain_loss: 0.0032 t_domain_loss: 0.0015 \n","[9/16] class_loss: 0.0013 s_domain_loss: 0.0004 t_domain_loss: 0.0015 \n","[10/16] class_loss: 0.0013 s_domain_loss: 0.0014 t_domain_loss: 0.0020 \n","[11/16] class_loss: 0.0031 s_domain_loss: 0.0004 t_domain_loss: 0.0013 \n","[12/16] class_loss: 0.0010 s_domain_loss: 0.0026 t_domain_loss: 0.0013 \n","[13/16] class_loss: 0.0009 s_domain_loss: 0.0012 t_domain_loss: 0.0015 \n","[14/16] class_loss: 0.0025 s_domain_loss: 0.0026 t_domain_loss: 0.0015 \n","[15/16] class_loss: 0.0014 s_domain_loss: 0.0006 t_domain_loss: 0.0015 \n","[16/16] class_loss: 0.0021 s_domain_loss: 0.0023 t_domain_loss: 0.0012 \n","\n","Epoch 0015 / 0030\n","=================\n","[1/16] class_loss: 0.0023 s_domain_loss: 0.0012 t_domain_loss: 0.0016 \n","[2/16] class_loss: 0.0010 s_domain_loss: 0.0003 t_domain_loss: 0.0015 \n","[3/16] class_loss: 0.0028 s_domain_loss: 0.0013 t_domain_loss: 0.0014 \n","[4/16] class_loss: 0.0010 s_domain_loss: 0.0005 t_domain_loss: 0.0016 \n","[5/16] class_loss: 0.0040 s_domain_loss: 0.0019 t_domain_loss: 0.0014 \n","[6/16] class_loss: 0.0014 s_domain_loss: 0.0005 t_domain_loss: 0.0013 \n","[7/16] class_loss: 0.0016 s_domain_loss: 0.0016 t_domain_loss: 0.0011 \n","[8/16] class_loss: 0.0014 s_domain_loss: 0.0010 t_domain_loss: 0.0012 \n","[9/16] class_loss: 0.0022 s_domain_loss: 0.0004 t_domain_loss: 0.0012 \n","[10/16] class_loss: 0.0016 s_domain_loss: 0.0007 t_domain_loss: 0.0015 \n","[11/16] class_loss: 0.0022 s_domain_loss: 0.0001 t_domain_loss: 0.0010 \n","[12/16] class_loss: 0.0011 s_domain_loss: 0.0019 t_domain_loss: 0.0010 \n","[13/16] class_loss: 0.0012 s_domain_loss: 0.0013 t_domain_loss: 0.0011 \n","[14/16] class_loss: 0.0012 s_domain_loss: 0.0009 t_domain_loss: 0.0011 \n","[15/16] class_loss: 0.0016 s_domain_loss: 0.0012 t_domain_loss: 0.0011 \n","[16/16] class_loss: 0.0079 s_domain_loss: 0.0153 t_domain_loss: 0.0009 \n","\n","Epoch 0016 / 0030\n","=================\n","[1/16] class_loss: 0.0007 s_domain_loss: 0.0032 t_domain_loss: 0.0012 \n","[2/16] class_loss: 0.0013 s_domain_loss: 0.0015 t_domain_loss: 0.0012 \n","[3/16] class_loss: 0.0012 s_domain_loss: 0.0019 t_domain_loss: 0.0012 \n","[4/16] class_loss: 0.0017 s_domain_loss: 0.0003 t_domain_loss: 0.0015 \n","[5/16] class_loss: 0.0025 s_domain_loss: 0.0069 t_domain_loss: 0.0014 \n","[6/16] class_loss: 0.0039 s_domain_loss: 0.0007 t_domain_loss: 0.0014 \n","[7/16] class_loss: 0.0037 s_domain_loss: 0.0357 t_domain_loss: 0.0013 \n","[8/16] class_loss: 0.0016 s_domain_loss: 0.0002 t_domain_loss: 0.0019 \n","[9/16] class_loss: 0.0015 s_domain_loss: 0.0010 t_domain_loss: 0.0023 \n","[10/16] class_loss: 0.0009 s_domain_loss: 0.0044 t_domain_loss: 0.0034 \n","[11/16] class_loss: 0.0043 s_domain_loss: 0.0004 t_domain_loss: 0.0030 \n","[12/16] class_loss: 0.0030 s_domain_loss: 0.0008 t_domain_loss: 0.0038 \n","[13/16] class_loss: 0.0027 s_domain_loss: 0.0037 t_domain_loss: 0.0044 \n","[14/16] class_loss: 0.0110 s_domain_loss: 0.0121 t_domain_loss: 0.0051 \n","[15/16] class_loss: 0.0021 s_domain_loss: 0.0002 t_domain_loss: 0.0054 \n","[16/16] class_loss: 0.0015 s_domain_loss: 0.0006 t_domain_loss: 0.0050 \n","\n","Epoch 0017 / 0030\n","=================\n","[1/16] class_loss: 0.0019 s_domain_loss: 0.0001 t_domain_loss: 0.0066 \n","[2/16] class_loss: 0.0010 s_domain_loss: 0.0006 t_domain_loss: 0.0065 \n","[3/16] class_loss: 0.0014 s_domain_loss: 0.0007 t_domain_loss: 0.0055 \n","[4/16] class_loss: 0.0047 s_domain_loss: 0.0028 t_domain_loss: 0.0060 \n","[5/16] class_loss: 0.0036 s_domain_loss: 0.0006 t_domain_loss: 0.0045 \n","[6/16] class_loss: 0.0023 s_domain_loss: 0.0000 t_domain_loss: 0.0033 \n","[7/16] class_loss: 0.0022 s_domain_loss: 0.0004 t_domain_loss: 0.0029 \n","[8/16] class_loss: 0.0020 s_domain_loss: 0.0021 t_domain_loss: 0.0027 \n","[9/16] class_loss: 0.0026 s_domain_loss: 0.0002 t_domain_loss: 0.0022 \n","[10/16] class_loss: 0.0034 s_domain_loss: 0.0023 t_domain_loss: 0.0025 \n","[11/16] class_loss: 0.0053 s_domain_loss: 0.0019 t_domain_loss: 0.0015 \n","[12/16] class_loss: 0.0010 s_domain_loss: 0.0009 t_domain_loss: 0.0015 \n","[13/16] class_loss: 0.0019 s_domain_loss: 0.0010 t_domain_loss: 0.0014 \n","[14/16] class_loss: 0.0029 s_domain_loss: 0.0044 t_domain_loss: 0.0013 \n","[15/16] class_loss: 0.0011 s_domain_loss: 0.0001 t_domain_loss: 0.0013 \n","[16/16] class_loss: 0.0041 s_domain_loss: 0.0004 t_domain_loss: 0.0009 \n","\n","Epoch 0018 / 0030\n","=================\n","[1/16] class_loss: 0.0014 s_domain_loss: 0.0004 t_domain_loss: 0.0011 \n","[2/16] class_loss: 0.0012 s_domain_loss: 0.0089 t_domain_loss: 0.0010 \n","[3/16] class_loss: 0.0012 s_domain_loss: 0.0010 t_domain_loss: 0.0009 \n","[4/16] class_loss: 0.0060 s_domain_loss: 0.0004 t_domain_loss: 0.0011 \n","[5/16] class_loss: 0.0018 s_domain_loss: 0.0008 t_domain_loss: 0.0010 \n","[6/16] class_loss: 0.0029 s_domain_loss: 0.0015 t_domain_loss: 0.0009 \n","[7/16] class_loss: 0.0012 s_domain_loss: 0.0142 t_domain_loss: 0.0008 \n","[8/16] class_loss: 0.0014 s_domain_loss: 0.0003 t_domain_loss: 0.0009 \n","[9/16] class_loss: 0.0009 s_domain_loss: 0.0239 t_domain_loss: 0.0010 \n","[10/16] class_loss: 0.0013 s_domain_loss: 0.0011 t_domain_loss: 0.0015 \n","[11/16] class_loss: 0.0012 s_domain_loss: 0.0032 t_domain_loss: 0.0012 \n","[12/16] class_loss: 0.0012 s_domain_loss: 0.0007 t_domain_loss: 0.0015 \n","[13/16] class_loss: 0.0018 s_domain_loss: 0.0008 t_domain_loss: 0.0018 \n","[14/16] class_loss: 0.0009 s_domain_loss: 0.0063 t_domain_loss: 0.0021 \n","[15/16] class_loss: 0.0008 s_domain_loss: 0.0002 t_domain_loss: 0.0022 \n","[16/16] class_loss: 0.0008 s_domain_loss: 0.0002 t_domain_loss: 0.0020 \n","\n","Epoch 0019 / 0030\n","=================\n","[1/16] class_loss: 0.0008 s_domain_loss: 0.0052 t_domain_loss: 0.0029 \n","[2/16] class_loss: 0.0018 s_domain_loss: 0.0009 t_domain_loss: 0.0031 \n","[3/16] class_loss: 0.0006 s_domain_loss: 0.0005 t_domain_loss: 0.0030 \n","[4/16] class_loss: 0.0014 s_domain_loss: 0.0058 t_domain_loss: 0.0035 \n","[5/16] class_loss: 0.0007 s_domain_loss: 0.0010 t_domain_loss: 0.0033 \n","[6/16] class_loss: 0.0006 s_domain_loss: 0.0000 t_domain_loss: 0.0028 \n","[7/16] class_loss: 0.0010 s_domain_loss: 0.0005 t_domain_loss: 0.0028 \n","[8/16] class_loss: 0.0012 s_domain_loss: 0.0015 t_domain_loss: 0.0029 \n","[9/16] class_loss: 0.0011 s_domain_loss: 0.0003 t_domain_loss: 0.0027 \n","[10/16] class_loss: 0.0028 s_domain_loss: 0.0003 t_domain_loss: 0.0031 \n","[11/16] class_loss: 0.0012 s_domain_loss: 0.0002 t_domain_loss: 0.0022 \n","[12/16] class_loss: 0.0043 s_domain_loss: 0.0005 t_domain_loss: 0.0023 \n","[13/16] class_loss: 0.0020 s_domain_loss: 0.0008 t_domain_loss: 0.0022 \n","[14/16] class_loss: 0.0012 s_domain_loss: 0.0003 t_domain_loss: 0.0020 \n","[15/16] class_loss: 0.0009 s_domain_loss: 0.0007 t_domain_loss: 0.0019 \n","[16/16] class_loss: 0.0011 s_domain_loss: 0.0006 t_domain_loss: 0.0013 \n","\n","Epoch 0020 / 0030\n","=================\n","[1/16] class_loss: 0.0020 s_domain_loss: 0.0005 t_domain_loss: 0.0017 \n","[2/16] class_loss: 0.0011 s_domain_loss: 0.0001 t_domain_loss: 0.0017 \n","[3/16] class_loss: 0.0025 s_domain_loss: 0.0003 t_domain_loss: 0.0015 \n","[4/16] class_loss: 0.0013 s_domain_loss: 0.0005 t_domain_loss: 0.0017 \n","[5/16] class_loss: 0.0011 s_domain_loss: 0.0005 t_domain_loss: 0.0016 \n","[6/16] class_loss: 0.0009 s_domain_loss: 0.0050 t_domain_loss: 0.0014 \n","[7/16] class_loss: 0.0008 s_domain_loss: 0.0001 t_domain_loss: 0.0013 \n","[8/16] class_loss: 0.0030 s_domain_loss: 0.0006 t_domain_loss: 0.0015 \n","[9/16] class_loss: 0.0007 s_domain_loss: 0.0040 t_domain_loss: 0.0014 \n","[10/16] class_loss: 0.0005 s_domain_loss: 0.0006 t_domain_loss: 0.0017 \n","[11/16] class_loss: 0.0014 s_domain_loss: 0.0001 t_domain_loss: 0.0012 \n","[12/16] class_loss: 0.0011 s_domain_loss: 0.0008 t_domain_loss: 0.0014 \n","[13/16] class_loss: 0.0014 s_domain_loss: 0.0015 t_domain_loss: 0.0014 \n","[14/16] class_loss: 0.0014 s_domain_loss: 0.0001 t_domain_loss: 0.0015 \n","[15/16] class_loss: 0.0011 s_domain_loss: 0.0001 t_domain_loss: 0.0014 \n","[16/16] class_loss: 0.0016 s_domain_loss: 0.0003 t_domain_loss: 0.0011 \n","\n","Epoch 0021 / 0030\n","=================\n","[1/16] class_loss: 0.0014 s_domain_loss: 0.0005 t_domain_loss: 0.0015 \n","[2/16] class_loss: 0.0015 s_domain_loss: 0.0001 t_domain_loss: 0.0015 \n","[3/16] class_loss: 0.0007 s_domain_loss: 0.0001 t_domain_loss: 0.0014 \n","[4/16] class_loss: 0.0010 s_domain_loss: 0.0004 t_domain_loss: 0.0016 \n","[5/16] class_loss: 0.0006 s_domain_loss: 0.0009 t_domain_loss: 0.0015 \n","[6/16] class_loss: 0.0015 s_domain_loss: 0.0012 t_domain_loss: 0.0013 \n","[7/16] class_loss: 0.0014 s_domain_loss: 0.0009 t_domain_loss: 0.0012 \n","[8/16] class_loss: 0.0011 s_domain_loss: 0.0003 t_domain_loss: 0.0013 \n","[9/16] class_loss: 0.0011 s_domain_loss: 0.0010 t_domain_loss: 0.0013 \n","[10/16] class_loss: 0.0021 s_domain_loss: 0.0001 t_domain_loss: 0.0016 \n","[11/16] class_loss: 0.0013 s_domain_loss: 0.0003 t_domain_loss: 0.0011 \n","[12/16] class_loss: 0.0014 s_domain_loss: 0.0004 t_domain_loss: 0.0012 \n","[13/16] class_loss: 0.0007 s_domain_loss: 0.0001 t_domain_loss: 0.0013 \n","[14/16] class_loss: 0.0017 s_domain_loss: 0.0010 t_domain_loss: 0.0013 \n","[15/16] class_loss: 0.0010 s_domain_loss: 0.0001 t_domain_loss: 0.0013 \n","[16/16] class_loss: 0.0017 s_domain_loss: 0.0002 t_domain_loss: 0.0010 \n","\n","Epoch 0022 / 0030\n","=================\n","[1/16] class_loss: 0.0074 s_domain_loss: 0.0011 t_domain_loss: 0.0014 \n","[2/16] class_loss: 0.0020 s_domain_loss: 0.0018 t_domain_loss: 0.0014 \n","[3/16] class_loss: 0.0020 s_domain_loss: 0.0001 t_domain_loss: 0.0013 \n","[4/16] class_loss: 0.0009 s_domain_loss: 0.0001 t_domain_loss: 0.0014 \n","[5/16] class_loss: 0.0011 s_domain_loss: 0.0002 t_domain_loss: 0.0013 \n","[6/16] class_loss: 0.0008 s_domain_loss: 0.0151 t_domain_loss: 0.0012 \n","[7/16] class_loss: 0.0015 s_domain_loss: 0.0008 t_domain_loss: 0.0011 \n","[8/16] class_loss: 0.0012 s_domain_loss: 0.0001 t_domain_loss: 0.0012 \n","[9/16] class_loss: 0.0019 s_domain_loss: 0.0005 t_domain_loss: 0.0012 \n","[10/16] class_loss: 0.0010 s_domain_loss: 0.0431 t_domain_loss: 0.0015 \n","[11/16] class_loss: 0.0006 s_domain_loss: 0.0004 t_domain_loss: 0.0011 \n","[12/16] class_loss: 0.0010 s_domain_loss: 0.0004 t_domain_loss: 0.0012 \n","[13/16] class_loss: 0.0011 s_domain_loss: 0.0002 t_domain_loss: 0.0013 \n","[14/16] class_loss: 0.0004 s_domain_loss: 0.0101 t_domain_loss: 0.0014 \n","[15/16] class_loss: 0.0022 s_domain_loss: 0.0009 t_domain_loss: 0.0014 \n","[16/16] class_loss: 0.0009 s_domain_loss: 0.0002 t_domain_loss: 0.0011 \n","\n","Epoch 0023 / 0030\n","=================\n","[1/16] class_loss: 0.0010 s_domain_loss: 0.0004 t_domain_loss: 0.0015 \n","[2/16] class_loss: 0.0011 s_domain_loss: 0.0002 t_domain_loss: 0.0016 \n","[3/16] class_loss: 0.0007 s_domain_loss: 0.0005 t_domain_loss: 0.0014 \n","[4/16] class_loss: 0.0015 s_domain_loss: 0.0003 t_domain_loss: 0.0017 \n","[5/16] class_loss: 0.0008 s_domain_loss: 0.0005 t_domain_loss: 0.0016 \n","[6/16] class_loss: 0.0007 s_domain_loss: 0.0015 t_domain_loss: 0.0014 \n","[7/16] class_loss: 0.0023 s_domain_loss: 0.0013 t_domain_loss: 0.0013 \n","[8/16] class_loss: 0.0010 s_domain_loss: 0.0005 t_domain_loss: 0.0015 \n","[9/16] class_loss: 0.0017 s_domain_loss: 0.0047 t_domain_loss: 0.0014 \n","[10/16] class_loss: 0.0010 s_domain_loss: 0.0018 t_domain_loss: 0.0018 \n","[11/16] class_loss: 0.0006 s_domain_loss: 0.0002 t_domain_loss: 0.0013 \n","[12/16] class_loss: 0.0005 s_domain_loss: 0.0002 t_domain_loss: 0.0014 \n","[13/16] class_loss: 0.0009 s_domain_loss: 0.0003 t_domain_loss: 0.0015 \n","[14/16] class_loss: 0.0022 s_domain_loss: 0.0001 t_domain_loss: 0.0015 \n","[15/16] class_loss: 0.0009 s_domain_loss: 0.0004 t_domain_loss: 0.0015 \n","[16/16] class_loss: 0.0012 s_domain_loss: 0.0060 t_domain_loss: 0.0012 \n","\n","Epoch 0024 / 0030\n","=================\n","[1/16] class_loss: 0.0009 s_domain_loss: 0.0004 t_domain_loss: 0.0016 \n","[2/16] class_loss: 0.0010 s_domain_loss: 0.0004 t_domain_loss: 0.0016 \n","[3/16] class_loss: 0.0013 s_domain_loss: 0.0002 t_domain_loss: 0.0015 \n","[4/16] class_loss: 0.0010 s_domain_loss: 0.0001 t_domain_loss: 0.0017 \n","[5/16] class_loss: 0.0014 s_domain_loss: 0.0003 t_domain_loss: 0.0016 \n","[6/16] class_loss: 0.0012 s_domain_loss: 0.0006 t_domain_loss: 0.0014 \n","[7/16] class_loss: 0.0013 s_domain_loss: 0.0002 t_domain_loss: 0.0013 \n","[8/16] class_loss: 0.0007 s_domain_loss: 0.0017 t_domain_loss: 0.0015 \n","[9/16] class_loss: 0.0008 s_domain_loss: 0.0042 t_domain_loss: 0.0014 \n","[10/16] class_loss: 0.0008 s_domain_loss: 0.0005 t_domain_loss: 0.0018 \n","[11/16] class_loss: 0.0012 s_domain_loss: 0.0003 t_domain_loss: 0.0013 \n","[12/16] class_loss: 0.0006 s_domain_loss: 0.0005 t_domain_loss: 0.0014 \n","[13/16] class_loss: 0.0021 s_domain_loss: 0.0004 t_domain_loss: 0.0015 \n","[14/16] class_loss: 0.0007 s_domain_loss: 0.0011 t_domain_loss: 0.0015 \n","[15/16] class_loss: 0.0010 s_domain_loss: 0.0002 t_domain_loss: 0.0015 \n","[16/16] class_loss: 0.0009 s_domain_loss: 0.0006 t_domain_loss: 0.0011 \n","\n","Epoch 0025 / 0030\n","=================\n","[1/16] class_loss: 0.0007 s_domain_loss: 0.0004 t_domain_loss: 0.0016 \n","[2/16] class_loss: 0.0009 s_domain_loss: 0.0007 t_domain_loss: 0.0015 \n","[3/16] class_loss: 0.0007 s_domain_loss: 0.0009 t_domain_loss: 0.0014 \n","[4/16] class_loss: 0.0008 s_domain_loss: 0.0003 t_domain_loss: 0.0016 \n","[5/16] class_loss: 0.0007 s_domain_loss: 0.0004 t_domain_loss: 0.0015 \n","[6/16] class_loss: 0.0014 s_domain_loss: 0.0002 t_domain_loss: 0.0013 \n","[7/16] class_loss: 0.0027 s_domain_loss: 0.0008 t_domain_loss: 0.0012 \n","[8/16] class_loss: 0.0011 s_domain_loss: 0.0004 t_domain_loss: 0.0014 \n","[9/16] class_loss: 0.0009 s_domain_loss: 0.0016 t_domain_loss: 0.0013 \n","[10/16] class_loss: 0.0023 s_domain_loss: 0.0013 t_domain_loss: 0.0016 \n","[11/16] class_loss: 0.0020 s_domain_loss: 0.0004 t_domain_loss: 0.0012 \n","[12/16] class_loss: 0.0039 s_domain_loss: 0.0003 t_domain_loss: 0.0013 \n","[13/16] class_loss: 0.0008 s_domain_loss: 0.0004 t_domain_loss: 0.0013 \n","[14/16] class_loss: 0.0018 s_domain_loss: 0.0007 t_domain_loss: 0.0014 \n","[15/16] class_loss: 0.0010 s_domain_loss: 0.0031 t_domain_loss: 0.0013 \n","[16/16] class_loss: 0.0009 s_domain_loss: 0.0024 t_domain_loss: 0.0010 \n","\n","Epoch 0026 / 0030\n","=================\n","[1/16] class_loss: 0.0005 s_domain_loss: 0.0004 t_domain_loss: 0.0014 \n","[2/16] class_loss: 0.0016 s_domain_loss: 0.0020 t_domain_loss: 0.0014 \n","[3/16] class_loss: 0.0004 s_domain_loss: 0.0002 t_domain_loss: 0.0013 \n","[4/16] class_loss: 0.0008 s_domain_loss: 0.0041 t_domain_loss: 0.0015 \n","[5/16] class_loss: 0.0005 s_domain_loss: 0.0008 t_domain_loss: 0.0014 \n","[6/16] class_loss: 0.0010 s_domain_loss: 0.0015 t_domain_loss: 0.0012 \n","[7/16] class_loss: 0.0009 s_domain_loss: 0.0003 t_domain_loss: 0.0012 \n","[8/16] class_loss: 0.0006 s_domain_loss: 0.0009 t_domain_loss: 0.0013 \n","[9/16] class_loss: 0.0010 s_domain_loss: 0.0008 t_domain_loss: 0.0012 \n","[10/16] class_loss: 0.0004 s_domain_loss: 0.0011 t_domain_loss: 0.0016 \n","[11/16] class_loss: 0.0009 s_domain_loss: 0.0011 t_domain_loss: 0.0011 \n","[12/16] class_loss: 0.0011 s_domain_loss: 0.0016 t_domain_loss: 0.0012 \n","[13/16] class_loss: 0.0017 s_domain_loss: 0.0004 t_domain_loss: 0.0013 \n","[14/16] class_loss: 0.0008 s_domain_loss: 0.0142 t_domain_loss: 0.0013 \n","[15/16] class_loss: 0.0009 s_domain_loss: 0.0001 t_domain_loss: 0.0013 \n","[16/16] class_loss: 0.0013 s_domain_loss: 0.0002 t_domain_loss: 0.0010 \n","\n","Epoch 0027 / 0030\n","=================\n","[1/16] class_loss: 0.0011 s_domain_loss: 0.0001 t_domain_loss: 0.0014 \n","[2/16] class_loss: 0.0007 s_domain_loss: 0.0042 t_domain_loss: 0.0014 \n","[3/16] class_loss: 0.0007 s_domain_loss: 0.0003 t_domain_loss: 0.0013 \n","[4/16] class_loss: 0.0010 s_domain_loss: 0.0005 t_domain_loss: 0.0015 \n","[5/16] class_loss: 0.0015 s_domain_loss: 0.0018 t_domain_loss: 0.0014 \n","[6/16] class_loss: 0.0007 s_domain_loss: 0.0008 t_domain_loss: 0.0012 \n","[7/16] class_loss: 0.0020 s_domain_loss: 0.0001 t_domain_loss: 0.0012 \n","[8/16] class_loss: 0.0006 s_domain_loss: 0.0011 t_domain_loss: 0.0013 \n","[9/16] class_loss: 0.0007 s_domain_loss: 0.0006 t_domain_loss: 0.0013 \n","[10/16] class_loss: 0.0008 s_domain_loss: 0.0003 t_domain_loss: 0.0016 \n","[11/16] class_loss: 0.0005 s_domain_loss: 0.0012 t_domain_loss: 0.0011 \n","[12/16] class_loss: 0.0011 s_domain_loss: 0.0001 t_domain_loss: 0.0012 \n","[13/16] class_loss: 0.0015 s_domain_loss: 0.0031 t_domain_loss: 0.0013 \n","[14/16] class_loss: 0.0011 s_domain_loss: 0.0002 t_domain_loss: 0.0013 \n","[15/16] class_loss: 0.0036 s_domain_loss: 0.0055 t_domain_loss: 0.0013 \n","[16/16] class_loss: 0.0007 s_domain_loss: 0.0005 t_domain_loss: 0.0010 \n","\n","Epoch 0028 / 0030\n","=================\n","[1/16] class_loss: 0.0007 s_domain_loss: 0.0012 t_domain_loss: 0.0014 \n","[2/16] class_loss: 0.0014 s_domain_loss: 0.0002 t_domain_loss: 0.0014 \n","[3/16] class_loss: 0.0010 s_domain_loss: 0.0003 t_domain_loss: 0.0013 \n","[4/16] class_loss: 0.0007 s_domain_loss: 0.0005 t_domain_loss: 0.0015 \n","[5/16] class_loss: 0.0010 s_domain_loss: 0.0018 t_domain_loss: 0.0014 \n","[6/16] class_loss: 0.0010 s_domain_loss: 0.0078 t_domain_loss: 0.0012 \n","[7/16] class_loss: 0.0005 s_domain_loss: 0.0007 t_domain_loss: 0.0012 \n","[8/16] class_loss: 0.0014 s_domain_loss: 0.0005 t_domain_loss: 0.0013 \n","[9/16] class_loss: 0.0015 s_domain_loss: 0.0024 t_domain_loss: 0.0013 \n","[10/16] class_loss: 0.0007 s_domain_loss: 0.0011 t_domain_loss: 0.0016 \n","[11/16] class_loss: 0.0008 s_domain_loss: 0.0002 t_domain_loss: 0.0011 \n","[12/16] class_loss: 0.0008 s_domain_loss: 0.0003 t_domain_loss: 0.0013 \n","[13/16] class_loss: 0.0008 s_domain_loss: 0.0004 t_domain_loss: 0.0013 \n","[14/16] class_loss: 0.0016 s_domain_loss: 0.0002 t_domain_loss: 0.0014 \n","[15/16] class_loss: 0.0017 s_domain_loss: 0.0032 t_domain_loss: 0.0014 \n","[16/16] class_loss: 0.0007 s_domain_loss: 0.0005 t_domain_loss: 0.0011 \n","\n","Epoch 0029 / 0030\n","=================\n","[1/16] class_loss: 0.0009 s_domain_loss: 0.0002 t_domain_loss: 0.0015 \n","[2/16] class_loss: 0.0005 s_domain_loss: 0.0001 t_domain_loss: 0.0014 \n","[3/16] class_loss: 0.0007 s_domain_loss: 0.0011 t_domain_loss: 0.0013 \n","[4/16] class_loss: 0.0006 s_domain_loss: 0.0002 t_domain_loss: 0.0015 \n","[5/16] class_loss: 0.0006 s_domain_loss: 0.0009 t_domain_loss: 0.0014 \n","[6/16] class_loss: 0.0012 s_domain_loss: 0.0013 t_domain_loss: 0.0012 \n","[7/16] class_loss: 0.0014 s_domain_loss: 0.0025 t_domain_loss: 0.0012 \n","[8/16] class_loss: 0.0008 s_domain_loss: 0.0039 t_domain_loss: 0.0013 \n","[9/16] class_loss: 0.0017 s_domain_loss: 0.0002 t_domain_loss: 0.0013 \n","[10/16] class_loss: 0.0008 s_domain_loss: 0.0001 t_domain_loss: 0.0016 \n","[11/16] class_loss: 0.0007 s_domain_loss: 0.0001 t_domain_loss: 0.0011 \n","[12/16] class_loss: 0.0012 s_domain_loss: 0.0004 t_domain_loss: 0.0012 \n","[13/16] class_loss: 0.0014 s_domain_loss: 0.0003 t_domain_loss: 0.0013 \n","[14/16] class_loss: 0.0013 s_domain_loss: 0.0005 t_domain_loss: 0.0013 \n","[15/16] class_loss: 0.0006 s_domain_loss: 0.0009 t_domain_loss: 0.0013 \n","[16/16] class_loss: 0.0008 s_domain_loss: 0.0002 t_domain_loss: 0.0010 \n","\n","Epoch 0030 / 0030\n","=================\n","[1/16] class_loss: 0.0012 s_domain_loss: 0.0080 t_domain_loss: 0.0014 \n","[2/16] class_loss: 0.0009 s_domain_loss: 0.0002 t_domain_loss: 0.0014 \n","[3/16] class_loss: 0.0037 s_domain_loss: 0.0062 t_domain_loss: 0.0013 \n","[4/16] class_loss: 0.0011 s_domain_loss: 0.0006 t_domain_loss: 0.0015 \n","[5/16] class_loss: 0.0008 s_domain_loss: 0.0014 t_domain_loss: 0.0014 \n","[6/16] class_loss: 0.0006 s_domain_loss: 0.0010 t_domain_loss: 0.0012 \n","[7/16] class_loss: 0.0013 s_domain_loss: 0.0012 t_domain_loss: 0.0011 \n","[8/16] class_loss: 0.0008 s_domain_loss: 0.0009 t_domain_loss: 0.0013 \n","[9/16] class_loss: 0.0019 s_domain_loss: 0.0003 t_domain_loss: 0.0012 \n","[10/16] class_loss: 0.0006 s_domain_loss: 0.0007 t_domain_loss: 0.0016 \n","[11/16] class_loss: 0.0012 s_domain_loss: 0.0002 t_domain_loss: 0.0011 \n","[12/16] class_loss: 0.0006 s_domain_loss: 0.0012 t_domain_loss: 0.0012 \n","[13/16] class_loss: 0.0016 s_domain_loss: 0.0001 t_domain_loss: 0.0013 \n","[14/16] class_loss: 0.0006 s_domain_loss: 0.0070 t_domain_loss: 0.0013 \n","[15/16] class_loss: 0.0008 s_domain_loss: 0.0019 t_domain_loss: 0.0013 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[16/16] class_loss: 0.0013 s_domain_loss: 0.0001 t_domain_loss: 0.0010 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:16<00:00,  1.01s/it]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.5869140625\n","hyperprameters are: LR=0.007 and NUM_EPOCHS = 10\n","\n","Epoch 0001 / 0010\n","=================\n","[1/16] class_loss: 1.9717 s_domain_loss: 1.2515 t_domain_loss: 0.3654 \n","[2/16] class_loss: 1.1733 s_domain_loss: 0.0578 t_domain_loss: 2.9564 \n","[3/16] class_loss: 0.8516 s_domain_loss: 1.9354 t_domain_loss: 0.1715 \n","[4/16] class_loss: 0.4630 s_domain_loss: 0.4752 t_domain_loss: 0.9802 \n","[5/16] class_loss: 0.3968 s_domain_loss: 0.5373 t_domain_loss: 0.8723 \n","[6/16] class_loss: 0.2420 s_domain_loss: 1.5167 t_domain_loss: 0.2631 \n","[7/16] class_loss: 0.3271 s_domain_loss: 0.0818 t_domain_loss: 2.5553 \n","[8/16] class_loss: 0.1852 s_domain_loss: 1.7746 t_domain_loss: 0.1943 \n","[9/16] class_loss: 0.2150 s_domain_loss: 0.3724 t_domain_loss: 1.1100 \n","[10/16] class_loss: 0.1260 s_domain_loss: 0.7553 t_domain_loss: 0.5657 \n","[11/16] class_loss: 0.1957 s_domain_loss: 0.7093 t_domain_loss: 0.5940 \n","[12/16] class_loss: 0.1369 s_domain_loss: 0.4669 t_domain_loss: 0.9172 \n","[13/16] class_loss: 0.2004 s_domain_loss: 1.1991 t_domain_loss: 0.3039 \n","[14/16] class_loss: 0.0728 s_domain_loss: 0.1529 t_domain_loss: 1.8053 \n","[15/16] class_loss: 0.1102 s_domain_loss: 1.9421 t_domain_loss: 0.1225 \n","[16/16] class_loss: 0.1248 s_domain_loss: 0.2187 t_domain_loss: 1.4564 \n","\n","Epoch 0002 / 0010\n","=================\n","[1/16] class_loss: 0.1206 s_domain_loss: 1.0466 t_domain_loss: 0.3363 \n","[2/16] class_loss: 0.1896 s_domain_loss: 0.3781 t_domain_loss: 0.8921 \n","[3/16] class_loss: 0.1047 s_domain_loss: 0.9655 t_domain_loss: 0.3506 \n","[4/16] class_loss: 0.0855 s_domain_loss: 0.2493 t_domain_loss: 1.1318 \n","[5/16] class_loss: 0.1037 s_domain_loss: 1.5908 t_domain_loss: 0.1436 \n","[6/16] class_loss: 0.0612 s_domain_loss: 0.1439 t_domain_loss: 1.7034 \n","[7/16] class_loss: 0.0795 s_domain_loss: 1.0109 t_domain_loss: 0.2499 \n","[8/16] class_loss: 0.0740 s_domain_loss: 0.4905 t_domain_loss: 0.6109 \n","[9/16] class_loss: 0.0642 s_domain_loss: 0.3160 t_domain_loss: 0.7910 \n","[10/16] class_loss: 0.0674 s_domain_loss: 1.2392 t_domain_loss: 0.1765 \n","[11/16] class_loss: 0.0819 s_domain_loss: 0.1316 t_domain_loss: 1.3248 \n","[12/16] class_loss: 0.0659 s_domain_loss: 1.1318 t_domain_loss: 0.1756 \n","[13/16] class_loss: 0.0570 s_domain_loss: 0.2742 t_domain_loss: 0.7966 \n","[14/16] class_loss: 0.0878 s_domain_loss: 0.5778 t_domain_loss: 0.3759 \n","[15/16] class_loss: 0.0451 s_domain_loss: 0.4626 t_domain_loss: 0.4239 \n","[16/16] class_loss: 0.0343 s_domain_loss: 0.3776 t_domain_loss: 0.3793 \n","\n","Epoch 0003 / 0010\n","=================\n","[1/16] class_loss: 0.0856 s_domain_loss: 0.5717 t_domain_loss: 0.3030 \n","[2/16] class_loss: 0.0606 s_domain_loss: 0.2421 t_domain_loss: 0.6172 \n","[3/16] class_loss: 0.0451 s_domain_loss: 0.5985 t_domain_loss: 0.2124 \n","[4/16] class_loss: 0.0354 s_domain_loss: 0.3227 t_domain_loss: 0.3740 \n","[5/16] class_loss: 0.0798 s_domain_loss: 0.2439 t_domain_loss: 0.4800 \n","[6/16] class_loss: 0.0601 s_domain_loss: 0.6362 t_domain_loss: 0.1342 \n","[7/16] class_loss: 0.0522 s_domain_loss: 0.1673 t_domain_loss: 0.4113 \n","[8/16] class_loss: 0.0938 s_domain_loss: 0.2449 t_domain_loss: 0.2727 \n","[9/16] class_loss: 0.0660 s_domain_loss: 0.3219 t_domain_loss: 0.1666 \n","[10/16] class_loss: 0.0595 s_domain_loss: 0.2404 t_domain_loss: 0.2676 \n","[11/16] class_loss: 0.0553 s_domain_loss: 0.2350 t_domain_loss: 0.2922 \n","[12/16] class_loss: 0.0552 s_domain_loss: 0.2751 t_domain_loss: 0.1847 \n","[13/16] class_loss: 0.1496 s_domain_loss: 0.4016 t_domain_loss: 0.1063 \n","[14/16] class_loss: 0.0673 s_domain_loss: 0.1145 t_domain_loss: 0.2965 \n","[15/16] class_loss: 0.0645 s_domain_loss: 0.1080 t_domain_loss: 0.2760 \n","[16/16] class_loss: 0.1101 s_domain_loss: 0.3491 t_domain_loss: 0.0787 \n","\n","Epoch 0004 / 0010\n","=================\n","[1/16] class_loss: 0.1041 s_domain_loss: 0.1189 t_domain_loss: 0.0918 \n","[2/16] class_loss: 0.2062 s_domain_loss: 0.1706 t_domain_loss: 0.1170 \n","[3/16] class_loss: 0.1084 s_domain_loss: 0.1154 t_domain_loss: 0.1771 \n","[4/16] class_loss: 0.0676 s_domain_loss: 0.0662 t_domain_loss: 0.1345 \n","[5/16] class_loss: 0.0405 s_domain_loss: 0.1623 t_domain_loss: 0.0692 \n","[6/16] class_loss: 0.0809 s_domain_loss: 0.5155 t_domain_loss: 0.0489 \n","[7/16] class_loss: 0.1318 s_domain_loss: 0.4486 t_domain_loss: 0.2937 \n","[8/16] class_loss: 0.0853 s_domain_loss: 0.0198 t_domain_loss: 1.2022 \n","[9/16] class_loss: 0.0553 s_domain_loss: 0.3514 t_domain_loss: 0.0902 \n","[10/16] class_loss: 0.0818 s_domain_loss: 0.5638 t_domain_loss: 0.0473 \n","[11/16] class_loss: 0.1066 s_domain_loss: 0.7806 t_domain_loss: 0.0452 \n","[12/16] class_loss: 0.2843 s_domain_loss: 0.1138 t_domain_loss: 0.1731 \n","[13/16] class_loss: 0.3630 s_domain_loss: 0.2098 t_domain_loss: 0.5010 \n","[14/16] class_loss: 0.2275 s_domain_loss: 0.0932 t_domain_loss: 0.2962 \n","[15/16] class_loss: 0.2122 s_domain_loss: 0.1045 t_domain_loss: 0.0707 \n","[16/16] class_loss: 0.1926 s_domain_loss: 0.3070 t_domain_loss: 0.0175 \n","\n","Epoch 0005 / 0010\n","=================\n","[1/16] class_loss: 0.1716 s_domain_loss: 0.0626 t_domain_loss: 0.0392 \n","[2/16] class_loss: 0.3295 s_domain_loss: 0.2440 t_domain_loss: 0.0535 \n","[3/16] class_loss: 0.2535 s_domain_loss: 0.1061 t_domain_loss: 0.2016 \n","[4/16] class_loss: 0.1521 s_domain_loss: 0.0478 t_domain_loss: 0.2254 \n","[5/16] class_loss: 0.1561 s_domain_loss: 0.0627 t_domain_loss: 0.0734 \n","[6/16] class_loss: 0.1588 s_domain_loss: 0.1940 t_domain_loss: 0.0202 \n","[7/16] class_loss: 0.2345 s_domain_loss: 0.0578 t_domain_loss: 0.0250 \n","[8/16] class_loss: 0.1416 s_domain_loss: 0.1261 t_domain_loss: 0.0113 \n","[9/16] class_loss: 0.1272 s_domain_loss: 0.1175 t_domain_loss: 0.0170 \n","[10/16] class_loss: 0.0991 s_domain_loss: 0.0315 t_domain_loss: 0.0778 \n","[11/16] class_loss: 0.1805 s_domain_loss: 0.0933 t_domain_loss: 0.0626 \n","[12/16] class_loss: 0.1677 s_domain_loss: 0.2608 t_domain_loss: 0.0712 \n","[13/16] class_loss: 0.1795 s_domain_loss: 0.0368 t_domain_loss: 0.1052 \n","[14/16] class_loss: 0.1890 s_domain_loss: 0.4464 t_domain_loss: 0.1414 \n","[15/16] class_loss: 0.1572 s_domain_loss: 0.0068 t_domain_loss: 0.3605 \n","[16/16] class_loss: 0.2352 s_domain_loss: 0.1490 t_domain_loss: 0.2580 \n","\n","Epoch 0006 / 0010\n","=================\n","[1/16] class_loss: 0.2733 s_domain_loss: 0.1123 t_domain_loss: 0.0541 \n","[2/16] class_loss: 0.2161 s_domain_loss: 0.3571 t_domain_loss: 0.0101 \n","[3/16] class_loss: 0.1559 s_domain_loss: 0.2012 t_domain_loss: 0.0126 \n","[4/16] class_loss: 0.1079 s_domain_loss: 0.0119 t_domain_loss: 0.0303 \n","[5/16] class_loss: 0.1889 s_domain_loss: 0.0237 t_domain_loss: 0.0385 \n","[6/16] class_loss: 0.1603 s_domain_loss: 0.0172 t_domain_loss: 0.0490 \n","[7/16] class_loss: 0.1549 s_domain_loss: 0.0227 t_domain_loss: 0.0862 \n","[8/16] class_loss: 0.1887 s_domain_loss: 0.0280 t_domain_loss: 0.0365 \n","[9/16] class_loss: 0.1144 s_domain_loss: 0.0082 t_domain_loss: 0.0288 \n","[10/16] class_loss: 0.1273 s_domain_loss: 0.1745 t_domain_loss: 0.0448 \n","[11/16] class_loss: 0.1188 s_domain_loss: 0.0341 t_domain_loss: 0.0352 \n","[12/16] class_loss: 0.1071 s_domain_loss: 0.0346 t_domain_loss: 0.0556 \n","[13/16] class_loss: 0.1342 s_domain_loss: 0.1231 t_domain_loss: 0.0384 \n","[14/16] class_loss: 0.1303 s_domain_loss: 0.0412 t_domain_loss: 0.0569 \n","[15/16] class_loss: 0.1336 s_domain_loss: 0.0138 t_domain_loss: 0.0659 \n","[16/16] class_loss: 0.0894 s_domain_loss: 0.0289 t_domain_loss: 0.0606 \n","\n","Epoch 0007 / 0010\n","=================\n","[1/16] class_loss: 0.0976 s_domain_loss: 0.0097 t_domain_loss: 0.0261 \n","[2/16] class_loss: 0.0796 s_domain_loss: 0.0115 t_domain_loss: 0.0089 \n","[3/16] class_loss: 0.0598 s_domain_loss: 0.0248 t_domain_loss: 0.0071 \n","[4/16] class_loss: 0.0700 s_domain_loss: 0.0346 t_domain_loss: 0.0051 \n","[5/16] class_loss: 0.0561 s_domain_loss: 0.0092 t_domain_loss: 0.0044 \n","[6/16] class_loss: 0.0468 s_domain_loss: 0.0551 t_domain_loss: 0.0032 \n","[7/16] class_loss: 0.0832 s_domain_loss: 0.0131 t_domain_loss: 0.0030 \n","[8/16] class_loss: 0.0327 s_domain_loss: 0.0029 t_domain_loss: 0.0031 \n","[9/16] class_loss: 0.0339 s_domain_loss: 0.0262 t_domain_loss: 0.0045 \n","[10/16] class_loss: 0.0421 s_domain_loss: 0.0302 t_domain_loss: 0.0075 \n","[11/16] class_loss: 0.0327 s_domain_loss: 0.0018 t_domain_loss: 0.0085 \n","[12/16] class_loss: 0.0247 s_domain_loss: 0.0023 t_domain_loss: 0.0289 \n","[13/16] class_loss: 0.0405 s_domain_loss: 0.0236 t_domain_loss: 0.0265 \n","[14/16] class_loss: 0.0495 s_domain_loss: 0.0096 t_domain_loss: 0.0260 \n","[15/16] class_loss: 0.0324 s_domain_loss: 0.0017 t_domain_loss: 0.0129 \n","[16/16] class_loss: 0.0405 s_domain_loss: 0.0099 t_domain_loss: 0.0154 \n","\n","Epoch 0008 / 0010\n","=================\n","[1/16] class_loss: 0.0158 s_domain_loss: 0.0012 t_domain_loss: 0.0053 \n","[2/16] class_loss: 0.0292 s_domain_loss: 0.0037 t_domain_loss: 0.0045 \n","[3/16] class_loss: 0.0149 s_domain_loss: 0.0113 t_domain_loss: 0.0031 \n","[4/16] class_loss: 0.0153 s_domain_loss: 0.0101 t_domain_loss: 0.0042 \n","[5/16] class_loss: 0.0084 s_domain_loss: 0.0024 t_domain_loss: 0.0023 \n","[6/16] class_loss: 0.0270 s_domain_loss: 0.0086 t_domain_loss: 0.0020 \n","[7/16] class_loss: 0.0140 s_domain_loss: 0.0312 t_domain_loss: 0.0020 \n","[8/16] class_loss: 0.0230 s_domain_loss: 0.0318 t_domain_loss: 0.0022 \n","[9/16] class_loss: 0.0124 s_domain_loss: 0.0221 t_domain_loss: 0.0051 \n","[10/16] class_loss: 0.0164 s_domain_loss: 0.0023 t_domain_loss: 0.0075 \n","[11/16] class_loss: 0.0188 s_domain_loss: 0.0005 t_domain_loss: 0.0071 \n","[12/16] class_loss: 0.0269 s_domain_loss: 0.0033 t_domain_loss: 0.0072 \n","[13/16] class_loss: 0.0182 s_domain_loss: 0.0014 t_domain_loss: 0.0057 \n","[14/16] class_loss: 0.0101 s_domain_loss: 0.0006 t_domain_loss: 0.0059 \n","[15/16] class_loss: 0.0092 s_domain_loss: 0.0179 t_domain_loss: 0.0077 \n","[16/16] class_loss: 0.0099 s_domain_loss: 0.0005 t_domain_loss: 0.0066 \n","\n","Epoch 0009 / 0010\n","=================\n","[1/16] class_loss: 0.0121 s_domain_loss: 0.0026 t_domain_loss: 0.0073 \n","[2/16] class_loss: 0.0430 s_domain_loss: 0.0020 t_domain_loss: 0.0082 \n","[3/16] class_loss: 0.0042 s_domain_loss: 0.0004 t_domain_loss: 0.0068 \n","[4/16] class_loss: 0.0081 s_domain_loss: 0.0005 t_domain_loss: 0.0091 \n","[5/16] class_loss: 0.0089 s_domain_loss: 0.0008 t_domain_loss: 0.0059 \n","[6/16] class_loss: 0.0095 s_domain_loss: 0.0165 t_domain_loss: 0.0041 \n","[7/16] class_loss: 0.0063 s_domain_loss: 0.0005 t_domain_loss: 0.0029 \n","[8/16] class_loss: 0.0061 s_domain_loss: 0.0076 t_domain_loss: 0.0020 \n","[9/16] class_loss: 0.0082 s_domain_loss: 0.0116 t_domain_loss: 0.0025 \n","[10/16] class_loss: 0.0051 s_domain_loss: 0.0071 t_domain_loss: 0.0047 \n","[11/16] class_loss: 0.0106 s_domain_loss: 0.0010 t_domain_loss: 0.0033 \n","[12/16] class_loss: 0.0074 s_domain_loss: 0.0007 t_domain_loss: 0.0035 \n","[13/16] class_loss: 0.0079 s_domain_loss: 0.0017 t_domain_loss: 0.0025 \n","[14/16] class_loss: 0.0041 s_domain_loss: 0.0015 t_domain_loss: 0.0024 \n","[15/16] class_loss: 0.0051 s_domain_loss: 0.0004 t_domain_loss: 0.0024 \n","[16/16] class_loss: 0.0034 s_domain_loss: 0.0012 t_domain_loss: 0.0027 \n","\n","Epoch 0010 / 0010\n","=================\n","[1/16] class_loss: 0.0037 s_domain_loss: 0.0028 t_domain_loss: 0.0024 \n","[2/16] class_loss: 0.0034 s_domain_loss: 0.0006 t_domain_loss: 0.0023 \n","[3/16] class_loss: 0.0040 s_domain_loss: 0.0091 t_domain_loss: 0.0021 \n","[4/16] class_loss: 0.0009 s_domain_loss: 0.0101 t_domain_loss: 0.0026 \n","[5/16] class_loss: 0.0082 s_domain_loss: 0.0016 t_domain_loss: 0.0024 \n","[6/16] class_loss: 0.0047 s_domain_loss: 0.0008 t_domain_loss: 0.0021 \n","[7/16] class_loss: 0.0042 s_domain_loss: 0.0012 t_domain_loss: 0.0016 \n","[8/16] class_loss: 0.0033 s_domain_loss: 0.0005 t_domain_loss: 0.0013 \n","[9/16] class_loss: 0.0087 s_domain_loss: 0.0015 t_domain_loss: 0.0018 \n","[10/16] class_loss: 0.0022 s_domain_loss: 0.0005 t_domain_loss: 0.0029 \n","[11/16] class_loss: 0.0037 s_domain_loss: 0.0017 t_domain_loss: 0.0018 \n","[12/16] class_loss: 0.0035 s_domain_loss: 0.0012 t_domain_loss: 0.0019 \n","[13/16] class_loss: 0.0030 s_domain_loss: 0.0008 t_domain_loss: 0.0015 \n","[14/16] class_loss: 0.0040 s_domain_loss: 0.0241 t_domain_loss: 0.0014 \n","[15/16] class_loss: 0.0207 s_domain_loss: 0.0032 t_domain_loss: 0.0016 \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[16/16] class_loss: 0.0044 s_domain_loss: 0.0020 t_domain_loss: 0.0019 \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:15<00:00,  1.04it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.3486328125\n","hyperprameters are: LR=0.007 and NUM_EPOCHS = 20\n","\n","Epoch 0001 / 0020\n","=================\n","[1/16] class_loss: 2.0375 s_domain_loss: 0.9648 t_domain_loss: 0.5352 \n","[2/16] class_loss: 1.3031 s_domain_loss: 0.2175 t_domain_loss: 1.7078 \n","[3/16] class_loss: 0.7745 s_domain_loss: 2.4571 t_domain_loss: 0.1058 \n","[4/16] class_loss: 0.4614 s_domain_loss: 0.1708 t_domain_loss: 1.8941 \n","[5/16] class_loss: 0.3156 s_domain_loss: 1.2538 t_domain_loss: 0.3573 \n","[6/16] class_loss: 0.2594 s_domain_loss: 0.4353 t_domain_loss: 1.0193 \n","[7/16] class_loss: 0.2523 s_domain_loss: 0.9609 t_domain_loss: 0.4833 \n","[8/16] class_loss: 0.3376 s_domain_loss: 0.3793 t_domain_loss: 1.0970 \n","[9/16] class_loss: 0.1651 s_domain_loss: 1.5052 t_domain_loss: 0.2398 \n","[10/16] class_loss: 0.2210 s_domain_loss: 0.1133 t_domain_loss: 2.0917 \n","[11/16] class_loss: 0.2317 s_domain_loss: 1.8593 t_domain_loss: 0.1541 \n","[12/16] class_loss: 0.2210 s_domain_loss: 0.2666 t_domain_loss: 1.3445 \n","[13/16] class_loss: 0.3417 s_domain_loss: 1.1311 t_domain_loss: 0.3242 \n","[14/16] class_loss: 0.1595 s_domain_loss: 0.3157 t_domain_loss: 1.1636 \n","[15/16] class_loss: 0.1490 s_domain_loss: 1.3388 t_domain_loss: 0.2415 \n","[16/16] class_loss: 0.2036 s_domain_loss: 0.1753 t_domain_loss: 1.6082 \n","\n","Epoch 0002 / 0020\n","=================\n","[1/16] class_loss: 0.2297 s_domain_loss: 1.6507 t_domain_loss: 0.1598 \n","[2/16] class_loss: 0.1532 s_domain_loss: 0.2090 t_domain_loss: 1.3874 \n","[3/16] class_loss: 0.1050 s_domain_loss: 1.1629 t_domain_loss: 0.2644 \n","[4/16] class_loss: 0.1934 s_domain_loss: 0.3426 t_domain_loss: 0.8964 \n","[5/16] class_loss: 0.1952 s_domain_loss: 0.9066 t_domain_loss: 0.3460 \n","[6/16] class_loss: 0.1098 s_domain_loss: 0.3012 t_domain_loss: 0.8678 \n","[7/16] class_loss: 0.0768 s_domain_loss: 0.8775 t_domain_loss: 0.2826 \n","[8/16] class_loss: 0.0829 s_domain_loss: 0.3053 t_domain_loss: 0.8061 \n","[9/16] class_loss: 0.1185 s_domain_loss: 0.7635 t_domain_loss: 0.3300 \n","[10/16] class_loss: 0.1567 s_domain_loss: 0.4591 t_domain_loss: 0.5820 \n","[11/16] class_loss: 0.0859 s_domain_loss: 0.3073 t_domain_loss: 0.7068 \n","[12/16] class_loss: 0.0938 s_domain_loss: 1.0905 t_domain_loss: 0.1562 \n","[13/16] class_loss: 0.0936 s_domain_loss: 0.1976 t_domain_loss: 1.0239 \n","[14/16] class_loss: 0.0914 s_domain_loss: 0.6308 t_domain_loss: 0.2382 \n","[15/16] class_loss: 0.1214 s_domain_loss: 0.6744 t_domain_loss: 0.2481 \n","[16/16] class_loss: 0.0618 s_domain_loss: 0.1150 t_domain_loss: 1.0951 \n","\n","Epoch 0003 / 0020\n","=================\n","[1/16] class_loss: 0.1044 s_domain_loss: 0.8593 t_domain_loss: 0.1190 \n","[2/16] class_loss: 0.0548 s_domain_loss: 0.4305 t_domain_loss: 0.2811 \n","[3/16] class_loss: 0.1261 s_domain_loss: 0.1774 t_domain_loss: 0.6732 \n","[4/16] class_loss: 0.0922 s_domain_loss: 0.6136 t_domain_loss: 0.1524 \n","[5/16] class_loss: 0.0959 s_domain_loss: 0.1857 t_domain_loss: 0.2895 \n","[6/16] class_loss: 0.0696 s_domain_loss: 0.4165 t_domain_loss: 0.2131 \n","[7/16] class_loss: 0.0998 s_domain_loss: 0.2683 t_domain_loss: 0.2152 \n","[8/16] class_loss: 0.0978 s_domain_loss: 0.2366 t_domain_loss: 0.2240 \n","[9/16] class_loss: 0.0986 s_domain_loss: 0.1740 t_domain_loss: 0.2363 \n","[10/16] class_loss: 0.0935 s_domain_loss: 0.4136 t_domain_loss: 0.1620 \n","[11/16] class_loss: 0.1451 s_domain_loss: 0.1302 t_domain_loss: 0.2959 \n","[12/16] class_loss: 0.0922 s_domain_loss: 0.3456 t_domain_loss: 0.1916 \n","[13/16] class_loss: 0.2423 s_domain_loss: 0.5572 t_domain_loss: 0.1007 \n","[14/16] class_loss: 0.1093 s_domain_loss: 0.0983 t_domain_loss: 0.3264 \n","[15/16] class_loss: 0.0814 s_domain_loss: 0.1460 t_domain_loss: 0.2660 \n","[16/16] class_loss: 0.1431 s_domain_loss: 0.2663 t_domain_loss: 0.0977 \n","\n","Epoch 0004 / 0020\n","=================\n","[1/16] class_loss: 0.1018 s_domain_loss: 0.2309 t_domain_loss: 0.0698 \n","[2/16] class_loss: 0.1593 s_domain_loss: 0.0918 t_domain_loss: 0.1302 \n","[3/16] class_loss: 0.2170 s_domain_loss: 0.1140 t_domain_loss: 0.1573 \n","[4/16] class_loss: 0.1267 s_domain_loss: 0.0565 t_domain_loss: 0.1147 \n","[5/16] class_loss: 0.0757 s_domain_loss: 0.1062 t_domain_loss: 0.0506 \n","[6/16] class_loss: 0.0640 s_domain_loss: 0.3885 t_domain_loss: 0.0253 \n","[7/16] class_loss: 0.0990 s_domain_loss: 0.0435 t_domain_loss: 0.0874 \n","[8/16] class_loss: 0.1528 s_domain_loss: 0.0297 t_domain_loss: 0.1843 \n","[9/16] class_loss: 0.1337 s_domain_loss: 0.0635 t_domain_loss: 0.1288 \n","[10/16] class_loss: 0.0753 s_domain_loss: 0.0881 t_domain_loss: 0.0471 \n","[11/16] class_loss: 0.0712 s_domain_loss: 0.2301 t_domain_loss: 0.0230 \n","[12/16] class_loss: 0.1222 s_domain_loss: 0.0661 t_domain_loss: 0.0455 \n","[13/16] class_loss: 0.1513 s_domain_loss: 0.0823 t_domain_loss: 0.0615 \n","[14/16] class_loss: 0.0833 s_domain_loss: 0.1100 t_domain_loss: 0.0746 \n","[15/16] class_loss: 0.0896 s_domain_loss: 0.0293 t_domain_loss: 0.1494 \n","[16/16] class_loss: 0.1103 s_domain_loss: 0.0372 t_domain_loss: 0.0765 \n","\n","Epoch 0005 / 0020\n","=================\n","[1/16] class_loss: 0.1277 s_domain_loss: 0.0678 t_domain_loss: 0.0293 \n","[2/16] class_loss: 0.0699 s_domain_loss: 0.0524 t_domain_loss: 0.0175 \n","[3/16] class_loss: 0.0466 s_domain_loss: 0.0796 t_domain_loss: 0.0173 \n","[4/16] class_loss: 0.0423 s_domain_loss: 0.0287 t_domain_loss: 0.0123 \n","[5/16] class_loss: 0.0342 s_domain_loss: 0.0198 t_domain_loss: 0.0143 \n","[6/16] class_loss: 0.0760 s_domain_loss: 0.0406 t_domain_loss: 0.0143 \n","[7/16] class_loss: 0.1001 s_domain_loss: 0.1045 t_domain_loss: 0.0184 \n","[8/16] class_loss: 0.0954 s_domain_loss: 0.0074 t_domain_loss: 0.0320 \n","[9/16] class_loss: 0.0426 s_domain_loss: 0.0157 t_domain_loss: 0.0448 \n","[10/16] class_loss: 0.0473 s_domain_loss: 0.0024 t_domain_loss: 0.0559 \n","[11/16] class_loss: 0.0450 s_domain_loss: 0.0106 t_domain_loss: 0.0293 \n","[12/16] class_loss: 0.0613 s_domain_loss: 0.0066 t_domain_loss: 0.0223 \n","[13/16] class_loss: 0.0346 s_domain_loss: 0.0223 t_domain_loss: 0.0119 \n","[14/16] class_loss: 0.0325 s_domain_loss: 0.0339 t_domain_loss: 0.0073 \n","[15/16] class_loss: 0.0221 s_domain_loss: 0.0246 t_domain_loss: 0.0080 \n","[16/16] class_loss: 0.0232 s_domain_loss: 0.0434 t_domain_loss: 0.0049 \n","\n","Epoch 0006 / 0020\n","=================\n","[1/16] class_loss: 0.0244 s_domain_loss: 0.0112 t_domain_loss: 0.0091 \n","[2/16] class_loss: 0.0150 s_domain_loss: 0.0524 t_domain_loss: 0.0090 \n","[3/16] class_loss: 0.0380 s_domain_loss: 0.0042 t_domain_loss: 0.0145 \n","[4/16] class_loss: 0.0654 s_domain_loss: 0.0521 t_domain_loss: 0.0168 \n","[5/16] class_loss: 0.0175 s_domain_loss: 0.0046 t_domain_loss: 0.0262 \n","[6/16] class_loss: 0.0339 s_domain_loss: 0.0992 t_domain_loss: 0.0269 \n","[7/16] class_loss: 0.0205 s_domain_loss: 0.0097 t_domain_loss: 0.0501 \n","[8/16] class_loss: 0.0181 s_domain_loss: 0.0017 t_domain_loss: 0.0526 \n","[9/16] class_loss: 0.0339 s_domain_loss: 0.0016 t_domain_loss: 0.0352 \n","[10/16] class_loss: 0.0177 s_domain_loss: 0.0014 t_domain_loss: 0.0185 \n","[11/16] class_loss: 0.0269 s_domain_loss: 0.0013 t_domain_loss: 0.0096 \n","[12/16] class_loss: 0.0170 s_domain_loss: 0.0097 t_domain_loss: 0.0072 \n","[13/16] class_loss: 0.0185 s_domain_loss: 0.0151 t_domain_loss: 0.0036 \n","[14/16] class_loss: 0.0311 s_domain_loss: 0.0057 t_domain_loss: 0.0025 \n","[15/16] class_loss: 0.0080 s_domain_loss: 0.0515 t_domain_loss: 0.0030 \n","[16/16] class_loss: 0.0106 s_domain_loss: 0.0157 t_domain_loss: 0.0019 \n","\n","Epoch 0007 / 0020\n","=================\n","[1/16] class_loss: 0.0188 s_domain_loss: 0.0054 t_domain_loss: 0.0036 \n","[2/16] class_loss: 0.0234 s_domain_loss: 0.0257 t_domain_loss: 0.0042 \n","[3/16] class_loss: 0.0157 s_domain_loss: 0.0064 t_domain_loss: 0.0042 \n","[4/16] class_loss: 0.0102 s_domain_loss: 0.0019 t_domain_loss: 0.0069 \n","[5/16] class_loss: 0.0074 s_domain_loss: 0.0349 t_domain_loss: 0.0067 \n","[6/16] class_loss: 0.0208 s_domain_loss: 0.0072 t_domain_loss: 0.0098 \n","[7/16] class_loss: 0.0230 s_domain_loss: 0.0113 t_domain_loss: 0.0200 \n","[8/16] class_loss: 0.0074 s_domain_loss: 0.0076 t_domain_loss: 0.0319 \n","[9/16] class_loss: 0.0111 s_domain_loss: 0.0020 t_domain_loss: 0.0182 \n","[10/16] class_loss: 0.0109 s_domain_loss: 0.0344 t_domain_loss: 0.0063 \n","[11/16] class_loss: 0.0169 s_domain_loss: 0.0036 t_domain_loss: 0.0061 \n","[12/16] class_loss: 0.0121 s_domain_loss: 0.0215 t_domain_loss: 0.0054 \n","[13/16] class_loss: 0.0188 s_domain_loss: 0.0186 t_domain_loss: 0.0045 \n","[14/16] class_loss: 0.0070 s_domain_loss: 0.0051 t_domain_loss: 0.0042 \n","[15/16] class_loss: 0.0101 s_domain_loss: 0.0025 t_domain_loss: 0.0088 \n","[16/16] class_loss: 0.0135 s_domain_loss: 0.0031 t_domain_loss: 0.0061 \n","\n","Epoch 0008 / 0020\n","=================\n","[1/16] class_loss: 0.0108 s_domain_loss: 0.0004 t_domain_loss: 0.0078 \n","[2/16] class_loss: 0.0112 s_domain_loss: 0.0030 t_domain_loss: 0.0062 \n","[3/16] class_loss: 0.0156 s_domain_loss: 0.0079 t_domain_loss: 0.0055 \n","[4/16] class_loss: 0.0064 s_domain_loss: 0.0056 t_domain_loss: 0.0045 \n","[5/16] class_loss: 0.0071 s_domain_loss: 0.0159 t_domain_loss: 0.0052 \n","[6/16] class_loss: 0.0172 s_domain_loss: 0.0022 t_domain_loss: 0.0049 \n","[7/16] class_loss: 0.0104 s_domain_loss: 0.0012 t_domain_loss: 0.0046 \n","[8/16] class_loss: 0.0073 s_domain_loss: 0.0044 t_domain_loss: 0.0043 \n","[9/16] class_loss: 0.0066 s_domain_loss: 0.0016 t_domain_loss: 0.0039 \n","[10/16] class_loss: 0.0121 s_domain_loss: 0.0081 t_domain_loss: 0.0035 \n","[11/16] class_loss: 0.0094 s_domain_loss: 0.0024 t_domain_loss: 0.0030 \n","[12/16] class_loss: 0.0084 s_domain_loss: 0.1734 t_domain_loss: 0.0042 \n","[13/16] class_loss: 0.0047 s_domain_loss: 0.0488 t_domain_loss: 0.0098 \n","[14/16] class_loss: 0.0684 s_domain_loss: 0.0278 t_domain_loss: 0.0308 \n","[15/16] class_loss: 0.0329 s_domain_loss: 0.0015 t_domain_loss: 0.0842 \n","[16/16] class_loss: 0.0105 s_domain_loss: 0.0015 t_domain_loss: 0.0646 \n","\n","Epoch 0009 / 0020\n","=================\n","[1/16] class_loss: 0.0297 s_domain_loss: 0.0000 t_domain_loss: 0.0597 \n","[2/16] class_loss: 0.0323 s_domain_loss: 0.0001 t_domain_loss: 0.0249 \n","[3/16] class_loss: 0.0706 s_domain_loss: 0.0023 t_domain_loss: 0.0103 \n","[4/16] class_loss: 0.0740 s_domain_loss: 0.0009 t_domain_loss: 0.0045 \n","[5/16] class_loss: 0.0251 s_domain_loss: 0.0065 t_domain_loss: 0.0021 \n","[6/16] class_loss: 0.0351 s_domain_loss: 0.0070 t_domain_loss: 0.0011 \n","[7/16] class_loss: 0.0495 s_domain_loss: 0.0212 t_domain_loss: 0.0005 \n","[8/16] class_loss: 0.0291 s_domain_loss: 0.0154 t_domain_loss: 0.0003 \n","[9/16] class_loss: 0.0525 s_domain_loss: 0.0516 t_domain_loss: 0.0002 \n","[10/16] class_loss: 0.0151 s_domain_loss: 0.0084 t_domain_loss: 0.0005 \n","[11/16] class_loss: 0.0085 s_domain_loss: 0.0294 t_domain_loss: 0.0004 \n","[12/16] class_loss: 0.0135 s_domain_loss: 0.0205 t_domain_loss: 0.0003 \n","[13/16] class_loss: 0.0099 s_domain_loss: 0.0080 t_domain_loss: 0.0005 \n","[14/16] class_loss: 0.0309 s_domain_loss: 0.0013 t_domain_loss: 0.0006 \n","[15/16] class_loss: 0.0301 s_domain_loss: 0.0175 t_domain_loss: 0.0009 \n","[16/16] class_loss: 0.0214 s_domain_loss: 0.0071 t_domain_loss: 0.0011 \n","\n","Epoch 0010 / 0020\n","=================\n","[1/16] class_loss: 0.0136 s_domain_loss: 0.0031 t_domain_loss: 0.0025 \n","[2/16] class_loss: 0.0105 s_domain_loss: 0.0140 t_domain_loss: 0.0029 \n","[3/16] class_loss: 0.0046 s_domain_loss: 0.0023 t_domain_loss: 0.0038 \n","[4/16] class_loss: 0.0078 s_domain_loss: 0.0008 t_domain_loss: 0.0073 \n","[5/16] class_loss: 0.0053 s_domain_loss: 0.0011 t_domain_loss: 0.0081 \n","[6/16] class_loss: 0.0077 s_domain_loss: 0.0016 t_domain_loss: 0.0095 \n","[7/16] class_loss: 0.0145 s_domain_loss: 0.0045 t_domain_loss: 0.0102 \n","[8/16] class_loss: 0.0114 s_domain_loss: 0.0007 t_domain_loss: 0.0090 \n","[9/16] class_loss: 0.0119 s_domain_loss: 0.0147 t_domain_loss: 0.0098 \n","[10/16] class_loss: 0.0061 s_domain_loss: 0.0012 t_domain_loss: 0.0090 \n","[11/16] class_loss: 0.0085 s_domain_loss: 0.0194 t_domain_loss: 0.0067 \n","[12/16] class_loss: 0.0057 s_domain_loss: 0.0002 t_domain_loss: 0.0078 \n","[13/16] class_loss: 0.0067 s_domain_loss: 0.0026 t_domain_loss: 0.0068 \n","[14/16] class_loss: 0.0065 s_domain_loss: 0.0025 t_domain_loss: 0.0061 \n","[15/16] class_loss: 0.0039 s_domain_loss: 0.0059 t_domain_loss: 0.0061 \n","[16/16] class_loss: 0.0032 s_domain_loss: 0.0006 t_domain_loss: 0.0044 \n","\n","Epoch 0011 / 0020\n","=================\n","[1/16] class_loss: 0.0015 s_domain_loss: 0.0037 t_domain_loss: 0.0053 \n","[2/16] class_loss: 0.0030 s_domain_loss: 0.0036 t_domain_loss: 0.0042 \n","[3/16] class_loss: 0.0028 s_domain_loss: 0.0018 t_domain_loss: 0.0038 \n","[4/16] class_loss: 0.0014 s_domain_loss: 0.0023 t_domain_loss: 0.0031 \n","[5/16] class_loss: 0.0077 s_domain_loss: 0.0684 t_domain_loss: 0.0029 \n","[6/16] class_loss: 0.0030 s_domain_loss: 0.0004 t_domain_loss: 0.0038 \n","[7/16] class_loss: 0.0092 s_domain_loss: 0.0012 t_domain_loss: 0.0046 \n","[8/16] class_loss: 0.0040 s_domain_loss: 0.0015 t_domain_loss: 0.0045 \n","[9/16] class_loss: 0.0043 s_domain_loss: 0.0001 t_domain_loss: 0.0061 \n","[10/16] class_loss: 0.0047 s_domain_loss: 0.0007 t_domain_loss: 0.0062 \n","[11/16] class_loss: 0.0066 s_domain_loss: 0.0002 t_domain_loss: 0.0064 \n","[12/16] class_loss: 0.0085 s_domain_loss: 0.5173 t_domain_loss: 0.0080 \n","[13/16] class_loss: 0.2091 s_domain_loss: 1.1111 t_domain_loss: 0.0500 \n","[14/16] class_loss: 0.1270 s_domain_loss: 0.0001 t_domain_loss: 0.5754 \n","[15/16] class_loss: 0.3543 s_domain_loss: 0.0158 t_domain_loss: 0.3469 \n","[16/16] class_loss: 0.2902 s_domain_loss: 0.2827 t_domain_loss: 0.0430 \n","\n","Epoch 0012 / 0020\n","=================\n","[1/16] class_loss: 0.3544 s_domain_loss: 0.1204 t_domain_loss: 0.0086 \n","[2/16] class_loss: 0.2714 s_domain_loss: 0.5062 t_domain_loss: 0.0023 \n","[3/16] class_loss: 0.8221 s_domain_loss: 7.8688 t_domain_loss: 0.0069 \n","[4/16] class_loss: 1.8062 s_domain_loss: 2.3797 t_domain_loss: 0.4594 \n","[5/16] class_loss: 0.9984 s_domain_loss: 0.0088 t_domain_loss: 6.6344 \n","[6/16] class_loss: 1.2279 s_domain_loss: 0.0583 t_domain_loss: 5.2280 \n","[7/16] class_loss: 0.8790 s_domain_loss: 4.0619 t_domain_loss: 0.0886 \n","[8/16] class_loss: 1.1297 s_domain_loss: 4.7112 t_domain_loss: 0.0305 \n","[9/16] class_loss: 1.0780 s_domain_loss: 0.5187 t_domain_loss: 1.6112 \n","[10/16] class_loss: 1.0147 s_domain_loss: 0.0832 t_domain_loss: 3.7682 \n","[11/16] class_loss: 1.4133 s_domain_loss: 1.5670 t_domain_loss: 0.5255 \n","[12/16] class_loss: 2.0707 s_domain_loss: 4.6844 t_domain_loss: 0.1139 \n","[13/16] class_loss: 2.2818 s_domain_loss: 1.4612 t_domain_loss: 0.6087 \n","[14/16] class_loss: 2.6688 s_domain_loss: 0.1115 t_domain_loss: 4.6273 \n","[15/16] class_loss: 2.0680 s_domain_loss: 0.6854 t_domain_loss: 1.4724 \n","[16/16] class_loss: 1.9636 s_domain_loss: 5.1331 t_domain_loss: 0.7393 \n","\n","Epoch 0013 / 0020\n","=================\n","[1/16] class_loss: 147.5693 s_domain_loss: 4.4619 t_domain_loss: 0.1420 \n","[2/16] class_loss: 557.0629 s_domain_loss: 0.0847 t_domain_loss: 3.7603 \n","[3/16] class_loss: 3020.8857 s_domain_loss: 0.0396 t_domain_loss: 6.6267 \n","[4/16] class_loss: 3231072.5000 s_domain_loss: 1.4576 t_domain_loss: 0.6676 \n","[5/16] class_loss: 169451203126468823873746894848.0000 s_domain_loss: 0.6529 t_domain_loss: 0.7351 \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0014 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0015 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0016 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0017 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0018 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0019 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0020 / 0020\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:15<00:00,  1.04it/s]\n"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.376953125\n","hyperprameters are: LR=0.007 and NUM_EPOCHS = 30\n","\n","Epoch 0001 / 0030\n","=================\n","[1/16] class_loss: 2.3260 s_domain_loss: 0.8916 t_domain_loss: 0.5824 \n","[2/16] class_loss: 1.1057 s_domain_loss: 0.3133 t_domain_loss: 1.3765 \n","[3/16] class_loss: 0.7840 s_domain_loss: 2.1627 t_domain_loss: 0.1360 \n","[4/16] class_loss: 0.5933 s_domain_loss: 0.1196 t_domain_loss: 2.3070 \n","[5/16] class_loss: 0.2917 s_domain_loss: 1.4425 t_domain_loss: 0.2846 \n","[6/16] class_loss: 0.2315 s_domain_loss: 0.4849 t_domain_loss: 0.9644 \n","[7/16] class_loss: 0.1761 s_domain_loss: 0.7066 t_domain_loss: 0.6628 \n","[8/16] class_loss: 0.2437 s_domain_loss: 0.8381 t_domain_loss: 0.5602 \n","[9/16] class_loss: 0.2218 s_domain_loss: 0.3480 t_domain_loss: 1.1744 \n","[10/16] class_loss: 0.1879 s_domain_loss: 1.7676 t_domain_loss: 0.1893 \n","[11/16] class_loss: 0.2463 s_domain_loss: 0.1120 t_domain_loss: 2.2282 \n","[12/16] class_loss: 0.1818 s_domain_loss: 1.6365 t_domain_loss: 0.2020 \n","[13/16] class_loss: 0.2158 s_domain_loss: 0.3706 t_domain_loss: 1.1014 \n","[14/16] class_loss: 0.1377 s_domain_loss: 0.8619 t_domain_loss: 0.4545 \n","[15/16] class_loss: 0.1135 s_domain_loss: 0.5012 t_domain_loss: 0.7685 \n","[16/16] class_loss: 0.0862 s_domain_loss: 0.8432 t_domain_loss: 0.4654 \n","\n","Epoch 0002 / 0030\n","=================\n","[1/16] class_loss: 0.0921 s_domain_loss: 0.3685 t_domain_loss: 1.0256 \n","[2/16] class_loss: 0.0811 s_domain_loss: 1.2633 t_domain_loss: 0.2387 \n","[3/16] class_loss: 0.0894 s_domain_loss: 0.1953 t_domain_loss: 1.6081 \n","[4/16] class_loss: 0.0975 s_domain_loss: 1.5733 t_domain_loss: 0.1512 \n","[5/16] class_loss: 0.1021 s_domain_loss: 0.2619 t_domain_loss: 1.1450 \n","[6/16] class_loss: 0.0690 s_domain_loss: 0.9129 t_domain_loss: 0.2962 \n","[7/16] class_loss: 0.0643 s_domain_loss: 0.2975 t_domain_loss: 0.8708 \n","[8/16] class_loss: 0.0506 s_domain_loss: 0.8987 t_domain_loss: 0.2533 \n","[9/16] class_loss: 0.0815 s_domain_loss: 0.2785 t_domain_loss: 0.9300 \n","[10/16] class_loss: 0.0670 s_domain_loss: 0.7923 t_domain_loss: 0.3265 \n","[11/16] class_loss: 0.0647 s_domain_loss: 0.3944 t_domain_loss: 0.5998 \n","[12/16] class_loss: 0.0735 s_domain_loss: 0.4771 t_domain_loss: 0.4964 \n","[13/16] class_loss: 0.0938 s_domain_loss: 0.5994 t_domain_loss: 0.3212 \n","[14/16] class_loss: 0.0658 s_domain_loss: 0.2193 t_domain_loss: 0.6612 \n","[15/16] class_loss: 0.0666 s_domain_loss: 0.8182 t_domain_loss: 0.1606 \n","[16/16] class_loss: 0.0549 s_domain_loss: 0.1771 t_domain_loss: 0.6169 \n","\n","Epoch 0003 / 0030\n","=================\n","[1/16] class_loss: 0.0916 s_domain_loss: 0.6736 t_domain_loss: 0.2462 \n","[2/16] class_loss: 0.1094 s_domain_loss: 0.2435 t_domain_loss: 0.5311 \n","[3/16] class_loss: 0.0634 s_domain_loss: 0.4637 t_domain_loss: 0.2599 \n","[4/16] class_loss: 0.0792 s_domain_loss: 0.4386 t_domain_loss: 0.2218 \n","[5/16] class_loss: 0.0698 s_domain_loss: 0.1737 t_domain_loss: 0.4337 \n","[6/16] class_loss: 0.0516 s_domain_loss: 0.4372 t_domain_loss: 0.1866 \n","[7/16] class_loss: 0.1042 s_domain_loss: 0.2816 t_domain_loss: 0.2879 \n","[8/16] class_loss: 0.0692 s_domain_loss: 0.1886 t_domain_loss: 0.4009 \n","[9/16] class_loss: 0.0882 s_domain_loss: 0.3862 t_domain_loss: 0.1287 \n","[10/16] class_loss: 0.0840 s_domain_loss: 0.4260 t_domain_loss: 0.1210 \n","[11/16] class_loss: 0.0725 s_domain_loss: 0.1190 t_domain_loss: 0.4411 \n","[12/16] class_loss: 0.0589 s_domain_loss: 0.2564 t_domain_loss: 0.2379 \n","[13/16] class_loss: 0.0649 s_domain_loss: 0.2372 t_domain_loss: 0.1107 \n","[14/16] class_loss: 0.0762 s_domain_loss: 0.1989 t_domain_loss: 0.0949 \n","[15/16] class_loss: 0.0780 s_domain_loss: 0.1909 t_domain_loss: 0.1425 \n","[16/16] class_loss: 0.0516 s_domain_loss: 0.1569 t_domain_loss: 0.1801 \n","\n","Epoch 0004 / 0030\n","=================\n","[1/16] class_loss: 0.0508 s_domain_loss: 0.1169 t_domain_loss: 0.1886 \n","[2/16] class_loss: 0.0689 s_domain_loss: 0.2139 t_domain_loss: 0.1022 \n","[3/16] class_loss: 0.1095 s_domain_loss: 0.1634 t_domain_loss: 0.0628 \n","[4/16] class_loss: 0.0819 s_domain_loss: 0.0761 t_domain_loss: 0.0793 \n","[5/16] class_loss: 0.0981 s_domain_loss: 0.0435 t_domain_loss: 0.0804 \n","[6/16] class_loss: 0.0634 s_domain_loss: 0.0778 t_domain_loss: 0.0606 \n","[7/16] class_loss: 0.0930 s_domain_loss: 0.1205 t_domain_loss: 0.0466 \n","[8/16] class_loss: 0.0400 s_domain_loss: 0.2909 t_domain_loss: 0.0622 \n","[9/16] class_loss: 0.0394 s_domain_loss: 0.0374 t_domain_loss: 0.2473 \n","[10/16] class_loss: 0.0400 s_domain_loss: 0.1646 t_domain_loss: 0.3118 \n","[11/16] class_loss: 0.0898 s_domain_loss: 0.1361 t_domain_loss: 0.0509 \n","[12/16] class_loss: 0.1531 s_domain_loss: 1.0966 t_domain_loss: 0.0369 \n","[13/16] class_loss: 0.0706 s_domain_loss: 0.3003 t_domain_loss: 0.4875 \n","[14/16] class_loss: 0.3448 s_domain_loss: 0.6253 t_domain_loss: 0.7504 \n","[15/16] class_loss: 0.2820 s_domain_loss: 0.0524 t_domain_loss: 0.2947 \n","[16/16] class_loss: 0.3599 s_domain_loss: 2.6397 t_domain_loss: 0.0296 \n","\n","Epoch 0005 / 0030\n","=================\n","[1/16] class_loss: 0.2007 s_domain_loss: 0.1080 t_domain_loss: 0.7626 \n","[2/16] class_loss: 0.2556 s_domain_loss: 0.1956 t_domain_loss: 0.9113 \n","[3/16] class_loss: 0.4628 s_domain_loss: 1.0931 t_domain_loss: 0.0657 \n","[4/16] class_loss: 0.3204 s_domain_loss: 1.0993 t_domain_loss: 0.0721 \n","[5/16] class_loss: 0.3034 s_domain_loss: 0.2891 t_domain_loss: 0.5257 \n","[6/16] class_loss: 0.4330 s_domain_loss: 0.2262 t_domain_loss: 0.5778 \n","[7/16] class_loss: 0.4209 s_domain_loss: 0.9242 t_domain_loss: 0.1280 \n","[8/16] class_loss: 0.4758 s_domain_loss: 0.1585 t_domain_loss: 0.2844 \n","[9/16] class_loss: 0.4821 s_domain_loss: 0.2358 t_domain_loss: 0.2504 \n","[10/16] class_loss: 0.2998 s_domain_loss: 0.1099 t_domain_loss: 0.1598 \n","[11/16] class_loss: 0.3263 s_domain_loss: 0.2480 t_domain_loss: 0.0247 \n","[12/16] class_loss: 0.3580 s_domain_loss: 0.5595 t_domain_loss: 0.0189 \n","[13/16] class_loss: 0.3590 s_domain_loss: 0.2288 t_domain_loss: 0.0800 \n","[14/16] class_loss: 0.3411 s_domain_loss: 0.0260 t_domain_loss: 0.5766 \n","[15/16] class_loss: 0.4465 s_domain_loss: 0.0827 t_domain_loss: 0.2315 \n","[16/16] class_loss: 0.3081 s_domain_loss: 0.0634 t_domain_loss: 0.0543 \n","\n","Epoch 0006 / 0030\n","=================\n","[1/16] class_loss: 0.3527 s_domain_loss: 0.3358 t_domain_loss: 0.0326 \n","[2/16] class_loss: 0.3883 s_domain_loss: 0.0487 t_domain_loss: 0.0101 \n","[3/16] class_loss: 0.5010 s_domain_loss: 0.1478 t_domain_loss: 0.0114 \n","[4/16] class_loss: 0.4604 s_domain_loss: 4.3004 t_domain_loss: 0.0139 \n","[5/16] class_loss: 0.4128 s_domain_loss: 0.4043 t_domain_loss: 2.0089 \n","[6/16] class_loss: 0.3374 s_domain_loss: 0.0021 t_domain_loss: 2.7023 \n","[7/16] class_loss: 0.4727 s_domain_loss: 1.0381 t_domain_loss: 0.0756 \n","[8/16] class_loss: 0.4805 s_domain_loss: 0.1899 t_domain_loss: 0.0102 \n","[9/16] class_loss: 0.2976 s_domain_loss: 1.0555 t_domain_loss: 0.0032 \n","[10/16] class_loss: 0.5599 s_domain_loss: 1.9637 t_domain_loss: 0.0403 \n","[11/16] class_loss: 0.5757 s_domain_loss: 0.0060 t_domain_loss: 1.2111 \n","[12/16] class_loss: 0.7152 s_domain_loss: 0.0002 t_domain_loss: 1.2587 \n","[13/16] class_loss: 0.7347 s_domain_loss: 2.9479 t_domain_loss: 0.0582 \n","[14/16] class_loss: 0.4718 s_domain_loss: 0.1159 t_domain_loss: 0.2001 \n","[15/16] class_loss: 1.5625 s_domain_loss: 1.8750 t_domain_loss: 0.2920 \n","[16/16] class_loss: 0.8812 s_domain_loss: 0.1707 t_domain_loss: 1.2437 \n","\n","Epoch 0007 / 0030\n","=================\n","[1/16] class_loss: 0.8648 s_domain_loss: 0.2678 t_domain_loss: 0.3431 \n","[2/16] class_loss: 0.8124 s_domain_loss: 0.2668 t_domain_loss: 0.0170 \n","[3/16] class_loss: 0.8066 s_domain_loss: 7.9353 t_domain_loss: 0.0017 \n","[4/16] class_loss: 0.8646 s_domain_loss: 2.6669 t_domain_loss: 0.2904 \n","[5/16] class_loss: 0.6428 s_domain_loss: 0.0479 t_domain_loss: 7.2097 \n","[6/16] class_loss: 0.6394 s_domain_loss: 0.0622 t_domain_loss: 7.3520 \n","[7/16] class_loss: 0.6238 s_domain_loss: 1.7454 t_domain_loss: 1.0909 \n","[8/16] class_loss: 0.7132 s_domain_loss: 6.6119 t_domain_loss: 0.0027 \n","[9/16] class_loss: 0.6653 s_domain_loss: 3.6487 t_domain_loss: 0.0534 \n","[10/16] class_loss: 0.7762 s_domain_loss: 0.0248 t_domain_loss: 3.6556 \n","[11/16] class_loss: 0.8790 s_domain_loss: 0.0364 t_domain_loss: 4.1498 \n","[12/16] class_loss: 0.9378 s_domain_loss: 1.2035 t_domain_loss: 0.1740 \n","[13/16] class_loss: 0.8194 s_domain_loss: 1.3172 t_domain_loss: 0.0063 \n","[14/16] class_loss: 0.7850 s_domain_loss: 0.9215 t_domain_loss: 0.0540 \n","[15/16] class_loss: 0.7942 s_domain_loss: 0.0815 t_domain_loss: 0.5297 \n","[16/16] class_loss: 0.8055 s_domain_loss: 0.1265 t_domain_loss: 0.6257 \n","\n","Epoch 0008 / 0030\n","=================\n","[1/16] class_loss: 0.8405 s_domain_loss: 0.3807 t_domain_loss: 0.3591 \n","[2/16] class_loss: 0.6976 s_domain_loss: 0.0714 t_domain_loss: 0.0977 \n","[3/16] class_loss: 0.6998 s_domain_loss: 0.0579 t_domain_loss: 0.0237 \n","[4/16] class_loss: 0.6109 s_domain_loss: 0.6566 t_domain_loss: 0.0040 \n","[5/16] class_loss: 0.6383 s_domain_loss: 0.0986 t_domain_loss: 0.0146 \n","[6/16] class_loss: 0.6989 s_domain_loss: 0.0236 t_domain_loss: 0.0613 \n","[7/16] class_loss: 0.7437 s_domain_loss: 1.1826 t_domain_loss: 0.0522 \n","[8/16] class_loss: 0.5822 s_domain_loss: 0.0015 t_domain_loss: 0.2038 \n","[9/16] class_loss: 0.8480 s_domain_loss: 0.1511 t_domain_loss: 0.2974 \n","[10/16] class_loss: 0.6348 s_domain_loss: 1.7941 t_domain_loss: 0.1225 \n","[11/16] class_loss: 0.8405 s_domain_loss: 0.0027 t_domain_loss: 0.9569 \n","[12/16] class_loss: 0.9141 s_domain_loss: 0.0132 t_domain_loss: 0.7126 \n","[13/16] class_loss: 0.8250 s_domain_loss: 1.3484 t_domain_loss: 0.0964 \n","[14/16] class_loss: 0.5282 s_domain_loss: 0.2572 t_domain_loss: 0.0533 \n","[15/16] class_loss: 0.7479 s_domain_loss: 0.3234 t_domain_loss: 0.0316 \n","[16/16] class_loss: 0.5964 s_domain_loss: 8.1272 t_domain_loss: 0.0380 \n","\n","Epoch 0009 / 0030\n","=================\n","[1/16] class_loss: 0.5819 s_domain_loss: 0.5304 t_domain_loss: 1.0376 \n","[2/16] class_loss: 0.6925 s_domain_loss: 0.1151 t_domain_loss: 2.6118 \n","[3/16] class_loss: 0.6341 s_domain_loss: 0.0966 t_domain_loss: 1.3768 \n","[4/16] class_loss: 0.7683 s_domain_loss: 0.9497 t_domain_loss: 0.0593 \n","[5/16] class_loss: 1.1911 s_domain_loss: 0.5401 t_domain_loss: 0.0222 \n","[6/16] class_loss: 0.9251 s_domain_loss: 0.1350 t_domain_loss: 0.0121 \n","[7/16] class_loss: 1.0198 s_domain_loss: 0.1041 t_domain_loss: 0.0069 \n","[8/16] class_loss: 0.9441 s_domain_loss: 2.6636 t_domain_loss: 0.0035 \n","[9/16] class_loss: 1.4323 s_domain_loss: 0.1126 t_domain_loss: 0.1134 \n","[10/16] class_loss: 1.4573 s_domain_loss: 1.9777 t_domain_loss: 0.7011 \n","[11/16] class_loss: 1.8972 s_domain_loss: 0.0319 t_domain_loss: 3.6407 \n","[12/16] class_loss: 0.9648 s_domain_loss: 0.0087 t_domain_loss: 1.6624 \n","[13/16] class_loss: 1.1390 s_domain_loss: 0.4646 t_domain_loss: 0.0222 \n","[14/16] class_loss: 1.1378 s_domain_loss: 0.5211 t_domain_loss: 0.0004 \n","[15/16] class_loss: 0.9862 s_domain_loss: 1.3506 t_domain_loss: 0.0001 \n","[16/16] class_loss: 1.0745 s_domain_loss: 4.8488 t_domain_loss: 0.0000 \n","\n","Epoch 0010 / 0030\n","=================\n","[1/16] class_loss: 1.4579 s_domain_loss: 4.5626 t_domain_loss: 0.0008 \n","[2/16] class_loss: 1.3994 s_domain_loss: 0.6540 t_domain_loss: 0.1768 \n","[3/16] class_loss: 1.0301 s_domain_loss: 0.0031 t_domain_loss: 0.9477 \n","[4/16] class_loss: 0.9469 s_domain_loss: 0.0584 t_domain_loss: 2.1291 \n","[5/16] class_loss: 1.0074 s_domain_loss: 0.2082 t_domain_loss: 0.5522 \n","[6/16] class_loss: 1.2952 s_domain_loss: 0.0343 t_domain_loss: 0.0303 \n","[7/16] class_loss: 0.8735 s_domain_loss: 0.1513 t_domain_loss: 0.0020 \n","[8/16] class_loss: 1.0393 s_domain_loss: 0.3245 t_domain_loss: 0.0001 \n","[9/16] class_loss: 1.0047 s_domain_loss: 0.1640 t_domain_loss: 0.0002 \n","[10/16] class_loss: 0.8935 s_domain_loss: 5.2739 t_domain_loss: 0.0002 \n","[11/16] class_loss: 2.8600 s_domain_loss: 6.2996 t_domain_loss: 0.0011 \n","[12/16] class_loss: 9.9752 s_domain_loss: 6.5998 t_domain_loss: 0.1662 \n","[13/16] class_loss: 5.9927 s_domain_loss: 0.9168 t_domain_loss: 2.2202 \n","[14/16] class_loss: 2.6421 s_domain_loss: 0.0152 t_domain_loss: 7.1326 \n","[15/16] class_loss: 4.2622 s_domain_loss: 0.0182 t_domain_loss: 5.2522 \n","[16/16] class_loss: 5.5975 s_domain_loss: 0.0461 t_domain_loss: 3.6951 \n","\n","Epoch 0011 / 0030\n","=================\n","[1/16] class_loss: 2.3846 s_domain_loss: 0.6034 t_domain_loss: 0.0503 \n","[2/16] class_loss: 2.7663 s_domain_loss: 0.5661 t_domain_loss: 0.0013 \n","[3/16] class_loss: 1.9083 s_domain_loss: 22.8844 t_domain_loss: 0.0001 \n","[4/16] class_loss: 43.0028 s_domain_loss: 30.1830 t_domain_loss: 0.0021 \n","[5/16] class_loss: 10.3762 s_domain_loss: 21.5491 t_domain_loss: 0.0614 \n","[6/16] class_loss: 90.8715 s_domain_loss: 5.1404 t_domain_loss: 1.1337 \n","[7/16] class_loss: 74.1699 s_domain_loss: 0.3081 t_domain_loss: 14.6861 \n","[8/16] class_loss: 223.7848 s_domain_loss: 0.0000 t_domain_loss: 23.1814 \n","[9/16] class_loss: 270.8336 s_domain_loss: 0.0000 t_domain_loss: 21.6421 \n","[10/16] class_loss: 106.7253 s_domain_loss: 0.8170 t_domain_loss: 11.8809 \n","[11/16] class_loss: 28352.3594 s_domain_loss: 6.1811 t_domain_loss: 0.3674 \n","[12/16] class_loss: 73619808256.0000 s_domain_loss: 13.9730 t_domain_loss: 0.0156 \n","[13/16] class_loss: nan s_domain_loss: 0.1558 t_domain_loss: 1.9361 \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0012 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0013 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0014 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0015 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0016 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0017 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0018 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0019 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0020 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0021 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0022 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0023 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0024 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0025 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0026 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0027 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0028 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0029 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","\n","Epoch 0030 / 0030\n","=================\n","[1/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[2/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[3/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[4/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[5/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[6/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[7/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[8/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[9/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[10/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[11/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[12/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[13/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[14/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n","[15/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["\r  0%|          | 0/16 [00:00<?, ?it/s]"],"name":"stderr"},{"output_type":"stream","text":["[16/16] class_loss: nan s_domain_loss: nan t_domain_loss: nan \n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 16/16 [00:15<00:00,  1.03it/s]"],"name":"stderr"},{"output_type":"stream","text":["Validation Accuracy on Sketch: 0.376953125\n","best hyperparemeters after validation on sketch are : LR=0.005, NUM_EPOCHS= 10 having validation accuracy= 0.5185546875 and validation loss =10.196216583251953\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vUbQ4cNxO6iX"},"source":["##Evaluate the best hyperparameters among the two validation sets "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"74rWSftjO6ib","outputId":"33366d96-585c-44eb-8928-9c1dfddc1588","executionInfo":{"status":"ok","timestamp":1591827337447,"user_tz":-120,"elapsed":10916466,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#I take the best hyperparameters belonging to the validation set where the loss is smaller\n","\n","if min_val_loss<min_val_loss2:\n","  best_final_LR= best_LR\n","  best_final_epoch_num= best_epoch_num\n","else:\n","    best_final_LR= best_LR2\n","    best_final_epoch_num= best_epoch_num2\n","\n","print(\"best final LR= {}, best final epoch number={}\".format(best_final_LR,best_final_epoch_num))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["best final LR= 0.007, best final epoch number=20\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gNtzzuXlO-os","colab_type":"text"},"source":["##Train on Photo and test on Art Paintings with the best hyperparameters with domain adaptation"]},{"cell_type":"markdown","metadata":{"id":"1tS2cIdyPUpn","colab_type":"text"},"source":["###Train on photo"]},{"cell_type":"code","metadata":{"id":"MF-YSulRPXnX","colab_type":"code","outputId":"1e7c2449-8c83-48f8-a056-bb67a1704e7e","executionInfo":{"status":"ok","timestamp":1591827805282,"user_tz":-120,"elapsed":11382292,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["alpha=1\n","\n","net = DANNAlexnet(num_classes = 7)\n","net = net.to(DEVICE)\n","\n","class_loss = nn.CrossEntropyLoss() \n","domain_loss = nn.CrossEntropyLoss()\n","\n","parameters_to_optimize = net.parameters() \n","\n","optimizer = optim.SGD(parameters_to_optimize, lr=best_final_LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n","\n","scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)\n","\n","\n","max_batches = max(len(train_dataloader), len(test_dataloader))\n","min_batches = min(len(train_dataloader), len(test_dataloader))#\n","net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","\n","cudnn.benchmark #function to optimize runtime by finding the best configuration for your hw, useful when input size \n","running_corrects = 0\n","current_step = 0\n","for epoch in range(best_final_epoch_num):\n","  print(f'\\nEpoch {epoch+1:04d} / {best_final_epoch_num:04d}', end='\\n=================\\n')\n","  scheduler.step() \n","  train_iterable = iter(train_dataloader)\n","  test_iterable = iter(test_dataloader)\n","  for batch in range(max_batches):\n","    net.train() # Sets module in training mode\n","    optimizer.zero_grad() # Zero-ing the gradients \n","    if( batch == min_batches):\n","      train_iterable = iter(train_dataloader)#\n","\n","    images_source, labels_source = next(train_iterable)\n","    labels_domain = torch.zeros(len(images_source), dtype=torch.long)    \n","    \n","    images_source = images_source.to(DEVICE)\n","    labels_source = labels_source.to(DEVICE)\n","    labels_domain = labels_domain.to(DEVICE)\n","    \n","    class_output = net(images_source)\n","    domain_output = net(images_source, alpha)\n","    \n","\n","\n","    loss_s_label = class_loss(class_output, labels_source)\n","    loss_s_domain = domain_loss(domain_output, labels_domain)\n","    \n","\n","  \n","    targets, _ = next(test_iterable)\n","    target_domain = torch.ones(len(targets), dtype=torch.long)\n","\n"," \n","    targets = targets.to(DEVICE)\n","    target_domain = target_domain.to(DEVICE)\n","\n","    target_output = net(targets, alpha)\n","\n","\n","    loss_t_domain = domain_loss(target_output,target_domain)\n","\n","\n","    loss = loss_s_label + loss_s_domain + loss_t_domain\n","    loss.backward() \n","\n","    optimizer.step() \n","\n","    current_step += 1\n","\n","    print(f'[{batch+1}/{max_batches}] '\n","          f'class_loss: {loss_s_label.item():.4f} ' f's_domain_loss: {loss_s_domain.item():.4f} '\n","          f't_domain_loss: {loss_t_domain.item():.4f} '\n","          )  \n","\n","\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\n","Epoch 0001 / 0020\n","=================\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["[1/8] class_loss: 1.8695 s_domain_loss: 0.5458 t_domain_loss: 0.9141 \n","[2/8] class_loss: 1.0663 s_domain_loss: 1.4367 t_domain_loss: 0.2952 \n","[3/8] class_loss: 0.7143 s_domain_loss: 0.1133 t_domain_loss: 2.2845 \n","[4/8] class_loss: 0.3813 s_domain_loss: 2.0741 t_domain_loss: 0.1473 \n","[5/8] class_loss: 0.2924 s_domain_loss: 0.2818 t_domain_loss: 1.4189 \n","[6/8] class_loss: 0.2640 s_domain_loss: 1.1076 t_domain_loss: 0.4096 \n","[7/8] class_loss: 0.2372 s_domain_loss: 0.3712 t_domain_loss: 1.1456 \n","[8/8] class_loss: 0.2636 s_domain_loss: 1.4310 t_domain_loss: 0.2752 \n","\n","Epoch 0002 / 0020\n","=================\n","[1/8] class_loss: 0.2075 s_domain_loss: 0.1312 t_domain_loss: 1.9738 \n","[2/8] class_loss: 0.2272 s_domain_loss: 2.0298 t_domain_loss: 0.1373 \n","[3/8] class_loss: 0.1358 s_domain_loss: 0.2061 t_domain_loss: 1.5749 \n","[4/8] class_loss: 0.2274 s_domain_loss: 1.2667 t_domain_loss: 0.3087 \n","[5/8] class_loss: 0.2107 s_domain_loss: 0.3104 t_domain_loss: 1.2160 \n","[6/8] class_loss: 0.1241 s_domain_loss: 1.4492 t_domain_loss: 0.2346 \n","[7/8] class_loss: 0.2198 s_domain_loss: 0.1370 t_domain_loss: 1.8703 \n","[8/8] class_loss: 0.2668 s_domain_loss: 1.8191 t_domain_loss: 0.1531 \n","\n","Epoch 0003 / 0020\n","=================\n","[1/8] class_loss: 0.1079 s_domain_loss: 0.2134 t_domain_loss: 1.4106 \n","[2/8] class_loss: 0.0846 s_domain_loss: 1.1258 t_domain_loss: 0.3013 \n","[3/8] class_loss: 0.1098 s_domain_loss: 0.3252 t_domain_loss: 1.0300 \n","[4/8] class_loss: 0.1359 s_domain_loss: 1.0909 t_domain_loss: 0.2938 \n","[5/8] class_loss: 0.1655 s_domain_loss: 0.2414 t_domain_loss: 1.2724 \n","[6/8] class_loss: 0.0526 s_domain_loss: 1.4235 t_domain_loss: 0.1935 \n","[7/8] class_loss: 0.0394 s_domain_loss: 0.1721 t_domain_loss: 1.4835 \n","[8/8] class_loss: 0.0606 s_domain_loss: 1.3121 t_domain_loss: 0.1968 \n","\n","Epoch 0004 / 0020\n","=================\n","[1/8] class_loss: 0.0685 s_domain_loss: 0.2333 t_domain_loss: 1.0437 \n","[2/8] class_loss: 0.0983 s_domain_loss: 0.8649 t_domain_loss: 0.2957 \n","[3/8] class_loss: 0.0613 s_domain_loss: 0.3669 t_domain_loss: 0.6969 \n","[4/8] class_loss: 0.0951 s_domain_loss: 0.5760 t_domain_loss: 0.4696 \n","[5/8] class_loss: 0.1126 s_domain_loss: 0.5859 t_domain_loss: 0.4809 \n","[6/8] class_loss: 0.0897 s_domain_loss: 0.3948 t_domain_loss: 0.7278 \n","[7/8] class_loss: 0.0680 s_domain_loss: 0.8331 t_domain_loss: 0.2977 \n","[8/8] class_loss: 0.0376 s_domain_loss: 0.3050 t_domain_loss: 0.7882 \n","\n","Epoch 0005 / 0020\n","=================\n","[1/8] class_loss: 0.0539 s_domain_loss: 0.6247 t_domain_loss: 0.3555 \n","[2/8] class_loss: 0.0339 s_domain_loss: 0.3743 t_domain_loss: 0.5341 \n","[3/8] class_loss: 0.0295 s_domain_loss: 0.6095 t_domain_loss: 0.3403 \n","[4/8] class_loss: 0.0343 s_domain_loss: 0.2669 t_domain_loss: 0.6853 \n","[5/8] class_loss: 0.0556 s_domain_loss: 0.7849 t_domain_loss: 0.2092 \n","[6/8] class_loss: 0.0467 s_domain_loss: 0.3563 t_domain_loss: 0.5273 \n","[7/8] class_loss: 0.0580 s_domain_loss: 0.5398 t_domain_loss: 0.5267 \n","[8/8] class_loss: 0.0271 s_domain_loss: 0.2552 t_domain_loss: 0.5739 \n","\n","Epoch 0006 / 0020\n","=================\n","[1/8] class_loss: 0.0314 s_domain_loss: 0.7991 t_domain_loss: 0.1822 \n","[2/8] class_loss: 0.0505 s_domain_loss: 0.2736 t_domain_loss: 0.4721 \n","[3/8] class_loss: 0.0329 s_domain_loss: 0.1931 t_domain_loss: 0.5247 \n","[4/8] class_loss: 0.0425 s_domain_loss: 0.9829 t_domain_loss: 0.1043 \n","[5/8] class_loss: 0.0588 s_domain_loss: 0.1141 t_domain_loss: 0.6668 \n","[6/8] class_loss: 0.0569 s_domain_loss: 0.4064 t_domain_loss: 0.2590 \n","[7/8] class_loss: 0.0477 s_domain_loss: 0.4150 t_domain_loss: 0.1775 \n","[8/8] class_loss: 0.0543 s_domain_loss: 0.4427 t_domain_loss: 0.2609 \n","\n","Epoch 0007 / 0020\n","=================\n","[1/8] class_loss: 0.0780 s_domain_loss: 0.0661 t_domain_loss: 0.9296 \n","[2/8] class_loss: 0.0471 s_domain_loss: 0.4637 t_domain_loss: 0.1422 \n","[3/8] class_loss: 0.0211 s_domain_loss: 0.7733 t_domain_loss: 0.1071 \n","[4/8] class_loss: 0.0424 s_domain_loss: 0.1099 t_domain_loss: 0.4218 \n","[5/8] class_loss: 0.0953 s_domain_loss: 0.2563 t_domain_loss: 0.2842 \n","[6/8] class_loss: 0.0440 s_domain_loss: 0.5306 t_domain_loss: 0.1315 \n","[7/8] class_loss: 0.0319 s_domain_loss: 0.1141 t_domain_loss: 0.4592 \n","[8/8] class_loss: 0.1556 s_domain_loss: 0.5718 t_domain_loss: 0.2397 \n","\n","Epoch 0008 / 0020\n","=================\n","[1/8] class_loss: 0.0893 s_domain_loss: 0.2502 t_domain_loss: 0.2099 \n","[2/8] class_loss: 0.1262 s_domain_loss: 0.2991 t_domain_loss: 0.1800 \n","[3/8] class_loss: 0.2039 s_domain_loss: 0.4236 t_domain_loss: 0.2250 \n","[4/8] class_loss: 0.0871 s_domain_loss: 0.0905 t_domain_loss: 0.5661 \n","[5/8] class_loss: 0.0703 s_domain_loss: 0.2837 t_domain_loss: 0.1799 \n","[6/8] class_loss: 0.1201 s_domain_loss: 0.6748 t_domain_loss: 0.0450 \n","[7/8] class_loss: 0.1104 s_domain_loss: 0.1178 t_domain_loss: 0.2596 \n","[8/8] class_loss: 0.1545 s_domain_loss: 0.0802 t_domain_loss: 0.2994 \n","\n","Epoch 0009 / 0020\n","=================\n","[1/8] class_loss: 0.1774 s_domain_loss: 0.2959 t_domain_loss: 0.1940 \n","[2/8] class_loss: 0.0862 s_domain_loss: 0.2160 t_domain_loss: 0.1525 \n","[3/8] class_loss: 0.0845 s_domain_loss: 0.1800 t_domain_loss: 0.1348 \n","[4/8] class_loss: 0.0837 s_domain_loss: 0.1749 t_domain_loss: 0.1535 \n","[5/8] class_loss: 0.1604 s_domain_loss: 0.0783 t_domain_loss: 0.2088 \n","[6/8] class_loss: 0.0758 s_domain_loss: 0.3232 t_domain_loss: 0.0760 \n","[7/8] class_loss: 0.0930 s_domain_loss: 0.0793 t_domain_loss: 0.1912 \n","[8/8] class_loss: 0.1162 s_domain_loss: 0.1063 t_domain_loss: 0.1214 \n","\n","Epoch 0010 / 0020\n","=================\n","[1/8] class_loss: 0.0614 s_domain_loss: 0.1495 t_domain_loss: 0.1379 \n","[2/8] class_loss: 0.0879 s_domain_loss: 0.1659 t_domain_loss: 0.1005 \n","[3/8] class_loss: 0.0699 s_domain_loss: 0.0879 t_domain_loss: 0.0932 \n","[4/8] class_loss: 0.0604 s_domain_loss: 0.1826 t_domain_loss: 0.0573 \n","[5/8] class_loss: 0.0453 s_domain_loss: 0.1304 t_domain_loss: 0.1025 \n","[6/8] class_loss: 0.0515 s_domain_loss: 0.0337 t_domain_loss: 0.2006 \n","[7/8] class_loss: 0.0405 s_domain_loss: 0.0587 t_domain_loss: 0.1280 \n","[8/8] class_loss: 0.0442 s_domain_loss: 0.0438 t_domain_loss: 0.0357 \n","\n","Epoch 0011 / 0020\n","=================\n","[1/8] class_loss: 0.0499 s_domain_loss: 0.1698 t_domain_loss: 0.0258 \n","[2/8] class_loss: 0.0260 s_domain_loss: 0.1037 t_domain_loss: 0.0391 \n","[3/8] class_loss: 0.0239 s_domain_loss: 0.1158 t_domain_loss: 0.0699 \n","[4/8] class_loss: 0.0565 s_domain_loss: 0.0460 t_domain_loss: 0.0703 \n","[5/8] class_loss: 0.0379 s_domain_loss: 0.0978 t_domain_loss: 0.0887 \n","[6/8] class_loss: 0.0524 s_domain_loss: 0.0408 t_domain_loss: 0.0632 \n","[7/8] class_loss: 0.0459 s_domain_loss: 0.0435 t_domain_loss: 0.0910 \n","[8/8] class_loss: 0.0411 s_domain_loss: 0.2905 t_domain_loss: 0.0472 \n","\n","Epoch 0012 / 0020\n","=================\n","[1/8] class_loss: 0.0220 s_domain_loss: 0.0026 t_domain_loss: 0.2751 \n","[2/8] class_loss: 0.0420 s_domain_loss: 0.1043 t_domain_loss: 0.1981 \n","[3/8] class_loss: 0.0421 s_domain_loss: 0.0602 t_domain_loss: 0.0610 \n","[4/8] class_loss: 0.0240 s_domain_loss: 0.1701 t_domain_loss: 0.0134 \n","[5/8] class_loss: 0.0266 s_domain_loss: 0.1366 t_domain_loss: 0.0112 \n","[6/8] class_loss: 0.0681 s_domain_loss: 0.0476 t_domain_loss: 0.0154 \n","[7/8] class_loss: 0.0544 s_domain_loss: 0.0707 t_domain_loss: 0.0242 \n","[8/8] class_loss: 0.0314 s_domain_loss: 0.0538 t_domain_loss: 0.0456 \n","\n","Epoch 0013 / 0020\n","=================\n","[1/8] class_loss: 0.0327 s_domain_loss: 0.0448 t_domain_loss: 0.1301 \n","[2/8] class_loss: 0.0428 s_domain_loss: 0.0289 t_domain_loss: 0.1256 \n","[3/8] class_loss: 0.0387 s_domain_loss: 0.0042 t_domain_loss: 0.0723 \n","[4/8] class_loss: 0.0342 s_domain_loss: 0.0095 t_domain_loss: 0.0264 \n","[5/8] class_loss: 0.0436 s_domain_loss: 0.0583 t_domain_loss: 0.0167 \n","[6/8] class_loss: 0.0350 s_domain_loss: 0.1053 t_domain_loss: 0.0064 \n","[7/8] class_loss: 0.0248 s_domain_loss: 0.0351 t_domain_loss: 0.0162 \n","[8/8] class_loss: 0.0087 s_domain_loss: 0.1144 t_domain_loss: 0.0082 \n","\n","Epoch 0014 / 0020\n","=================\n","[1/8] class_loss: 0.0268 s_domain_loss: 0.0069 t_domain_loss: 0.0545 \n","[2/8] class_loss: 0.0188 s_domain_loss: 0.0190 t_domain_loss: 0.0344 \n","[3/8] class_loss: 0.0352 s_domain_loss: 0.0177 t_domain_loss: 0.0290 \n","[4/8] class_loss: 0.0169 s_domain_loss: 0.1164 t_domain_loss: 0.0289 \n","[5/8] class_loss: 0.0184 s_domain_loss: 0.0057 t_domain_loss: 0.0490 \n","[6/8] class_loss: 0.0745 s_domain_loss: 0.0038 t_domain_loss: 0.0489 \n","[7/8] class_loss: 0.0343 s_domain_loss: 0.0101 t_domain_loss: 0.0298 \n","[8/8] class_loss: 0.0277 s_domain_loss: 0.1003 t_domain_loss: 0.0179 \n","\n","Epoch 0015 / 0020\n","=================\n","[1/8] class_loss: 0.0327 s_domain_loss: 0.0816 t_domain_loss: 0.0290 \n","[2/8] class_loss: 0.0210 s_domain_loss: 0.0111 t_domain_loss: 0.0610 \n","[3/8] class_loss: 0.0201 s_domain_loss: 0.0198 t_domain_loss: 0.0354 \n","[4/8] class_loss: 0.0502 s_domain_loss: 0.0086 t_domain_loss: 0.0299 \n","[5/8] class_loss: 0.0337 s_domain_loss: 0.0177 t_domain_loss: 0.0358 \n","[6/8] class_loss: 0.0199 s_domain_loss: 0.0129 t_domain_loss: 0.0170 \n","[7/8] class_loss: 0.0066 s_domain_loss: 0.0202 t_domain_loss: 0.0200 \n","[8/8] class_loss: 0.0087 s_domain_loss: 0.0608 t_domain_loss: 0.0073 \n","\n","Epoch 0016 / 0020\n","=================\n","[1/8] class_loss: 0.0126 s_domain_loss: 0.0215 t_domain_loss: 0.0127 \n","[2/8] class_loss: 0.0399 s_domain_loss: 0.0162 t_domain_loss: 0.0078 \n","[3/8] class_loss: 0.0320 s_domain_loss: 0.0084 t_domain_loss: 0.0081 \n","[4/8] class_loss: 0.0265 s_domain_loss: 0.0051 t_domain_loss: 0.0068 \n","[5/8] class_loss: 0.0418 s_domain_loss: 0.0147 t_domain_loss: 0.0108 \n","[6/8] class_loss: 0.0082 s_domain_loss: 0.0098 t_domain_loss: 0.0084 \n","[7/8] class_loss: 0.0080 s_domain_loss: 0.0164 t_domain_loss: 0.0238 \n","[8/8] class_loss: 0.0096 s_domain_loss: 0.0093 t_domain_loss: 0.0112 \n","\n","Epoch 0017 / 0020\n","=================\n","[1/8] class_loss: 0.0106 s_domain_loss: 0.0419 t_domain_loss: 0.0241 \n","[2/8] class_loss: 0.0139 s_domain_loss: 0.0214 t_domain_loss: 0.0096 \n","[3/8] class_loss: 0.0079 s_domain_loss: 0.0081 t_domain_loss: 0.0085 \n","[4/8] class_loss: 0.0189 s_domain_loss: 0.0041 t_domain_loss: 0.0083 \n","[5/8] class_loss: 0.0161 s_domain_loss: 0.0017 t_domain_loss: 0.0112 \n","[6/8] class_loss: 0.0156 s_domain_loss: 0.0075 t_domain_loss: 0.0098 \n","[7/8] class_loss: 0.0195 s_domain_loss: 0.0728 t_domain_loss: 0.0131 \n","[8/8] class_loss: 0.0095 s_domain_loss: 0.0018 t_domain_loss: 0.0115 \n","\n","Epoch 0018 / 0020\n","=================\n","[1/8] class_loss: 0.0084 s_domain_loss: 0.0029 t_domain_loss: 0.0383 \n","[2/8] class_loss: 0.0197 s_domain_loss: 0.0051 t_domain_loss: 0.0241 \n","[3/8] class_loss: 0.0112 s_domain_loss: 0.0029 t_domain_loss: 0.0150 \n","[4/8] class_loss: 0.0028 s_domain_loss: 0.0018 t_domain_loss: 0.0111 \n","[5/8] class_loss: 0.0046 s_domain_loss: 0.0342 t_domain_loss: 0.0132 \n","[6/8] class_loss: 0.0080 s_domain_loss: 0.0054 t_domain_loss: 0.0080 \n","[7/8] class_loss: 0.0048 s_domain_loss: 0.0180 t_domain_loss: 0.0088 \n","[8/8] class_loss: 0.0086 s_domain_loss: 0.0105 t_domain_loss: 0.0058 \n","\n","Epoch 0019 / 0020\n","=================\n","[1/8] class_loss: 0.0037 s_domain_loss: 0.0083 t_domain_loss: 0.0073 \n","[2/8] class_loss: 0.0045 s_domain_loss: 0.0072 t_domain_loss: 0.0051 \n","[3/8] class_loss: 0.0078 s_domain_loss: 0.0038 t_domain_loss: 0.0041 \n","[4/8] class_loss: 0.0045 s_domain_loss: 0.0028 t_domain_loss: 0.0033 \n","[5/8] class_loss: 0.0027 s_domain_loss: 0.0254 t_domain_loss: 0.0047 \n","[6/8] class_loss: 0.0039 s_domain_loss: 0.0268 t_domain_loss: 0.0043 \n","[7/8] class_loss: 0.0043 s_domain_loss: 0.0038 t_domain_loss: 0.0057 \n","[8/8] class_loss: 0.0033 s_domain_loss: 0.0043 t_domain_loss: 0.0053 \n","\n","Epoch 0020 / 0020\n","=================\n","[1/8] class_loss: 0.0025 s_domain_loss: 0.0023 t_domain_loss: 0.0079 \n","[2/8] class_loss: 0.0104 s_domain_loss: 0.0073 t_domain_loss: 0.0063 \n","[3/8] class_loss: 0.0022 s_domain_loss: 0.0008 t_domain_loss: 0.0063 \n","[4/8] class_loss: 0.0095 s_domain_loss: 0.0023 t_domain_loss: 0.0055 \n","[5/8] class_loss: 0.0048 s_domain_loss: 0.0040 t_domain_loss: 0.0077 \n","[6/8] class_loss: 0.0098 s_domain_loss: 0.0079 t_domain_loss: 0.0069 \n","[7/8] class_loss: 0.0030 s_domain_loss: 0.0045 t_domain_loss: 0.0080 \n","[8/8] class_loss: 0.0045 s_domain_loss: 0.0015 t_domain_loss: 0.0058 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"E_uwvJCiP5iy","colab_type":"text"},"source":["###Test on Art Paintings"]},{"cell_type":"code","metadata":{"id":"dE14sfpFP9wE","colab_type":"code","outputId":"34836cc3-4925-41c5-aafd-2b0547b22593","executionInfo":{"status":"ok","timestamp":1591816082035,"user_tz":-120,"elapsed":10695,"user":{"displayName":"Eleonora Carletti","photoUrl":"","userId":"01659218477565948267"}},"colab":{"base_uri":"https://localhost:8080/","height":67}},"source":["net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n","net.train(False) # Set Network to evaluation mode\n","\n","running_corrects = 0\n","for images, labels in tqdm(test_dataloader):\n","  images = images.to(DEVICE)\n","  labels = labels.to(DEVICE)\n","\n","  # Forward Pass\n","  outputs = net(images)\n","\n","  loss = criterion(outputs, labels)\n","\n","  # Get predictions\n","  _, preds = torch.max(outputs.data, 1)\n","\n","  # Update Corrects\n","  running_corrects += torch.sum(preds == labels.data).data.item()\n","\n","# Calculate Accuracy\n","accuracy = running_corrects / float(len(test_dataset))\n","\n","print('Test Accuracy: {}'.format(accuracy))\n","print('Loss is: ' + str(loss.item()))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["100%|██████████| 8/8 [00:10<00:00,  1.31s/it]"],"name":"stderr"},{"output_type":"stream","text":["Test Accuracy: 0.4130859375\n","Loss is: 10.455820083618164\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]}]}